{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Foundations of Software Engineering","text":""},{"location":"#schedule","title":"Schedule","text":""},{"location":"#sprint-2-two-polished-stories-for-your-feature-sprint","title":"Sprint 2: Two Polished Stories for your Feature Sprint","text":""},{"location":"#mon-0428","title":"Mon 04/28","text":"<ul> <li><code>MT37 - Meeting</code> LDOC</li> </ul>"},{"location":"#fri-0425","title":"Fri 04/25","text":"<ul> <li><code>MT36 - Meeting</code> Stack Review</li> </ul>"},{"location":"#wed-0423","title":"Wed 04/23","text":"<ul> <li><code>MT35 - Meeting</code> Working Day</li> </ul>"},{"location":"#mon-0421","title":"Mon 04/21","text":"<ul> <li><code>MT34 - Meeting</code> Presentation Skills</li> </ul>"},{"location":"#wed-0416","title":"Wed 04/16","text":"<ul> <li><code>MT33 - Meeting</code> Sprint 2 Deployment</li> <li><code>SP02 - Sprint</code> Deployment Instructions</li> <li><code>SP02 - Sprint</code> Sprint 02 - Week 0 - Deployment and Progress on 2nd Story Due: Wed 04/23</li> </ul>"},{"location":"#mon-0414","title":"Mon 04/14","text":"<ul> <li><code>MT32 - Meeting</code> Sprint 1 Demo Day, Sprint 2 Kick-off</li> <li><code>SP02 - Sprint</code> Sprint 02 - Two Polished Stories End-to-End Due: Mon 04/28</li> </ul>"},{"location":"#sprint-1-end-to-end-code-prototype-sprint","title":"Sprint 1: End-to-End Code Prototype Sprint","text":""},{"location":"#fri-0411","title":"Fri 04/11","text":"<ul> <li><code>MT31 - Meeting</code> Sprint 1 Working Day</li> </ul>"},{"location":"#wed-0409","title":"Wed 04/09","text":"<ul> <li><code>QZ02 - Quiz</code> Quiz 2 - Front-end Concerns</li> </ul>"},{"location":"#mon-0407","title":"Mon 04/07","text":"<ul> <li><code>MT30 - Meeting</code> Entities and Demo Data</li> <li><code>SP01 - Sprint</code> Sprint 01 - End-to-End Code Prototype Sprint - Week 1 Due: Sun 04/13</li> </ul>"},{"location":"#fri-0404","title":"Fri 04/04","text":"<ul> <li><code>MT29 - Meeting</code> Secrets, Env Vars, and OpenAI</li> </ul>"},{"location":"#wed-0402","title":"Wed 04/02","text":"<ul> <li><code>MT28 - Meeting</code> XL Code Tour and Working Time</li> <li><code>RD33 - Reading</code> Authentication and Authorization on CSXL.unc.edu Due: Thu 04/02</li> </ul>"},{"location":"#mon-0331","title":"Mon 03/31","text":"<ul> <li><code>MT27 - Meeting</code> SP00 Demo Day and SP01 Kick-off</li> <li><code>SP00 - Sprint</code> Sprint 00 Submissions Individual and Team Due: Mon 03/31</li> <li><code>SP01 - Sprint</code> Sprint 01 - End-to-End Code Prototype Sprint - Week 0 Due: Sun 04/06</li> <li><code>RD32 - Reading</code> Introduction to Angular Widgets on CSXL.unc.edu  Due: Tue 04/01</li> </ul>"},{"location":"#sprint-0-agile-project-planning","title":"Sprint 0: Agile Project Planning","text":""},{"location":"#fri-0328","title":"Fri 03/28","text":"<ul> <li><code>MT26 - Meeting</code> Project Boards</li> <li><code>RD31 - Reading</code> Google's Engineering Practices: Code Review Due: Sun 3/30</li> </ul>"},{"location":"#wed-0326","title":"Wed 03/26","text":"<ul> <li><code>MT25 - Meeting</code> Career Planning</li> <li><code>RD30 - Reading</code> Team Repo Setup Due: Thu 3/26</li> </ul>"},{"location":"#mon-0324","title":"Mon 03/24","text":"<ul> <li><code>MT24 - Meeting</code> Interactive Prototypes</li> <li><code>SP00 - Sprint</code> Sprint 0 - Week 1 - Interactive Prototypes and API Scaffolding Due: Sun 3/30</li> </ul>"},{"location":"#fri-0321","title":"Fri 03/21","text":"<ul> <li><code>MT23 - Meeting</code> Figma and Epic Working Day</li> <li><code>RD28 - Reading</code> SQLAlchemy Tutorial 0-2 Due: Sun 3/23</li> <li><code>RD29 - Reading</code> SQLAlchemy Tutorial 3-5 Due: Tue 3/25</li> </ul>"},{"location":"#wed-0319","title":"Wed 03/19","text":"<ul> <li><code>MT22 - Meeting</code> Wireframes</li> <li><code>RD26 - Reading</code> CSXL Dev Env Setup Due: Thu 3/20</li> <li><code>RD27 - Reading</code> Wireframes Due: Thu 3/20</li> </ul>"},{"location":"#mon-0317","title":"Mon 03/17","text":"<ul> <li><code>MT21 - Meeting</code> Final Project Kick-off</li> <li><code>RD24 - Reading</code> Agile Epics Due: Tue 3/18</li> <li><code>RD25 - Reading</code> Agile Stories Due: Tue 3/18</li> <li><code>SP00 - Sprint</code> - First Sprint of Final Project<ul> <li>Final Project Teams</li> <li>Sprint 0 - Call for Proposals</li> <li>Sprint 0 - Write an Epic Due: Sun 3/23</li> </ul> </li> </ul>"},{"location":"#frontend-concerns-scripting-styling-and-structure","title":"Frontend Concerns: Scripting, Styling, and Structure","text":""},{"location":"#fri-0307","title":"Fri 03/07","text":"<ul> <li><code>MT20 - Meeting</code> Intentional Debugging Strategies</li> </ul>"},{"location":"#wed-0305","title":"Wed 03/05","text":"<ul> <li><code>MT19 - Meeting</code> Metaprogramming with Decorators and <code>@Annotations</code></li> </ul>"},{"location":"#mon-0303","title":"Mon 03/03","text":"<ul> <li><code>MT18 - Meeting</code> Syntactic Sugar: Destructuring, Rest, and Spread</li> <li><code>RD23 - Reading</code> Introduction to SQL Due: Tue 3/04</li> </ul>"},{"location":"#fri-0228","title":"Fri 02/28","text":"<ul> <li><code>MT17 - Meeting</code> More Closures</li> <li><code>RD21 - Reading</code> Angular Routing Due: Sun 3/02</li> <li><code>RD22 - Reading</code> RxJS Observables Due: Sun 3/02</li> <li><code>EX02 - Exercise</code> Front-end with Angular Due: Fri 3/07</li> </ul>"},{"location":"#wed-0226","title":"Wed 02/26","text":"<ul> <li><code>MT16 - Meeting</code> Lexical Closures</li> <li><code>RD20 - Reading</code> Angular Introduction Due: Thu 2/27</li> </ul>"},{"location":"#mon-0224","title":"Mon 02/24","text":"<ul> <li><code>MT15 - Meeting</code> Higher-order Functions</li> <li><code>RD19 - Reading</code> MDN Introduction to HTML and CSS Due: Tue 2/25</li> </ul>"},{"location":"#fri-0221","title":"Fri 02/21","text":"<ul> <li><code>MT14 - Meeting</code> Front-end Tooling</li> <li><code>RD16 - Reading</code> Web Client Platform Background: JavaScript Due: Sun 2/23</li> <li><code>RD17 - Reading</code> TypeScript for the 301 Java Developer Due: Sun 2/23</li> <li><code>RD18 - Reading</code> Event-Driven Programming in TypeScript </li> </ul>"},{"location":"#wed-0219","title":"Wed 02/19","text":"<ul> <li><code>SN00 - Snow Day</code> </li> </ul>"},{"location":"#backend-concerns-api-fundamentals-and-testing","title":"Backend Concerns: API Fundamentals and Testing","text":""},{"location":"#mon-0217","title":"Mon 02/17","text":"<ul> <li><code>MT13 - Meeting</code> CI/CD Tutorial</li> </ul>"},{"location":"#fri-0214","title":"Fri 02/14","text":"<ul> <li><code>MT12 - Meeting</code> Pairing time for EX01</li> </ul>"},{"location":"#wed-0212","title":"Wed 02/12","text":"<ul> <li><code>MT11 - Meeting</code> Implementing EX01 with a Service Layer</li> <li><code>RD15 - Reading</code> Introduction to Testing - Due: Thu 2/13</li> <li><code>EX01 - Exercise</code> Phase 2. API Implementation - Due: Fri 2/21</li> </ul>"},{"location":"#fri-0207","title":"Fri 02/07","text":"<ul> <li><code>QZ01 - Quiz</code></li> <li><code>RD13 - Reading</code> Layered Architecture - Due: Tue 2/11</li> <li><code>RD14 - Reading</code> Dependency Injection - Due: Tue 2/11</li> </ul>"},{"location":"#wed-0205","title":"Wed 02/05","text":"<ul> <li><code>MT10 - Meeting</code> HTTP API Case Study</li> </ul>"},{"location":"#mon-0203","title":"Mon 02/03","text":"<ul> <li><code>MT09 - Meeting</code> Input Validation</li> <li><code>RD12 - Reading</code> FastAPI Query Validation and Dynamic Path Validation - Due: Tue 2/4</li> </ul>"},{"location":"#fri-0131","title":"Fri 01/31","text":"<ul> <li><code>MT08 - Meeting</code> API Design Exercise</li> <li><code>RD11 - Reading</code> On Pair Programming - Due: Sun 2/2</li> <li><code>EX01 - Exercise</code> Phase 1. API Design Submission - Due: Thu 2/6</li> <li>QZ01 - Quiz 01 on HTTP APIs - Friday 2/7</li> </ul>"},{"location":"#wed-0129","title":"Wed 01/29","text":"<ul> <li><code>MT07 - Meeting</code> Intermediate <code>git</code> and HTTP Tool Introduction</li> <li><code>EX01 - Exercise</code> EX01 Partner Request Form Due: Wed 1/29</li> <li><code>RD10 - Reading</code> Toward Designing and Formally Specifying APIs - Due: Thu 1/30</li> <li><code>RD10 - Reading</code> FastAPI and Pydantic Tutorial - Due: Thu 1/30</li> </ul>"},{"location":"#toolchain-fundamentals","title":"Toolchain Fundamentals","text":""},{"location":"#mon-0127","title":"Mon 01/27","text":"<ul> <li><code>MT06 - Meeting</code> Containers Continued</li> <li><code>RD08 - Reading</code> On Communication in SDLC and in Systems Parts 0-2 - Due: Tue 1/28</li> <li><code>RD09 - Reading</code> API and HTTP Fundamentals - Due: Tue 1/28</li> </ul>"},{"location":"#fri-0124","title":"Fri 01/24","text":"<ul> <li><code>MT05 - Meeting</code> Modern Development Environments</li> </ul>"},{"location":"#wed-0122","title":"Wed 01/22","text":"<ul> <li><code>MT04 - Meeting</code> Getting Started with EX00</li> <li><code>EX00 - Exercise</code> Collaborating on a Documentation Project - Due: Sun 1/26</li> </ul>"},{"location":"#mon-0120","title":"Mon 01/20","text":"<ul> <li><code>HD00 - Holiday</code> Dr. Martin Luther King, Jr. Holiday</li> </ul>"},{"location":"#fri-0117","title":"Fri 01/17","text":"<ul> <li><code>QZ00 - Quiz</code> git 101 Quiz</li> </ul>"},{"location":"#wed-0115","title":"Wed 01/15","text":"<ul> <li><code>MT03 - Meeting</code> Introducing <code>git</code>'s Remote Commands: Fetch, Pull, and Push</li> </ul> <ul> <li><code>RD06 - Reading</code> Starting a Static Website Project with MkDocs - Due: Tue 1/21 </li> <li><code>RD07 - Reading</code> git Ch04 - Remote Operations: Fetch, Pull, Clone, and Push - Due: Tue 1/21 </li> </ul>"},{"location":"#mon-0113","title":"Mon 01/13","text":"<ul> <li><code>MT02 - Meeting</code> Modern Source Code Management (SCM) with <code>git</code></li> <li><code>RD05 - Reading</code> git Ch03 - Branching and Merging - Due: Tue 1/14 </li> <li><code>QZ00 - Quiz</code> Git 101: Ch 0, Ch 1, Ch 2, Ch 3 - On: Fri 1/17</li> </ul>"},{"location":"#orientation","title":"Orientation","text":""},{"location":"#fri-0110","title":"Fri 01/10","text":"<ul> <li><code>MT01 - Meeting</code> Software Development Lifecycle</li> <li><code>RD02 - Reading</code> git Ch00 - What is Source Code Manageement? - Due: Sun 1/12 </li> <li><code>RD03 - Reading</code> git Ch01 - Core Concepts of a <code>git</code> Repository  - Due: Sun 1/12 </li> <li><code>RD04 - Reading</code> git Ch02 - Fundamental <code>git</code> Subcommands - Due: Sun 1/12 </li> </ul>"},{"location":"#wed-0108","title":"Wed 01/08","text":"<ul> <li><code>MT00 - Meeting</code> Welcome to COMP423</li> <li><code>RD00 - Reading</code> Syllabus - Due: Thu 1/09</li> <li><code>RD01 - Reading</code> Personal Character, McConnel - Due: Thu 1/09 <ul> <li>RD01 is Chapter 30 from Steve McConnell's Code Complete. The PDF is found on Canvas Reserves, respond to GRQs on Gradescope.</li> </ul> </li> <li>Install Docker Desktop and be sure you can run <code>docker run hello-world</code> - Due: Sun 1/12 </li> </ul>"},{"location":"demo_markdown/","title":"Demo Markdown","text":"<p>For full documentation visit mkdocs.org.</p>"},{"location":"demo_markdown/#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"demo_markdown/#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"demo_markdown/#code-snippets","title":"Code Snippets","text":"<p>The following code snippet demonstrates line numbering as well as adding callout notes.</p> <pre><code>foo: string = \"bar\"\nfor i in range(1, 3):\n    print(i)  # (1)!\n\ndef f() -&gt; int:\n    return 42\n</code></pre> <ol> <li> printing <code>i</code> will result in <code>1</code>, <code>2</code>, and then the loop completes</li> </ol>"},{"location":"demo_markdown/#example-of-pulling-code-snippets-from-a-file-and-highlighting","title":"Example of pulling code snippets from a file (and highlighting)","text":"<ul> <li><code>linenums</code> is where line numbering starts from</li> <li><code>title</code> is added above the block of code to describe content</li> <li><code>hl_lines</code> is optional and can highlight specific lines of code (offset from 1, regardless of line numbering start)</li> </ul> foo.py<pre><code>def f() -&gt; int:\n    \"\"\"A simple function.\"\"\"\n    return 42\n</code></pre>"},{"location":"demo_markdown/#graphics-with-mermaid-to-be-explored","title":"Graphics with <code>mermaid</code> (to be explored)","text":"<pre><code>sequenceDiagram\n    participant WorkingDir as Working Directory\n    participant Changed as Changed\n    participant Staged as Staged\n    participant Committed as Commit\n\n    WorkingDir -&gt;&gt; Changed: Modify File\n    Changed -&gt;&gt; Staged: git add\n    Staged -&gt;&gt; Committed: git commit\n    Changed -&gt;&gt; WorkingDir: git restore &lt;file&gt;\n    Staged -&gt;&gt; Changed: git restore --staged &lt;file&gt;\n    Committed -&gt;&gt; WorkingDir: git checkout &lt;commit&gt; &lt;file&gt;</code></pre> Method Description <code>GET</code>      Fetch resource <code>PUT</code>  Update resource <code>DELETE</code>      Delete resource Date Topic Links W 1/9 Welcome to COMP423 F 1/11 git Repositories CC++ <pre><code>#include &lt;stdio.h&gt;\n\nint main(void) {\n  printf(\"Hello world!\\n\");\n  return 0;\n}\n</code></pre> <pre><code>#include &lt;iostream&gt;\n\nint main(void) {\n  std::cout &lt;&lt; \"Hello world!\" &lt;&lt; std::endl;\n  return 0;\n}\n</code></pre> <p>Note</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p>"},{"location":"meetings/2025_01_08/","title":"01/08. MT00 - Welcome to COMP423","text":"<p>We are looking forward to kicking off a new semester with you all!</p>"},{"location":"meetings/2025_01_08/#lecture-materials","title":"Lecture Materials","text":"<ul> <li> MT00 - Welcome to COMP423 Lecture Slides</li> </ul>"},{"location":"meetings/2025_01_08/#deadlines","title":"Deadlines","text":"<ul> <li>Due: Thu 1/09 <code>RD00 - Reading</code> Syllabus </li> <li>Due: Thu 1/09 <code>RD01 - Reading</code> Personal Character, McConnell <ul> <li>RD01 is Chapter 30 from Steve McConnell's Code Complete. The PDF is found on Canvas Reserves, respond to GRQs on Gradescope.</li> </ul> </li> <li>Due: Sun 1/12 Install Docker Desktop and be sure you can run <code>docker run hello-world</code></li> </ul>"},{"location":"meetings/2025_01_10/","title":"01/10. MT01 - Software Development Lifecycle","text":"<p>We are looking forward to kicking off a new semester with you all!</p>"},{"location":"meetings/2025_01_10/#lecture-materials","title":"Lecture Materials","text":"<ul> <li> Slides - MT01 - Software Development Lifecycle</li> <li> Recording - MT01 - Software Development Lifecycle</li> </ul>"},{"location":"meetings/2025_01_10/#deadlines","title":"Deadlines","text":"<ul> <li><code>RD02 - Reading</code> git Ch00 - What is Source Code Management? - Due: Sun 1/12 </li> <li><code>RD03 - Reading</code> git Ch01 - Core Concepts of a <code>git</code> Repository  - Due: Sun 1/12 </li> <li><code>RD04 - Reading</code> git Ch02 - Fundamental <code>git</code> Subcommands - Due: Sun 1/12 </li> </ul>"},{"location":"meetings/2025_01_13/","title":"01/13. MT02 - Big Ideas in <code>git</code>","text":""},{"location":"meetings/2025_01_13/#lecture-materials","title":"Lecture Materials","text":"<ul> <li> Slides - MT02 - Big Ideas in <code>git</code></li> <li> Recording - MT02 - Big Ideas in <code>git</code></li> </ul>"},{"location":"meetings/2025_01_13/#deadlines","title":"Deadlines","text":"<ul> <li><code>RD05 - Reading</code> git Ch03 - Branching and Merging - Due: Tue 1/14 </li> <li><code>QZ00 - Quiz</code> Git 101: Ch 0, Ch 1, Ch 2, Ch 3 - On: Fri 1/17</li> </ul>"},{"location":"meetings/2025_01_15/","title":"01/15. MT03 - Introducing <code>git</code>'s Remote Commands: Fetch, Pull, and Push","text":""},{"location":"meetings/2025_01_15/#lecture-materials","title":"Lecture Materials","text":"<ul> <li> Slides - MT03 - Introducing <code>git</code>'s Remote Commands: Fetch, Pull, and Push</li> <li> Recording - MT03 - Introducing <code>git</code>'s Remote Commands: Fetch, Pull, and Push</li> </ul>"},{"location":"meetings/2025_01_15/#deadlines","title":"Deadlines","text":"<ul> <li><code>QZ00 - Quiz</code> Submit Partner Preference for QZ00 and EX00 - Due: Wed 1/15 at 5pm</li> <li><code>QZ00 - Quiz</code> Git 101: Ch 0, Ch 1, Ch 2, Ch 3 - On: Fri 1/17</li> <li><code>RD06 - Reading</code> Starting a Static Website Project with MkDocs - Due: Tue 1/21 </li> <li><code>RD07 - Reading</code> git Ch04 - Remote Operations: Fetch, Pull, and Push - Due: Tue 1/21 </li> </ul>"},{"location":"meetings/2025_01_22/","title":"01/22. MT04 - Getting Started with ex00","text":""},{"location":"meetings/2025_01_22/#lecture-materials","title":"Lecture Materials","text":"<ul> <li> Slides - MT04 - Getting Started with EX00</li> <li> Recording - MT04 - Getting Started with EX00</li> </ul>"},{"location":"meetings/2025_01_22/#deadlines","title":"Deadlines","text":"<ul> <li><code>EX00 - Exercise</code> Collaborating on Technical Documentation - Due: Sun 1/26</li> </ul>"},{"location":"meetings/2025_01_24/","title":"01/24. MT05 - Modern Development Environments","text":""},{"location":"meetings/2025_01_24/#lecture-materials","title":"Lecture Materials","text":"<ul> <li> Slides - MT05 - Modern Development Environments</li> <li> Recording - MT05 - Modern Development Environments</li> </ul>"},{"location":"meetings/2025_01_24/#deadlines","title":"Deadlines","text":"<ul> <li><code>EX00 - Exercise</code> Collaborating on Technical Documentation - Due: Sun 1/26</li> </ul>"},{"location":"meetings/2025_01_27/","title":"01/27. MT06 - Containers Continued","text":""},{"location":"meetings/2025_01_27/#lecture-materials","title":"Lecture Materials","text":"<ul> <li> Slides - MT06 - Containers Continued</li> <li> Recording - MT05 - Modern Development Environments</li> </ul>"},{"location":"meetings/2025_01_27/#deadlines","title":"Deadlines","text":"<ul> <li><code>RD08 - Reading</code> On Communication in SDLC and in Systems Parts 0-2 - Due: Tue 1/28</li> <li><code>RD09 - Reading</code> API and HTTP Fundamentals - Due: Tue 1/28</li> </ul>"},{"location":"meetings/2025_01_29/","title":"01/29. MT07 - Intermediate <code>git</code> and HTTP Tool Introduction","text":""},{"location":"meetings/2025_01_29/#lecture-materials","title":"Lecture Materials","text":"<ul> <li> Slides - MT07 - Intermediate <code>git</code> and HTTP Tool Introduction</li> <li> Recording - MT07 - Intermediate <code>git</code> and HTTP Tool Introduction</li> </ul>"},{"location":"meetings/2025_01_29/#deadlines","title":"Deadlines","text":"<ul> <li><code>RD10 - Reading</code> Toward Designing and Formally Specifying APIs - Due: Thu 1/30</li> <li><code>RD10 - Reading</code> FastAPI and Pydantic Tutorial - Due: Thu 1/30</li> </ul>"},{"location":"meetings/2025_01_31/","title":"01/31. MT08 - API Design Exercise","text":""},{"location":"meetings/2025_01_31/#lecture-materials","title":"Lecture Materials","text":"<ul> <li> Slides - MT08 - API Design Exercise</li> <li> Recording - MT08 - API Design Exercise</li> </ul>"},{"location":"meetings/2025_01_31/#deadlines","title":"Deadlines","text":"<ul> <li><code>RD11 - Reading</code> On Pair Programming - Due: Sun 2/2</li> <li><code>EX01 - Exercise</code> Part 1. API Design Submission - Due: Wed 2/5</li> <li><code>EX01 - Exercise</code> Part 2. API Implementation - Due: Tue 2/11</li> <li>QZ01 - Quiz 01 on HTTP APIs - Friday 2/7</li> </ul>"},{"location":"meetings/2025_02_03/","title":"02/03. MT09 - Input Validation","text":""},{"location":"meetings/2025_02_03/#lecture-materials","title":"Lecture Materials","text":"<ul> <li> Slides - MT09 - Input Validation</li> <li> Recording - MT09 - Input Validation</li> </ul>"},{"location":"meetings/2025_02_03/#deadlines","title":"Deadlines","text":"<ul> <li><code>RD12 - Reading</code> FastAPI Query Validation and Dynamic Path Validation - Due: Tue 2/4</li> <li><code>EX01 - Exercise</code> Part 1. API Design Submission - Due: Thu 2/6</li> <li>QZ01 - Quiz 01 on HTTP APIs - Friday 2/7</li> <li><code>EX01 - Exercise</code> Part 2. API Implementation - Due: Thu 2/13</li> </ul>"},{"location":"meetings/2025_02_05/","title":"02/05. MT10 - API Case Study","text":""},{"location":"meetings/2025_02_05/#lecture-materials","title":"Lecture Materials","text":"<ul> <li> Slides - MT10 - API Case Study</li> <li> Recording - MT10 - API Case Study</li> </ul>"},{"location":"meetings/2025_02_05/#deadlines","title":"Deadlines","text":"<ul> <li><code>EX01 - Exercise</code> Part 1. API Design Submission - Due: Thu 2/6</li> <li>QZ01 - Quiz 01 on HTTP APIs - Friday 2/7</li> <li><code>EX01 - Exercise</code> Part 2. API Implementation - Due: Thu 2/13</li> </ul>"},{"location":"meetings/2025_02_12/","title":"02/12. MT11 - API Case Study","text":""},{"location":"meetings/2025_02_12/#lecture-materials","title":"Lecture Materials","text":"<ul> <li> Slides - MT11 - Implementing EX01 with a Service Layer</li> <li> Recording - MT11 - Implementing EX01 with a Service Layer</li> </ul>"},{"location":"meetings/2025_02_12/#deadlines","title":"Deadlines","text":"<ul> <li><code>RD15 - Reading</code> Introduction to Testing - Due: Thu 2/13</li> </ul>"},{"location":"meetings/2025_02_14/","title":"02/14. MT12 - Pairing time for EX01","text":""},{"location":"meetings/2025_02_14/#lecture-materials","title":"Lecture Materials","text":"<ul> <li> Slides - MT12 - Pairing time for EX01</li> <li> Recording - MT12 - Pairing time for EX01</li> </ul>"},{"location":"meetings/2025_02_17/","title":"02/17. MT13 - CI/CD Tutorial","text":""},{"location":"meetings/2025_02_17/#lecture-materials","title":"Lecture Materials","text":"<ul> <li> Slides - MT13 - CI/CD Tutorial</li> <li> Recording - MT13 - CI/CD Tutorial</li> </ul>"},{"location":"meetings/2025_02_21/","title":"02/21. MT14 - Front-end Tooling","text":""},{"location":"meetings/2025_02_21/#lecture-materials","title":"Lecture Materials","text":"<ul> <li> Slides - MT14 - CI/CD Tutorial</li> <li> Recording - MT14 - CI/CD Tutorial</li> </ul>"},{"location":"meetings/2025_02_24/","title":"02/24. MT15 - Higher-order Functions","text":""},{"location":"meetings/2025_02_24/#lecture-materials","title":"Lecture Materials","text":"<ul> <li> Slides - MT15 - Higher-order Functions</li> <li> Recording - MT15 - Higher-order Functions</li> </ul>"},{"location":"meetings/2025_02_24/#reading","title":"Reading","text":"<ul> <li><code>RD19 - Reading</code> MDN Introduction to HTML and CSS Due: Tue 2/25</li> </ul>"},{"location":"meetings/2025_02_26/","title":"02/26. MT16 - Lexical Closures","text":""},{"location":"meetings/2025_02_26/#lecture-materials","title":"Lecture Materials","text":"<ul> <li> Slides - MT16 - Lexical Closures</li> <li> Recording - MT16 - Lexical Closures</li> </ul>"},{"location":"meetings/2025_02_28/","title":"02/28. MT17 - Lexical Closures","text":""},{"location":"meetings/2025_02_28/#lecture-materials","title":"Lecture Materials","text":"<ul> <li> Slides - MT17 - More Closures</li> <li> Recording - MT17 - More Closures</li> </ul>"},{"location":"meetings/2025_02_28/#deadlines","title":"Deadlines","text":"<ul> <li><code>RD21 - Reading</code> Angular Routing Due: Sun 3/02</li> <li><code>RD22 - Reading</code> RxJS Observables Due: Sun 3/02</li> <li><code>EX02 - Exercise</code> Front-end with Angular Due: Fri 3/07</li> </ul>"},{"location":"meetings/2025_03_03/","title":"03/03. MT18 - Syntactic Sugar: Destructuring, Rest, and Spread","text":""},{"location":"meetings/2025_03_03/#lecture-materials","title":"Lecture Materials","text":"<ul> <li> Slides - MT18 - Syntactic Sugar</li> <li> Recording - MT18 - Syntactic Sugar</li> </ul>"},{"location":"meetings/2025_03_03/#deadlines","title":"Deadlines","text":"<ul> <li><code>RD23 - Reading</code> SQL 101 Due: Tue 3/04</li> </ul>"},{"location":"meetings/2025_03_05/","title":"03/05. MT19 - Metaprogramming with Decorators and @Annotations","text":""},{"location":"meetings/2025_03_05/#lecture-materials","title":"Lecture Materials","text":"<ul> <li> Slides - MT19 - Metaprogramming</li> <li> Recording - MT19 - Metaprogramming</li> </ul>"},{"location":"meetings/2025_03_07/","title":"03/07. MT20 - Debugging Strategies","text":""},{"location":"meetings/2025_03_07/#lecture-materials","title":"Lecture Materials","text":"<ul> <li> Slides - MT20 - Debugging Strategies</li> <li> Recording - MT20 - Debugging Strategies</li> </ul>"},{"location":"meetings/2025_03_17/","title":"03/17. MT21 - Final Project Kick-off","text":""},{"location":"meetings/2025_03_17/#lecture-materials","title":"Lecture Materials","text":"<ul> <li> Slides - MT21 - Final Project Kick-off</li> <li> Recording - MT21 - Final Project Kick-off</li> </ul>"},{"location":"meetings/2025_03_17/#deadlines","title":"Deadlines","text":"<ul> <li><code>RD24 - Reading</code> Agile Epics Due: Tue 3/18</li> <li><code>RD25 - Reading</code> Agile User Stories Due: Tue 3/18</li> <li><code>SP00 - Sprint</code> - First Sprint of Final Project<ul> <li>Final Project Teams</li> <li>Sprint 0 - Call for Proposals</li> <li>Sprint 0 - Write an Epic Due: Sun 3/23</li> </ul> </li> </ul>"},{"location":"meetings/2025_03_19/","title":"03/19. MT22 - Wireframes","text":""},{"location":"meetings/2025_03_19/#lecture-materials","title":"Lecture Materials","text":"<ul> <li> Slides - MT22 - Wireframes</li> <li> Recording - MT22 - Wireframes</li> </ul>"},{"location":"meetings/2025_03_19/#deadlines","title":"Deadlines","text":"<ul> <li><code>RD26 - Reading</code> CSXL Dev Env Setup Due: Thu 3/20</li> <li><code>RD27 - Reading</code> Wireframes Due: Thu 3/20</li> </ul>"},{"location":"meetings/2025_03_21/","title":"03/21. MT23 - Figma &amp; Epic Work Day","text":""},{"location":"meetings/2025_03_21/#lecture-materials","title":"Lecture Materials","text":"<ul> <li> Slides - MT23 - Figma &amp; Epic Work Day</li> <li> Recording - MT23 - Figma &amp; Epic Work Day</li> </ul>"},{"location":"meetings/2025_03_21/#deadlines","title":"Deadlines","text":"<ul> <li><code>RD28 - Reading</code> SQLAlchemy Tutorial 0-2 Due: Sun 3/23</li> <li><code>RD29 - Reading</code> SQLAlchemy Tutorial 3-5 Due: Tue 3/25</li> </ul>"},{"location":"meetings/2025_03_24/","title":"03/24. MT24 - Interactive Prototypes","text":""},{"location":"meetings/2025_03_24/#lecture-materials","title":"Lecture Materials","text":"<ul> <li> Slides - MT24 - Interactive Prototypes</li> <li> Recording - MT24 - Interactive Prototypes</li> </ul>"},{"location":"meetings/2025_03_24/#deadlines","title":"Deadlines","text":"<ul> <li><code>RD29 - Reading</code> SQLAlchemy Tutorial 3-5 Due: Tue 3/25</li> <li><code>SP00 - Sprint</code> Sprint 0 - Week 1 - Interactive Prototypes and API Scaffolding</li> </ul>"},{"location":"meetings/2025_03_26/","title":"03/26. MT25 - Career Planning","text":""},{"location":"meetings/2025_03_26/#lecture-materials","title":"Lecture Materials","text":"<ul> <li> Slides - MT26 - Career Planning</li> </ul>"},{"location":"meetings/2025_03_26/#deadlines","title":"Deadlines","text":"<ul> <li><code>RD30 - Reading</code> Team Repo Setup Due: Thu 3/26</li> </ul>"},{"location":"meetings/2025_03_28/","title":"03/28. MT26 - Project Boards","text":""},{"location":"meetings/2025_03_28/#lecture-materials","title":"Lecture Materials","text":"<ul> <li> Slides - MT26 - Project Boards</li> <li> Recording - MT26 - Project Boards</li> </ul>"},{"location":"meetings/2025_03_28/#deadlines","title":"Deadlines","text":"<ul> <li><code>RD31 - Reading</code> Google's Engineering Practices: Code Review</li> </ul>"},{"location":"meetings/2025_03_31/","title":"03/31. MT27 - SP00 Demo Day and SP01 Kick-off","text":""},{"location":"meetings/2025_03_31/#lecture-materials","title":"Lecture Materials","text":"<ul> <li> Slides - MT27 - SP00 Demo Day and SP01 Kick-off</li> <li> Recording - MT27 - SP00 Demo Day and SP01 Kick-off</li> </ul>"},{"location":"meetings/2025_03_31/#deadlines","title":"Deadlines","text":"<ul> <li><code>RD32 - Reading</code> Introduction to Angular Widgets on CSXL.unc.edu</li> </ul>"},{"location":"meetings/2025_04_02/","title":"04/02. MT28 - Code Tour and Working Day","text":""},{"location":"meetings/2025_04_02/#lecture-materials","title":"Lecture Materials","text":"<ul> <li> Slides - MT28 - Code Tour and Working Day</li> <li> Recording - MT28 - Code Tour and Working Day</li> </ul>"},{"location":"meetings/2025_04_02/#deadlines","title":"Deadlines","text":"<ul> <li><code>RD33 - Reading</code> Authentication and Authorization on CSXL.unc.edu Due: Thu 04/02</li> </ul>"},{"location":"meetings/2025_04_04/","title":"04/04. MT29 - Secrets, Env Vars, and OpenAI Integration","text":""},{"location":"meetings/2025_04_04/#lecture-materials","title":"Lecture Materials","text":"<ul> <li> Slides - MT28 - Code Tour and Working Day</li> <li> Recording - MT28 - Code Tour and Working Day</li> </ul>"},{"location":"meetings/2025_04_07/","title":"04/07. MT30 - Entities and Demo Data","text":""},{"location":"meetings/2025_04_07/#lecture-materials","title":"Lecture Materials","text":"<ul> <li> Slides - MT30 - Entities and Demo Data</li> <li> Recording - MT30 - Entities and Demo Data</li> </ul>"},{"location":"meetings/2025_04_07/#due-dates","title":"Due Dates","text":"<ul> <li> <ul> <li><code>SP01 - Sprint</code> Sprint 01 - End-to-End Code Prototype Sprint - Week 1 Due: Sun 04/13</li> </ul> </li> </ul>"},{"location":"meetings/2025_04_14/","title":"04/14. MT32 - Sprint 1 Demo Day, Sprint 2 Kick-off","text":""},{"location":"meetings/2025_04_14/#lecture-materials","title":"Lecture Materials","text":"<ul> <li> Slides - MT32 - Demo Day</li> </ul>"},{"location":"meetings/2025_04_14/#due-dates","title":"Due Dates","text":"<ul> <li><code>SP02 - Sprint</code> Sprint 02 - Two Polished Stories End-to-End Due: Mon 04/28</li> </ul>"},{"location":"meetings/2025_04_16/","title":"04/16. MT33 - Sprint 2 Deployment","text":""},{"location":"meetings/2025_04_16/#lecture-materials","title":"Lecture Materials","text":"<ul> <li> Slides - MT33 - Sprint 2 Deployment</li> <li> Lecture - MT33 - Sprint 2 Deployment</li> </ul>"},{"location":"meetings/2025_04_16/#due-dates","title":"Due Dates","text":"<ul> <li><code>SP02 - Sprint</code> Sprint 02 - Week 0 - Deployment and Progress on 2nd Story Due: Wed 04/23</li> </ul>"},{"location":"meetings/2025_04_21/","title":"04/21. MT34 - Presentation Skills","text":""},{"location":"meetings/2025_04_21/#lecture-materials","title":"Lecture Materials","text":"<ul> <li> Slides - MT34 - Presentation Skills</li> </ul>"},{"location":"meetings/2025_04_23/","title":"04/23. MT35 - Sprint Working Day","text":""},{"location":"meetings/2025_04_23/#lecture-materials","title":"Lecture Materials","text":"<ul> <li> Slides - MT35 - Working Day</li> </ul>"},{"location":"meetings/2025_04_25/","title":"04/25. MT36 - Stack Review","text":""},{"location":"meetings/2025_04_25/#lecture-materials","title":"Lecture Materials","text":"<ul> <li> Slides - MT36 - Working Day</li> </ul>"},{"location":"meetings/2025_04_28/","title":"04/28. MT37 - LDOC","text":""},{"location":"meetings/2025_04_28/#lecture-materials","title":"Lecture Materials","text":"<ul> <li> Slides - MT37 - LDOC</li> <li> Video - MT37 - LDOC</li> </ul>"},{"location":"people/team/","title":"TA Team","text":"<p>COMP423 would not be possible without the substantial contributions of these Undergraduate Teaching Assistants (UTAs):</p> <ul> <li> <p></p> <p>Kiernan Almand</p> </li> <li> <p></p> <p>Mitchell Anderson</p> </li> <li> <p></p> <p>Ife Babarinde</p> </li> <li> <p></p> <p>Alicia Bao</p> </li> <li> <p></p> <p>Bernie Chen</p> </li> <li> <p></p> <p>Benjamin Eldridge</p> </li> <li> <p></p> <p>Katie Fort</p> </li> <li> <p></p> <p>Andrew Lockard</p> </li> <li> <p></p> <p>Embrey Morton</p> </li> <li> <p></p> <p>Shaina Patel</p> </li> <li> <p></p> <p>Sunny Wang</p> </li> <li> <p></p> <p>Amy Xu</p> </li> <li> <p></p> <p>Will Zahrt</p> </li> <li> <p> </p> <p>Alanna Zhang</p> </li> </ul>"},{"location":"people/bios/alanna26_about/","title":"Alanna Zhang","text":"<p>Edited: 2/5/2025</p> <p></p>"},{"location":"people/bios/alanna26_about/#about","title":"About","text":"<p>Hello! My name is Alanna Zhang. I'm a third-year Computer Science major with minors in Data Science and Statistics, and this is my first semester TA-ing for 423. I really enjoyed the collaborative aspect of this course, and my favorite part was working on the final project: an organization roster management system. For fun, I like to doodle and am currently attempting to get better at using colors in digital art.</p>"},{"location":"people/bios/alanna26_about/#projects-links","title":"Projects &amp; Links","text":"<ul> <li>COMP 426 Personal Website</li> <li>GitHub</li> <li>LinkedIn</li> </ul>"},{"location":"people/bios/albao_about/","title":"Alicia Bao","text":""},{"location":"people/bios/albao_about/#about","title":"About","text":"<p>Hi! I'm Alicia Bao, a third-year CS and Sociology major. This is my first semester TAing for 423 and my second semester TAing overall. My project for this course was digital signage (not the one being merged in but shoutout to my team\u2013 Shaina, Daisy, and Sherly!) and it was the first time I had worked in a full stack. </p> <p>Outside of thinking about CS, I love looking at cool data viz projects, updating my Beli, painting, and advocating for an Asian American Studies program at UNC. </p>"},{"location":"people/bios/albao_about/#find-me-at","title":"Find Me At","text":"<ul> <li>Shimpy (Comp 426)</li> <li>LinkedIn</li> <li>Beli (@aliciabao)</li> </ul>"},{"location":"people/bios/alockard_about/","title":"Andrew Lockard","text":"<p>Edited: 3/20/2025</p> <p></p>"},{"location":"people/bios/alockard_about/#about-me","title":"About Me","text":"<p>Hello there! Thanks for taking a peek at my bio! As you may already know, my name is Andrew Lockard. I am from Harrisburg, North Carolina and I am a senior pursuing a Computer Science BS and Applied Mathematics BS. This is my 3rd semester as a ULA with COMP 423. I have a focus on fullstack web development. After graduation, I will be working as a Software Engineering Associate Consultant with CapTech in Washington D.C!</p> <p>Other than computer science, I enjoy working out, hiking/backpacking, going to concerts, hanging with friends, and watching UNC Basketball. In my spare time I also like to cook fun meals, play cards, and watch funny cartoons.</p> <p>Feel free to connect with me and ask me any questions abour projects, software engineering, or anything else that might pique your interest. I'm looking forwaard to meeting you all!</p>"},{"location":"people/bios/alockard_about/#where-to-find-me","title":"Where to Find Me","text":"<ul> <li>LinkedIn</li> <li>Github</li> </ul>"},{"location":"people/bios/amitche_about/","title":"Mitchell Anderson","text":"<p>Edited: 3/5/2025</p> <p></p>"},{"location":"people/bios/amitche_about/#about-me","title":"About Me","text":"<p>Hi everyone! Thanks for checking out my bio! As you may already know, my name is Mitchell Anderson. I am from Winston Salem, North Carolina and I am a junior  pursuing a Computer Science BS and minors in both Math and Economics. This is my 3rd semester as a ULA and my 1st semester with COMP 423. I have a focus on fullstack web development. Last summer I completed a fullstack software engineering internship in Santa Clara, California at a tech company called ServiceNow.</p> <p>Other than computer science, I enjoy working out, mountain biking, skiing, hanging with friends, and watching UNC Basketball. I also enjoy a good fortnite game from time to time. </p> <p>Feel free to connect with me and ask me any questions abour projects, software engineering, or anything else that might pique your interest. I'm looking forwaard to meeting you all!</p>"},{"location":"people/bios/amitche_about/#where-to-find-me","title":"Where to Find Me","text":"<ul> <li>LinkedIn</li> <li>Github</li> </ul>"},{"location":"people/bios/axu1_about/","title":"Amy Xu","text":""},{"location":"people/bios/axu1_about/#about-me","title":"About Me","text":"<p>Hello! I am a junior from New Jersey graduating with CS and Statistics B.S. degrees. I took Kris's 423 last semester and had a fantastic time learning about software engineering, but also about the teaching and collaboration process. I worked on the organization roster feature with Alanna. This will be my sole experience TA-ing, but I have held other leadership/teaching positions in various clubs.</p> <p>Namely, I am active in the Game Development Club (game development), CS for Social Good (web app development/consulting), and Chapel Thrill Escapes (on-campus escape room). I am also currently working part-time at SAS (started summer 2024) as a frontend developer. I would be happy to help out or talk to you about any of these experiences - just email me or find a way to contact me somehow.</p> <p>Outside of CS activities, I frequent BeaM's Murray wood shop and make various crafts. I also enjoy practicing piano/recorder, growing herbs, and developing/playing games for fun. I enjoy playing rhythm games and developing RPG games the most!</p>"},{"location":"people/bios/axu1_about/#where-to-find-me","title":"Where to Find Me","text":"<ul> <li>itch.io I've made over 10 small games for game jams, and more are on the way!</li> <li>Github I sometimes publish my game code after a jam.</li> <li>LinkedIn I barely use LinkedIn.</li> </ul>"},{"location":"people/bios/benjaben_about/","title":"Benjamin Eldridge","text":"<p>Edited 3/26/2025</p> <p></p>"},{"location":"people/bios/benjaben_about/#about","title":"About","text":"<p>Hey, my name is Benjamin, I'm a senior majoring in Computer Science and Mathematics from Oak Island, NC. This is my first semester as a COMP 423 TA, although you may recognize me as a longtime COMP 110 TA. This class was super useful for me to learn about full-stack development in general as well as how to work well in a team on a large coding project. Outside of this class I enjoy cryptography, hardware security, and other systems and theoretical topics in computer science. I hope to be pursuing a master's degree in CS at UNC next year!</p> <p>For fun, I am a huge card games guy and the games I play include MTG, Balatro, and recently Slay the Spire. I also follow the NBA and NFL pretty closely, especially to see how former UNC players are doing. Feel free to connect via the links below, and I hope you all enjoy the class!</p>"},{"location":"people/bios/benjaben_about/#projects-links","title":"Projects &amp; Links","text":"<ul> <li>GitHub</li> <li>LinkedIn</li> </ul>"},{"location":"people/bios/bscc_about/","title":"Bernie Chen","text":""},{"location":"people/bios/bscc_about/#about-me","title":"About Me","text":"<p>Hello! I'm a fourth-year double majoring in Computer Science (BS) and Business, with a minor in Math. I'm an international student from Toronto, Canada, and this is my first semester TAing for 423 - but my 6th semester as a TA for the CS department! I learned so much from taking 423 as a student, and it remains one of my favorite courses at UNC. I've continued to learn even more as a TA, and I'm so glad I had the chance to meet all the amazing people on this team! I definitely recommend becoming a TA if you're interested!</p> <p>Outside of classes, I love traveling and trying new cuisines, hiking, and watching movies. I'm also a big F1 fan (go papaya)!</p> <p>Feel free to connect with me, I'm always looking forward to meeting new people!</p>"},{"location":"people/bios/bscc_about/#where-to-find-me","title":"Where to Find Me","text":"<ul> <li>LinkedIn</li> <li>Github</li> </ul>"},{"location":"people/bios/embreezy_about/","title":"Embrey Morton","text":""},{"location":"people/bios/embreezy_about/#about-me","title":"About Me","text":"<p>What's up everyone, my name is Embrey Morton. I'm a fourth-year Computer Science major as well as a Statistics &amp; Analytics major. This is my first semester as a COMP423 TA, but I was a COMP301 TA for the previous three semesters. I truly enjoyed taking this course, as I met a bunch of cool people, and I learned valuable skills about full-stack development that gave a leg up with previous internships. So, I wanted to join the team to assist future students while further enhancing my knowledge as well. So, I am super grateful for the opportunity to work with you all!</p> <p>Outside of the amazing computer science world, I am a huge sports fanatic. I grew up in Charlotte, NC so I am inevitably a fan of the Charlotte Hornets (sadly) and Carolina Panthers (a bit less sadly as of late thanks to Bryce Young). I'm also a pretty big gamer and I enjoy playing sports games, FPS games, and Marvel Rivals (currently a Grandmaster Loki main). I try to just be a chill guy to be honest.</p>"},{"location":"people/bios/embreezy_about/#where-to-find-me","title":"Where to Find Me","text":"<ul> <li>LinkedIn</li> <li>Github</li> <li>Rivals-Tracker</li> </ul>"},{"location":"people/bios/ifebaba_about/","title":"Ife Babarinde","text":"<p>Pictured: Me and Bolt</p>"},{"location":"people/bios/ifebaba_about/#about","title":"About","text":"<p>Hey! My name is Ife Babarinde and i'm a final-year Computer Science major. This is my first semester TA-ing for 423 and TA-ing in general. I really enjoyed taking this course, so much so that I worked again under Kris for my COMP 523 class! I enjoyed that so much that I decided to return as a TA for this course. In this class, I had the opportunity to meet many other students and build a strong foundation for teamwork and full-stack development. Given that, I'm grateful to be back and look forward to helping in any way I can.</p> <p>CSXL</p> <p>You also may have seen me in the CSXL, where I work as an Ambassador!</p> <p>When I'm not in the XL or Office Hours, I enjoy reading books, watching movies, boxing and playing with my dog!</p>"},{"location":"people/bios/ifebaba_about/#find-me-here","title":"Find Me Here","text":"<ul> <li> <p> Github Check out my stuff here!</p> </li> <li> <p> LinkedIn Connect with me here!</p> </li> <li> <p> Letterboxd Where I judge movies</p> </li> </ul>"},{"location":"people/bios/kiernana_about/","title":"Kiernan Almand","text":"<p>Edited: 3/21/25</p> <p></p>"},{"location":"people/bios/kiernana_about/#about","title":"About","text":"<p>Hello!! My name is Kiernan Almand and I am a Computer Science major and Data Science minor graduating this May. I am from Alexandria, Virginia and while I think it is the greatest city in the world, I also love to travel. In May 2023, I traveled to Copenhagen where I took a COMP 590 course with Kris Jordan and during Spring 2024 I studied at the National University of Singapore!</p> <p>This is my second semester as a TA for 423 and it has been #epic . This class taught me so much when I took it in Fall 2023 and I continue to learn from it every day as a TA.</p> <p>When I am not in office hours, I like to listen to podcasts (5-4, Binchtopia, and Normal Gossip are my favs), do yoga, draw, and drink coffee. </p>"},{"location":"people/bios/kiernana_about/#where-to-find-me","title":"Where to Find Me","text":"<ul> <li>LinkedIn</li> <li>Github</li> </ul>"},{"location":"people/bios/ktcooper_about/","title":"Katie Fort","text":"<p>Edited: 3/4/2025</p> <p></p>"},{"location":"people/bios/ktcooper_about/#about","title":"About","text":"<p>Hi, my name is Katie Fort! I\u2019m a third-year undergraduate student at UNC, majoring in Computer Science (B.S.) with minors in Data Science and Studio Art, focusing on ceramics.</p> <p>This is my first semester as a TA for 423. I took the class in Fall 2024, and it was definitely one of the most applicable CS courses I\u2019ve had at UNC! I\u2019m excited to continue developing the class with Kris and the 423 team this semester.</p> <p>In my free time, I love going on walks, cooking, doing yoga, and reading. I also enjoy hiking and getting outdoors\u2014if you have any great nearby hike recommendations, I\u2019d love to hear them! </p>"},{"location":"people/bios/ktcooper_about/#projects-links","title":"Projects &amp; Links","text":"<ul> <li>LinkedIn</li> <li>GitHub</li> </ul>"},{"location":"people/bios/shainap_about/","title":"Shaina Patel","text":""},{"location":"people/bios/shainap_about/#about","title":"About","text":"<p>Hi, my name is Shaina Patel! I\u2019m a junior double majoring in Computer Science and Linguistics and minoring in Studio Arts. </p> <p>I'm a previous COMP 110 TA and this is my first semester as a COMP 423 TA. By taking COMP 423 I've learned so many industry applicable skills. I really enjoyed the collaborative feature of this class and can't wait for this semester!</p> <p>In my free time I love to cook food, create playlists, run, and crochet!</p>"},{"location":"people/bios/shainap_about/#projects-links","title":"Projects &amp; Links","text":"<ul> <li>LinkedIn</li> <li>Portfolio</li> </ul>"},{"location":"people/bios/wzahrt_about/","title":"Will Zahrt","text":"<p>Edited: 3/5/2025</p> <p></p>"},{"location":"people/bios/wzahrt_about/#about-me","title":"About Me","text":"<p>Howdy! Thanks for checking out my bio! As you may already know, my name is William Zahrt but I go by Will. I am from Morgan Hill, California (Silicon Valley area) and I am a fourth year pursuing both a Computer Science BS and Data Science BS major here at UNC. This is my 5th semester as a ULA and my 3rd semester with COMP 423. I actually took the first version of this 590 with Kris and my final project was a FAQ page for the CSXL (which sadly did not get merged). I am proud to say that I have completed a digital signage feature in tandem with Andrew Lockard (another fellow ULA) this semester. So when you are checking into the CSXL and you see the beautiful TV screen full of useful info just know that I worked on that!</p> <p>Other than computer science, I enjoy working out, biking, knitting, playing board games, and catching dubs in fortnite. I have a 15 year old blind and deaf dog named JoJo who I love with all my heart. I often travel back to the west coast to do backpacking trips with my Eagle Scout buddies from high school as well. </p> <p>I am glad I landed at Chapel Hill though. I'll be here for another year and a half pursuing the BS/MS Computer Science so I'll see y'all around for a couple of semesters to come!</p>"},{"location":"people/bios/wzahrt_about/#where-to-find-me","title":"Where to Find Me","text":"<ul> <li>LinkedIn</li> <li>Github</li> </ul>"},{"location":"people/bios/xsw_about/","title":"Sunny Wang","text":"<p>Edited: 3/4/2025</p> <p></p>"},{"location":"people/bios/xsw_about/#about-me","title":"About Me","text":"<p>Hi there! My name is Sunny Wang. I'm a fourth-year Computer Science major (B.S.) with a double major in Economics and a minor in Business Administration. This is my first semester TA-ing for 423, but actually my seventh (and last) semester TA-ing for the CS department. I'm really grateful for this course for teaching me so many valuable skills that I can apply in industry work. Being a TA is so awesome because I get to deepen my understanding on topics and work with such a wonderful team. One of my favorite parts is definitely hanging out during lectures and answering any questions you may have! In my free time, I like to cook, play racket/paddle sports, watch films, play Bananagrams, and travel. </p> <p>As an out-of-state student, I feel especially grateful to the CS community for bringing so many lovely people into my life. In addition to being a TA, I also serve as a Student Experience Ambassador for the department. Part of our role is to connect with the student body through coffee chats! So if you are interested in chatting with me and grabbing coffee (on us), feel free to schedule one here! </p>"},{"location":"people/bios/xsw_about/#where-to-find-me","title":"Where to Find Me","text":"<ul> <li>LinkedIn</li> <li>Personal Website</li> <li>Letterboxd</li> </ul>"},{"location":"resources/","title":"Resources","text":""},{"location":"resources/#core-content","title":"Core Content","text":"<ul> <li>Backend Architecture and Testing</li> <li>Introduction to HTTP, RESTful APIs, and FastAPI</li> <li>Collaborating with <code>git</code></li> <li>Static Documentation Sites with <code>MkDocs</code></li> </ul>"},{"location":"resources/#exercises","title":"Exercises","text":"<ul> <li>EX00 - Collaborating on Technical Documentation</li> <li>EX01 - API Design with FastAPI</li> <li>EX02 - Angular Front-end</li> </ul>"},{"location":"resources/#course-content","title":"Course Content","text":"<ul> <li>Syllabus</li> <li>Team</li> <li>Playlists</li> </ul>"},{"location":"resources/playlist/","title":"Semester Playlists","text":"<ul> <li>Spotify</li> <li>YouTube</li> </ul>"},{"location":"resources/syllabus/","title":"Course Syllabus","text":""},{"location":"resources/syllabus/#general-course-info","title":"General Course Info","text":"<ul> <li>Title: Foundations of Software Engineering</li> <li>Term: Spring 2025</li> <li>Department: Computer Science (COMP)</li> <li>Course Number: 590-140 (Pilot for 423) </li> <li>Section: 001 In-person MWF - 1:25pm to 2:15pm</li> <li>Instructor: Kris Jordan<ul> <li>E-mail: kris+comp590.25s@cs.unc.edu</li> <li>LinkedIn: https://www.linkedin.com/in/krisjordan/</li> </ul> </li> </ul>"},{"location":"resources/syllabus/#course-description-target-audience-and-prerequisites","title":"Course Description, Target Audience, and Prerequisites","text":"<p>This course introduces students to the fundamentals of Software Engineering. Students gain experience with technical communication, team collaboration, design process, project management methodologies, development and production environment concerns, automation, code review, and so on, with an emphasis on today's best practices and tools.</p> <p>The target audience for this course are Undergraduate Computer Science majors seeking experience in the discipline of software engineering.</p> <p>Pre-requisite Courses: C or better in both COMP301 and COMP211.</p>"},{"location":"resources/syllabus/#goals","title":"Goals","text":"<p>The goal of this course is to prepare you for technical leadership, emphasizing on collaborative designing, implementation, and delivery of human-centered software systems.</p> <ol> <li>Develop healthy habits for lifelong learning in the field through reading, experimentation,  self-reflection, and participation in professional communities.</li> <li>Improve spoken and written technical communications to specific audiences of stakeholders with an emphasis on collaborators.</li> <li>Practice designing, specifying, constructing, verifying, iterating on, and operating production-grade software systems in pairs and small teams following intentional methodologies.</li> </ol>"},{"location":"resources/syllabus/#textbooks-and-resources","title":"Textbooks and Resources","text":"<p>The course web page (https://comp423-25s.github.io/) and Canvas are the primary resources for this course. There is no textbook for this course. We will distribute frequent readings, reference material, and tutorials via the course website and Canvas.</p> <p>Textbooks we will source chapters from, without your needing to purchase any texts, include the following. Each of these books is worth reading in whole and having on your bookshelf as you progress in your software engineering career!</p> <ul> <li>The Mythical Man-month, Fred Brooks</li> <li>Code Complete 2nd Edition, Steve McConnell</li> <li>The Pragmatic Programmer, Dave Thomas and Andrew Hunt</li> <li>Clean Code and Clean Agile, Robert Martin</li> <li>A Philosophy of Software Design, John Ousterhout</li> <li>Understanding Comics, Scott McCloud</li> <li>Conceptual Blockbusting, James L Adams</li> </ul>"},{"location":"resources/syllabus/#disclaimer","title":"Disclaimer","text":"<p>This is a pilot course. The instructor reserves to right to make changes to the syllabus. Any changes will be announced as early as possible. Given the experimental nature of this course, please anticipate changes in the syllabus being far more likely than with established courses of record. Check the course site regularly for updates and announcements!</p>"},{"location":"resources/syllabus/#modality-in-person","title":"Modality: In-person","text":"<p>The most valuable resources in this course are lecture and office hours. Both will be held exclusively in-person; remote participation in lecture is not feasible due to the emphasis on groupwork.</p> <p>Unlike most of the courses in the computer science curriculum, Software Engineering is as much, or more, about interpersonal communication and the methodologies of collaboration as it is about programming and the mastery of neatly defined concepts and skills. You will be working in pairs and teams throughout the semester. Your ability to be an upstanding teammate is critical to your success in this course.</p>"},{"location":"resources/syllabus/#course-requirements-and-policies","title":"Course Requirements and Policies","text":"<p>You should attend all lectures and check the course page for announcements and updates. You should complete all assignments on time.</p> <p>Please show up at least five minutes early to lecture so class can begin promptly at its scheduled start time. Please place your bookbag in the basket beneath your seat.</p>"},{"location":"resources/syllabus/#course-load-expectation","title":"Course Load Expectation","text":"<p>This course is a rigorous introduction to Software Engineering. Communicating with your team mates, reading, designing, self-teaching, and debugging will require significant amounts of time every week. The amount of time you and your team mates spend engaging with course content and projects outside of lecture will significantly impact what you get out of this course. You should expect to spend 3 hours per week on lecture in addition to 9 hours per week outside of lecture working on the course.</p> <p>We DO NOT recommended taking COMP423 in a semester when you are enrolled in 17 or more credit hours.</p>"},{"location":"resources/syllabus/#grading-criteria","title":"Grading Criteria","text":"<p>To do well in this course you must actively participate in lecture, be a professional, responsible, and productive team mate, keep up with the reading, writing, and programming assignments, and produce quality software.</p> <p>Peer evaluations of each team member's individual contributions to the final project will be heavily factored into final grade determinations. If you do not equitably contribute as a team mate in pair work on exercises and team work on the final project, which together represent 60% of your course grade, you may fail the course despite succeeding in the other components.</p> <p>Final grades are calculated with the following weights for each course component:</p> <ul> <li>30% - Project Sprints (SP) / Final Project (FN)<ul> <li>5% SP00 - Sprint 0</li> <li>5% SP01 - Sprint 1</li> <li>10% SP02 - Sprint 2</li> <li>10% for Final Project Presentations and Final Project Hand-in</li> </ul> </li> <li>30% - Homework<ul> <li>15% - (EX) Exercises</li> <li>15% - (RD) Readings &amp; Professional Development</li> </ul> </li> <li>30% - (QZ) Quizzes (Some Fridays, announced by Monday of same week)</li> <li>10% - (MT) Class Meeting Attendance and Participation</li> </ul>"},{"location":"resources/syllabus/#meeting-class-attendance-policy","title":"Meeting (Class Attendance) Policy","text":"<p>Our course adheres to UNC's official policies on Attendance, Grading, and Examination.</p> <p>Each student is permitted to be absent for up to four (4) class meetings without any penalty, prior approval, or instructor notification, regardless of absence type (university approved or otherwise). After four missed lectures, absences will count against your in-class activities and participation grade unless they are university approved absences.</p>"},{"location":"resources/syllabus/#regrade-requests","title":"Regrade Requests","text":"<p>Regrade requests for quizzes and other manually graded assignments are open for 48 hours following the release of the grade. If you missed any of the points on a given assignment, review your work when grades are posted and understand the marks you missed. This will raise your comprehension and mastery of the material. In the event we grade your work improperly, select the specific question on Gradescope and submit a regrade request. If there are multiple questions, submit one request per question. Do not use regrade requests to ask why something is wrong, come work with us in office hours to understand the problem at hand.</p>"},{"location":"resources/syllabus/#late-policies","title":"Late policies","text":"<p>All class meeting assignments will be due by the end of the meeting and handed-in on Gradescope.</p> <p>All assignments, outside of assessments such as quizzes and the final, will have a 10:00pm deadline on their due date.</p> <p>Assignments with 10:00pm deadlines will have late periods. When the late period begins, there is a 2-hour grace period in which no penalty is applied. A 15% late penalty will be applied at the end of the semester. The late period for assignments is 48-hours.</p>"},{"location":"resources/syllabus/#slip-days","title":"Slip Days","text":"<p>To ensure fairness to everyone, as emergencies may arise for anyone, we will drop penalties on up to four late assignments. Priority will go to assignments weighted higher (e.g. exercises ahead of readings). This penalty drop does not impact zeroes, only penalties for assignments handed in late. We expect you to hand everything in!</p>"},{"location":"resources/syllabus/#grading-scale-breakdown","title":"Grading Scale Breakdown","text":"<ul> <li>A: 93-100</li> <li>A-: 90-92</li> <li>B+: 87-89</li> <li>B: 83-86</li> <li>B-: 80-82</li> <li>C+: 77-79</li> <li>C: 73-76</li> <li>C-: 70-72</li> <li>D: 60-69</li> <li>F: 59 or below</li> </ul> <p>In cases of fractional points, grades will be rounded up if greater than 0.4999999999...</p>"},{"location":"resources/syllabus/#office-hour-expectations","title":"Office Hour Expectations","text":"<p>Office hours are a terrific resource for you to get help. We use the CSXL web application for managing Office Hours. You will be automatically enrolled.</p> <p>All of our office hours are held in-person in Sitterson Hall SN136. The up-to-date office hours schedule will be available on the CSXL web application.</p> <p>To ensure that all the UTA staff is able to help students get the help they need, we have instituted the following expectations:</p> <ul> <li> <p>UTAs will help individual students with one ticket for up to a maximum of 20 minutes per day. This limit ensures that more students have access to UTA help and ensures that UTA help does not impede your own learning and self-discovery working through problems on your own or with your teammates. Reasoning critically through problems and working with teammates to discover solutions is not only a valuable skill to develop, but it also makes you a better software engineer, team member, and problem solver.</p> </li> <li> <p>In addition, we expect that students write their CSXL help tickets thoughtfully. Please explain the problem you are having in detail, and what you first tried to fix it. We will help you make progress on the problem you specify in the ticket, but will encourage you to try to reason through other problems if they come up before returning to office hours.</p> </li> </ul>"},{"location":"resources/syllabus/#final-project-presentations","title":"Final Project Presentations","text":"<p>This course centers around a large final project. In lieu of a final exam, we will still meet on the scheduled day of finals, but each group will give group presentations and demonstrations of their feature work completed in the back half of this semester.</p>"},{"location":"resources/syllabus/#final-project-licensing-agreement","title":"Final Project Licensing Agreement","text":"<p>The final project of this course is to work in a team of four on implementing a feature for an MIT Licensed open source software project that serves the students in the Computer Science Department at UNC-Chapel Hill. The hope for final projects is to select the best implemented, documented, and tested features produced by teams in this course and merge them into the production software's code base for future UNC-Chapel Hill computer science students to benefit from. As such, the implementation work you and your team does will be subject to a popular open source license, the MIT License https://opensource.org/licenses/MIT. Of course, per the license, any works merged in will record proper attribution and authorship in order.</p>"},{"location":"resources/syllabus/#honor-code-and-collaboration-policy","title":"Honor Code and Collaboration Policy","text":"<p>Software Engineering is as at least as much, but typically more, about collaboration as it is about individual production. This course will emphasize technical collaboration, team work, community building, and leadership. Group work with peer students enrolled in the course and collaboration with course staff is encouraged unless made explicit otherwise (such as on quizzes and individual projects). The most significant graded portion of this course will be a group-based project. Quizzes are the only course component where collaboration is not permitted.</p> <p>Collaboration on submitted work in this course should cite all collaborators clearly and distinctly.</p> <p>No written text should be generated by an LLM. When we get to final project specifications, LLMs may be used to edit or provide feedback suggestions on your writing. Until then, and especially for personally reflective questions, we want to see your thinking and writing, not a machine's!</p> <p>Any code snippets, derivations, or generated code found or produced through artificial intelligence tools outside of the official documentation for a language, framework, or package, and made use of in your work, should be clearly cited and linked back to with a complete URL. You must understand and be able to explain any code snippet, derivation, or generated code you make use of in your work. For example, you do not need to cite an example usage found in a Python package imported into a project. However, you do need to cite an example usage found in StackOverflow, generated through ChatGPT, Github Co-pilot, or similar sources.</p> <p>Finally, this Spring we are implementing the \"Google Rule.\" As of late 2024, about 20% of code merged in by Google Engineers was written in collaboration with a Large Language Model (like ChatGPT or Gemini). In COMP423, for any given assignment involving code, no more than 20% of the lines added should be written in collaboration with an LLM. If you exceed this limitation, a 50% deduction will be assessed for the assignment for you and your partner or team.</p>"},{"location":"resources/syllabus/#code-review-test","title":"Code Review Test","text":"<p>The instructor reserves the right to, at any time, ask you to submit to a \"code review\" test with me or a TA. We may ask you to meet to explain any line of code or decision made in your program. </p> <p>Using code, even if cited, that you do not understand and cannot explain is intellectually dishonest and a lost learning opportunity for you.</p> <p>Thus, you should be able to comfortably explain the code you hand in for credit. Should you be unable to do so, your grade will be penalized for the assignment in question and you may be taken to honor court depending on the severity of the infraction.</p>"},{"location":"resources/syllabus/#feedback","title":"Feedback","text":"<p>If you have suggestions on how to improve the course or just want to leave some positive, encouraging feedback for the TAs or I, please give us feedback. If you make a suggestion we're able to act on, while we still have time to, we're more than happy to!</p>"},{"location":"resources/syllabus/#diversity-statement","title":"Diversity Statement","text":"<p>The instructor and the undergraduate teaching assistant team value the perspectives of individuals from all backgrounds reflecting the diversity of our students. We broadly define diversity to include race, gender identity, national origin, ethnicity, religion, social class, age, sexual orientation, political background, and physical and learning ability. We strive to make this classroom an inclusive space for all students. Please let us know if there is anything we can do to improve; we appreciate suggestions.</p>"},{"location":"resources/syllabus/#title-ix-resources","title":"Title IX Resources","text":"<p>Any student who is impacted by discrimination, harassment, interpersonal (relationship) violence, sexual violence, sexual exploitation, or stalking is encouraged to seek resources on campus or in the community. Please contact the Director of Title IX Compliance (Adrienne Allison \u2013 Adrienne.allison@unc.edu), Report and Response Coordinators in the Equal Opportunity and Compliance Office (reportandresponse@unc.edu), Counseling and Psychological Services (confidential), or the Gender Violence Services Coordinators (gvsc@unc.edu; confidential) to discuss your specific needs. Additional resources are available at safe.unc.edu.</p>"},{"location":"resources/syllabus/#counseling-and-psychological-services","title":"Counseling and Psychological Services","text":"<p>CAPS is strongly committed to addressing the mental health needs of a diverse student body through timely access to consultation and connection to clinically appropriate services, whether for short or long-term needs. Go to their website: https://caps.unc.edu/ or visit their facilities on the third floor of the Campus Health Services building for a walk-in evaluation to learn more. (source: Student Safety and Wellness Proposal for EPC, Sep 2018)</p>"},{"location":"resources/MkDocs/ex00/","title":"EX00 - Collaborating on Technical Documentation","text":""},{"location":"resources/MkDocs/ex00/#learning-objectives","title":"Learning Objectives","text":"<p>Welcome to your first pair project! This exercise aims to build your skills in several key areas:</p> <ul> <li>Starting Projects: Learn how to create a new project using today\u2019s development tools and be empowered to start your own!</li> <li>Using Technical Documentation: Get better at finding, reading, and using guides and manuals to achieve your goals on your own.</li> <li>Writing Technical Documentation: Improve at writing clear instructions for others on how to do technical tasks.</li> <li>Teamwork with Git: Develop your ability to work with others using git, focusing on how to manage changes and updates in your work effectively.</li> </ul>"},{"location":"resources/MkDocs/ex00/#workflow-expectations","title":"Workflow Expectations","text":"<p>We are prescribing, and grading on, some very specific workflow expectations in this exercise:</p> <ul> <li>All merges in this exercise must produce merge commits, thus always use the <code>--no-ff</code> flag when merging in this exercise. The <code>git merge --no-ff &lt;source-branch&gt;</code> command is short for no fast-forward and produces a merge commit where fast-forwarding was otherwise possible. This is how we will see your history of branch use.</li> <li>Before merging locally, be sure you have pushed your branch to your repository.</li> <li>Only you are permitted to merge into <code>main</code> on your own repository. You can push branches to your partner's repository.</li> <li>We will NOT use Pull Requests yet in order to apply our understanding of <code>git</code>'s fundamental collaboration commands (<code>fetch</code>, <code>branch</code>, <code>switch</code>, <code>merge</code>, <code>pull</code>, and <code>push</code>)</li> </ul>"},{"location":"resources/MkDocs/ex00/#deliverable-overview","title":"Deliverable Overview","text":"<p>You and your partner will work together to produce:</p> <ol> <li>Tutorial Guides (50 points): Each of you will write a tutorial for setting up a basic project from scratch, one of you for the Go programming language and the other for the Rust programming language. You\u2019ll publish your guide on your personal MkDocs site. Your partner will help by reviewing and suggesting improvements to your guide.<ul> <li>20 points - Well fomatted markdown and use of appropriate MkDocs for Material features (e.g. text formatting, bullets/enumerations where meaningful, subheadings, code blocks, and admonitions). Hint: Markdown reference.</li> <li>30 points - Tutorial includes required components (brief intro, git repo setup, dev container setup, initialize a project, add a hello world example, compile and run)</li> </ul> </li> <li>Project Repositories (20 points): Host the starter projects resulting from your tutorials on GitHub and make them public. Project repositories will need a <code>README.md</code> in the root directory that link out to your tutorial on your course notes site.</li> <li>EX00 Git Workflow Adherence (30 points): You will be asked to show how you followed the specific <code>git</code> workflow expectations we have in this exercise. This will be preserved in your <code>git</code> repository's history (e.g. via <code>log</code>) and we will show you how to share it via your GitHub repository. Read Workflow Expectations Above BEFORE Beginning!</li> </ol>"},{"location":"resources/MkDocs/ex00/#tutorial-anti-patterns","title":"Tutorial Anti-patterns","text":"<ul> <li>Besides VSCode, Docker, and git, users should not install any software directly to their host machine. That is the role of the dev container! (Instructions which install Go or Rust to the host machine will be a -25pt penalty.)</li> <li>When compiling Go or Rust in the Dev Container, since it is running Linux, you do not expect to see <code>.exe</code> file extensions anywhere in this project. That is a sign you are running something on the host machine.</li> </ul>"},{"location":"resources/MkDocs/ex00/#initial-setup-partner-repository-access-and-main-ruleset","title":"Initial Setup: Partner Repository Access and <code>main</code> Ruleset","text":"<p>You need to give your partner access to your repository and get access to theirs.</p>"},{"location":"resources/MkDocs/ex00/#setting-up-repository-access","title":"Setting Up Repository Access","text":"<p>Navigate to your <code>comp423-course-notes</code> repository on GitHub (the one you created in the previous tutorial) and follow these steps:</p> <ol> <li>Go to Settings &gt; Collaborators</li> <li>Click \"Add people\"</li> <li>Enter your partner's GitHub username</li> <li>Select their account and send the invitation</li> </ol> <p>Your partner will need to accept the invitation via email or through GitHub's interface before they can contribute to your repository. Make sure you both complete this step before proceeding.</p>"},{"location":"resources/MkDocs/ex00/#protecting-your-repository-with-rulesets","title":"Protecting Your Repository with Rulesets","text":"<p>Even though you've added your partner as a collaborator, you'll want to protect your <code>main</code> branch through a ruleset. Rulesets are GitHub's approach to repository security, allowing you to define who can make what kinds of changes to your codebase. Let's set up a simple one and understand what each setting does.</p> <p>Navigate to your repository's Settings page on GitHub and follow these steps:</p> <ol> <li>Click on \"Rules\" &gt; \"Rulesets\" in the left sidebar under \"Code and automation\"</li> <li>Click \"New ruleset\" &gt; \"New branch ruleset\" to create a ruleset</li> <li>Configure your ruleset with these settings:</li> </ol> <p>Basic Settings:</p> <ul> <li>Name your ruleset <code>main</code> </li> <li>For \"Enforcement status,\" select \"Active\"</li> <li>Bypass list: Add \"Repository admin\" (this is you, the repository owner)</li> <li>Under \"Target branches\" choose \"Add target\" and select \"Include default branch\" (this is <code>main</code>)</li> </ul> <p>Rules:</p> <ul> <li>Enable \"Restrict creations\"</li> <li>Enable \"Restrict updates\"</li> <li>Leave everything else as is. The following two settings should be checked by default:<ul> <li>Enable \"Restrict deletions\"</li> <li>Block force pushes</li> </ul> </li> </ul> <p>Let's understand what each of these settings means and why they're important:</p> <p>Targeting the Default Branch: Your default branch (in your project, this is <code>main</code>) is the primary branch of your repository.</p> <p>Restrict Creations, Updates, and Deletions: These three settings work together to control who can make changes to your default branch. When enabled, only people in the bypass list (in this case, just you) can create new commits on the primary branch, update existing commits, overwrite the branch (force push) or delete the branch entirely.</p> <p>These rules reflect a simplified real-world setup. Your partner can create branches, make changes, and push their branches to share with you - they just can't modify the protected <code>main</code> branch directly. That's your job!</p>"},{"location":"resources/MkDocs/ex00/#cloning-your-partners-repository","title":"Cloning Your Partner's Repository","text":"<p>Since you already have your own repository set up locally from the previous tutorial, you just need to clone your partner's repository. Because both repositories have the same name, you'll want to specify a different directory name when cloning to avoid conflicts. The target directory name is added as an extra command-line argument following the repository URL:</p> <pre><code># Clone your partner's repository with a descriptive directory name\ngit clone https://github.com/&lt;partner&gt;/comp423-course-notes.git partner-notes\n</code></pre> <p>After cloning, open your partner's notes site in the new directory in VS Code and then reopen the workspace in a dev container, just as you did with your own repository in the previous tutorial.</p>"},{"location":"resources/MkDocs/ex00/#pay-attention-to-which-project-you-are-working-on","title":"Pay Attention To Which Project You Are Working On","text":"<p>When working on this exercise, be sure you know whose project repository you are working in! In this exercise each of you owns your own repository and will be practicing contributing to your partner's repository.</p> <p>As a rule of thumb, when returning to work in VS Code, go to your \"File\" menu, \"Open Recent\", and select the directory with \"[Dev Container]\" that you intend to work on. If you're already in it, nothing happens. If you're switching between projects, your the new dev container will open.</p> <p>Finally, it is possible to have both dev containers running simultaneously. However, you cannot have both MkDocs dev servers available simultaneously on the same port. The most straightforward way around this is to start <code>mkdocs serve</code> with the <code>-a</code> (address) flag and provide an alternate port (e.g. <code>mkdocs serve -a localhost:4230</code>). In the event you forget to to do this, Docker will try to avoid the conflict by forwarding a different port on your host machine to your container port. To see these mappings in VS Code, go to the Ports tab (typically next to Terminal) or open up the Command Palatte and search for Focus on Ports View. Look for the forwarded address.</p>"},{"location":"resources/MkDocs/ex00/#direct-git-collaboration-workflow","title":"Direct Git Collaboration Workflow","text":"<p>In this exercise, you will rely on Git's fundamental commands to share and integrate changes. This approach helps you practice your understanding of Git's branching model. Here's the basic flow:</p> <ol> <li>You work on changes in your own repository</li> <li>Your partner clones your repository, makes suggestions in a branch, and they push their branch to your repo</li> <li>You fetch their suggestions locally and switch to their branch to consider the work</li> <li>After reviewing and testing, you merge changes into your <code>main</code> branch (with <code>--no-ff</code> to preserve the history!)</li> <li>You push the updated <code>main</code> branch back to GitHub to deploy your site</li> </ol> <p>This workflow requires careful coordination and communication between team members and a solid understanding of Git's core commands. Let's explore how to use these commands effectively.</p>"},{"location":"resources/MkDocs/ex00/#do-all-of-your-work-in-branches","title":"Do All of Your Work in Branches!","text":"<p>Always create a new branch for work you're about to embark upon:</p> <pre><code># Do you have any uncommitted work?\n#     Yes? Decide what to do with it!\n#     No? Great!\n# Are you on the right starting branch for new work?\n#     No? switch to where you want to branch from (usually main)\n#     Yes? Great!\ngit status\n\n# Create and switch to a new branch with a meaningful name\n# Of course, substitute &lt;meaningful-name&gt; with something... meaningful\ngit switch -c &lt;meaningful-name&gt;\n\n# As you work, commit regularly with meaningful messages\ngit add &lt;directory or file(s)&gt;\ngit commit -m \"&lt;message&gt;\"\n</code></pre>"},{"location":"resources/MkDocs/ex00/#share-your-work","title":"Share Your Work","text":"<p>When ready to share your changes for your partner to check out:</p> <pre><code># Push your meaningfully named branch to GitHub\n# Note: Use the same branch name locally as remotely!\ngit push -u origin &lt;meaningful-name&gt;\n</code></pre> <p>Go convince yourself the branch push worked by opening GitHub, clicking the Branch Dropdown (it should show <code>main</code>) and selecting your branch. Let your partner know the branch you shared by its name and/or by sharing a link directly to the branch on Github.</p>"},{"location":"resources/MkDocs/ex00/#reviewing-partners-work","title":"Reviewing Partner's Work","text":"<p>When your partner has pushed changes for review, open your copy of your partner's dev container project and then:</p> <ol> <li> <p>Fetch the latest changes from the project's repository:    <pre><code>git fetch origin\n</code></pre></p> </li> <li> <p>Switch to the branch they just pushed    <pre><code>git switch &lt;branch-name-partner-pushed&gt;\n</code></pre></p> </li> <li> <p>Review their changes locally, running their tutorial to verify it works. If you'd like to see the specific changes made relative to your <code>main</code> branch, or any other branch, you can use the <code>diff</code> subcommand of <code>git</code>:</p> </li> <li>In the terminal: <code>git diff main</code> - press <code>Space</code> to move forward page-by-page and <code>q</code> to exit. The diff shows additions (in green) and removals (in red).</li> <li> <p>On GitHub: View the branch, look for the Contribute button drop down, click it and select Compare (not Pull Request). You will see a diff of the changes.</p> </li> <li> <p>To make your own suggested edits to their work, go ahead and start a branch:    <pre><code>git switch -c edits/&lt;branch-name-partner-pushed&gt;\n</code></pre></p> </li> <li> <p>Make your changes, add commit(s) with meaningful commit messages, then push your edits:    <pre><code>git push -u origin edits/&lt;branch-name-partner-pushed&gt;\n</code></pre></p> </li> </ol> <p>Let your partner know the name of the branch you pushed edits to their work on.</p>"},{"location":"resources/MkDocs/ex00/#merging-a-partners-changes","title":"Merging a Partner's Changes","text":"<p>Ready to review the edits your partner pushed to your repo? Be sure you have your dev container open, then follow the same steps as reviewing partner work above, but use the branch name they pushed.</p> <p>Once you're ready to merge their work into your branch, or <code>main</code>, or your own work into <code>main</code>, the steps are as you already know with one minor twist: for this exercise, always use the <code>--no-ff</code> flag to preserve the merge history:</p> <pre><code># First, switch to the target branch you're merging into\ngit switch &lt;target branch&gt;\n\n# Best practice: be sure your branch is up-to-date\ngit pull origin &lt;target branch&gt;\n\n# Merge your source branch and force a merge commit \ngit merge --no-ff &lt;source branch being merged in&gt;\n\n# Push the merged changes to GitHub\ngit push origin &lt;target branch&gt;\n</code></pre>"},{"location":"resources/MkDocs/ex00/#class-meeting-04-practice-exchange","title":"Class Meeting 04 - Practice Exchange","text":"<p>Decide which of you will do a tutorial on Go and the other on Rust. If your partner is not in class, you get first dibs on either!</p> <ol> <li>Create and switch to a branch in your project named <code>mt04-setup</code></li> <li>Create a directory named <code>docs/tutorials</code></li> <li>Add a file named <code>docs/tutorials/rust-setup.md</code> or <code>docs/tutorials/go-setup.md</code>, whichever you are going to be working on, with the following contents:    <pre><code># Setting up a dev container for &lt;Insert: Go or Rust depending on which you are doing&gt;\n\n* Primary author: [&lt;Your Name&gt;](https://YourGitHubProfileLink)\n</code></pre></li> <li>Verify your work in your local development server (<code>mkdocs serve</code>)</li> <li>Push the branch to your repo (see Share Your Work above)</li> <li>Let your partner know and they should follow the steps of Reviewing Partner's Work (above)</li> <li>Your partner should create a new branch named <code>edits/mt04-setup</code> and add the following changes to your setup markdown file below the primary author line:    <pre><code>* Reviewer: [&lt;Partner name&gt;](https://PartnerGithubProfileLink)\n</code></pre></li> <li>Your partner should commit and push their branch to your repo</li> <li>You should fetch changes, then switch to their branch and see their contribution</li> <li>You should switch back to your work branch (<code>mt04-setup</code>) and merge their work in with <code>--no-ff</code>. Then push to your <code>mt04-branch</code>.</li> <li>You should switch back to your <code>main</code> branch and merge your work in <code>mt04-setup</code> with <code>--no-ff</code>. Then push your main branch. Your site should publish successfully with these changes!</li> </ol> <p>Review the commit graph history: </p> <ol> <li>In your dev container terminal <code>git log --graph --oneline</code> and notice the merge commits and where branches are.</li> <li>In your GitHub repository, go to the Insights tab, select Network. You should see your commit graph with tags here.</li> </ol> <p>Ultimately, when proving that you are following the workflow expectations with your partner for this assignment, you will submit a screenshot of these graphs as a record of the branches and merges made.</p>"},{"location":"resources/MkDocs/ex00/#assignment-structure","title":"Assignment Structure","text":"<p>You and your partner will each create a tutorial about setting up a new DevContainer project. One of you will focus on Go, while the other will work on Rust. Here's how to organize the work:</p> <ol> <li>Update your <code>mkdocs.yml</code> to include the required markdown features. You can enable whatever other features you would like, too!</li> <li>Write your tutorial in either <code>docs/tutorials/go-setup.md</code> or <code>docs/tutorials/rust-setup.md</code> (one per team mate course notes site)</li> <li>Share your tutorial branch with your team mate, they should follow along and add helpful additions, corrections, or suggestiosn along the way. They will push their brach back to your repo.</li> <li>You iterate off of their pushed branch and incorporate back into your work.</li> <li>You finalize your tutorial and merge into <code>main</code></li> <li>You follow your tutorial from start to finish and publish the resulting repository in a public repo on your GitHub account. Its <code>README.md</code> should link back to your course notes site's tutorial.</li> </ol>"},{"location":"resources/MkDocs/ex00/#required-material-for-mkdocs-features-to-enable","title":"Required Material for MkDocs Features to Enable","text":"<p>Before diving head first into your tutorial, there are a few helpful markdown features to enable in Material for MkDocs with your partner. Find how to enable these on the official website. Hint: try searching! Once you find reference for a particular feature, look at the sidebar for both configuration and usage examples.</p> <p>Start a branch for <code>mkdocs-extensions</code> and enable the following features. After enabling each feature, try adding an example of how to use them in markdown to your tutorial draft.</p> <p>Workflow Expectation: You setup code blocks in the branch. Your partner will check out your work and then incorporate admonitions in a branch off of your branch. You will then be responsible for merging all and pushing. If you've already individually enabled both features, let your partner find another feature to enable on your site (and do the same in exchange)!</p> <ol> <li>Code Blocks - for syntax highlighting of code</li> <li>Admonitions - for useful call-outs to draw attention to ideas or asides</li> </ol>"},{"location":"resources/MkDocs/ex00/#tutorial-content-requirements","title":"Tutorial Content Requirements","text":"<p>Your tutorials should include:</p> <ol> <li>Prerequisites</li> <li>Step-by-step instructions for creating a new Dev Container project for your language</li> <li>Should start from a blank directory and include git initialization</li> <li>Dev Container configuration file explanations</li> <li>Steps to create a new project, write a basic \"Hello COMP423\" program, compile, and run</li> <li>The program's requirement is that it simply prints \"Hello COMP423\" out to standard output</li> </ol> <p>Make use of Material for MkDocs features to enhance your documentation:</p> <ul> <li>Code blocks with syntax highlighting for configuration files and commands</li> <li>Admonitions for important notes and warnings</li> </ul> <p>You can cite and reuse instructions from the 423 MkDocs tutorial if useful.</p>"},{"location":"resources/MkDocs/ex00/#need-help","title":"Need Help?","text":"<ul> <li>If you encounter Git issues, try running <code>git status</code> and <code>git log</code> to understand your current state</li> <li>When in doubt, communicate with your partner about the current state of changes</li> <li>For language-specific questions, consult the official language documentation and Google</li> <li>Go documentation</li> <li>Rust / Cargo documentation</li> </ul> <p>Remember to commit early and often, and always use the <code>--no-ff</code> flag when merging to maintain a clear history of collaboration.</p>"},{"location":"resources/MkDocs/ex00/#go-tutorial-expectations","title":"Go Tutorial Expectations","text":"<ul> <li>Dev container should use a base image from Microsoft (Hint: refer back to the MkDocs tutorial)</li> <li>Be sure the Dev Container Installs the official Go VSCode Plugin (Made by the Go Team at Google)</li> <li>Show the <code>go version</code> subcommand to prove a recent version of Go</li> <li>Use the <code>mod</code> subcommand</li> <li>Use the <code>run</code> subcommand</li> <li>Use the <code>build</code> subcommand (discuss this in the context of COMP211's <code>gcc</code> command), run the built binary directly, and discuss the difference from <code>run</code></li> </ul>"},{"location":"resources/MkDocs/ex00/#rust-tutorial-expectations","title":"Rust Tutorial Expectations","text":"<ul> <li>Dev container should use a base image from Microsoft (Hint: refer back to the MkDocs tutorial)</li> <li>Be sure the Dev Container Installs the official <code>rust-analyzer</code> VSCode plugin by the Rust Programming Language Group</li> <li>Show the <code>rustc --version</code> to prove a recent version of rust</li> <li>Use the <code>cargo new</code> command to create a binary project (use the flag that does not create a new <code>git</code> repository automatically on your behalf: <code>--vcs none</code> (Version Control System))</li> <li>Use the <code>cargo build</code> command and show how to run the built file (discuss in terms of COMP211's <code>gcc</code> command)</li> <li>Use the <code>cargo run</code> subcommand and discuss difference with <code>build</code></li> </ul>"},{"location":"resources/MkDocs/ex00/#_1","title":"EX00 - Collaborating on Technical Documentation","text":""},{"location":"resources/MkDocs/tutorial/","title":"Starting a Static Website Project with MkDocs","text":"<p>Welcome! In this tutorial, you'll learn how to build a static website to organize your course notes using GitHub Pages and the powerful static site generator, Material for MkDocs. By the end of this guide, you'll have a fully functional website hosted online, starting from a blank repository. Along the way, you'll also set up a basic Python development container (dev container) in Visual Studio Code (VS Code) and configure GitHub Actions for continuous integration and deployment (CI/CD) and learn what all of this useful jargon means.</p> <p>Why Material for MkDocs?</p> <p>MkDocs is the de facto documentation site generator for today's most popular, modern Python projects, including a few we'll in this course: FastAPI and Pydantic. Those sites are made and maintained with this documentation tool. Material for MkDocs is one of the most popular themes for MkDocs, offering a sleek design, responsive layout, and tons of features out of the box. As an added endorsement, I, Kris, claim this is the best and easiest to use, static site generator tool I've ever seen. In fact, this course site you're reading right now is built using MkDocs, too! (There's a recursion joke somewhere in here.)</p>"},{"location":"resources/MkDocs/tutorial/#why-this-matters","title":"Why This Matters","text":"<p>Static websites are an essential part of software engineering and open-source projects. Many teams and individuals use them to document software, share knowledge, and create personal portfolios. Learning to build and manage one not only enhances your technical skillset but also sets you up for creating your own portfolio and blogging website.</p>"},{"location":"resources/MkDocs/tutorial/#what-you-will-learn","title":"What You Will Learn","text":"<p>By completing this tutorial, you will:</p> <ul> <li>Set up a basic Python Development Container in VS Code to streamline development.</li> <li>Initialize and configure a GitHub repository for a static site.</li> <li>Use Material for MkDocs to generate a clean, professional website.</li> <li>Deploy your site to GitHub Pages with GitHub Actions for CI/CD.</li> <li>Gain insight into the tools and practices used in open-source and professional software projects.</li> </ul>"},{"location":"resources/MkDocs/tutorial/#prerequisites","title":"Prerequisites","text":"<p>Before we dive in, make sure you have:</p> <ol> <li>A GitHub account: If you don\u2019t have one yet, sign up at GitHub.</li> <li>Git installed: Install Git if you don\u2019t already have it.</li> <li>Visual Studio Code (VS Code): Download and install it from here.</li> <li>Docker installed: Required to run the dev container. Get Docker here.</li> <li>Command-line basics: Your COMP211 command-line knowledge will serve you well here. If in doubt, review the Learn a CLI text!</li> </ol>"},{"location":"resources/MkDocs/tutorial/#part-1-project-setup-creating-the-repository","title":"Part 1. Project Setup: Creating the Repository","text":""},{"location":"resources/MkDocs/tutorial/#step-1-create-a-local-directory-and-initialize-git","title":"Step 1. Create a Local Directory and Initialize Git","text":"<p>(A) Open your terminal or command prompt.</p> <p>(B) Create a new directory for your project. (Note: Of course, if you'd like to organize this tutorial somewhere else on your machine, go ahead and change into that parent directory first. By default this will be in your user's home directory.):</p> <pre><code>mkdir comp423-course-notes\ncd comp423-course-notes\n</code></pre> <p>(C) Initialize a new Git repository:</p> <pre><code>git init\n</code></pre> <p>What is the effect of running the <code>init</code> subcommand?</p> <p>You should know what happens when you run this command at this point in the course! If you do not, please refer back to the chapter on Fundamental git Subcommands.  </p> <p>(D) Create a README file:</p> <pre><code>echo \"# COMP423 Course Notes\" &gt; README.md\ngit add README.md\ngit commit -m \"Initial commit with README\"\n</code></pre>"},{"location":"resources/MkDocs/tutorial/#step-2-create-a-remote-repository-on-github","title":"Step 2. Create a Remote Repository on GitHub","text":"<p>(1) Log in to your GitHub account and navigate to the Create a New Repository page.</p> <p>(2) Fill in the details as follows:</p> <ul> <li>Repository Name: <code>comp423-course-notes</code></li> <li>Description: \"Course notes organized as a static website using Material for MkDocs.\"</li> <li>Visibility: Public</li> </ul> <p>(3) Do not initialize the repository with a README, .gitignore, or license.</p> <p>(4) Click Create Repository.</p>"},{"location":"resources/MkDocs/tutorial/#step-3-link-your-local-repository-to-github","title":"Step 3. Link your Local Repository to GitHub","text":"<p>(1) Add the GitHub repository as a remote:</p> <pre><code>git remote add origin https://github.com/&lt;your-username&gt;/comp423-course-notes.git\n</code></pre> <p>Replace <code>&lt;your-username&gt;</code> with your GitHub username.</p> <p>(2) Check your default branch name with the subcommand <code>git branch</code>. If it's not <code>main</code>, rename it to <code>main</code> with the following command: <code>git branch -M main</code>. Old versions of <code>git</code> choose the name <code>master</code> for the primary branch, but these days <code>main</code> is the standard primary branch name.</p> <p>(3) Push your local commits to the GitHub repository:</p> <pre><code>git push --set-upstream origin main\n</code></pre> <p>Understanding the --set-upstream Flag</p> <ul> <li><code>git push --set-upstream origin main</code>: This command pushes the main branch to the remote repository origin. The <code>--set-upstream</code> flag sets up the main branch to track the remote branch, meaning future pushes and pulls can be done without specifying the branch name and just writing <code>git push origin</code> when working on your local <code>main</code> branch. This long flag has a corresponding <code>-u</code> short flag.</li> </ul> <p>(4) Back in your web browser, refresh your GitHub repository to see that the same commit you made locally has now been pushed to remote. You can use <code>git log</code> locally to see the commit ID and message which should match the ID of the most recent commit on GitHub. This is the result of pushing your changes to your remote repository.</p>"},{"location":"resources/MkDocs/tutorial/#part-2-setting-up-the-development-environment","title":"Part 2. Setting Up the Development Environment","text":""},{"location":"resources/MkDocs/tutorial/#what-is-a-development-dev-container","title":"What is a Development (Dev) Container?","text":"<p>A dev container ensures that your development environment is consistent and works across different machines. At its core, a dev container is a preconfigured environment defined by a set of files, typically leveraging Docker to create isolated, consistent setups for development. Think of it as a \"mini computer\" inside your computer that includes everything you need to work on a specific project\u2014like the right programming language, tools, libraries, and dependencies.</p> <p>Why is this valuable? In the technology industry, teams often work on complex projects that require a specific set of tools and dependencies to function correctly. Without a dev container, each developer must manually set up their environment, leading to errors, wasted time, and inconsistencies. With a dev container, everyone works in an identical environment, reducing bugs caused by \"it works on my machine\" issues. It also simplifies onboarding new team members since they can start coding with just a few steps.</p>"},{"location":"resources/MkDocs/tutorial/#how-are-software-project-dependencies-managed","title":"How are software project dependencies managed?","text":"<p>To effectively manage software dependencies, it's important to understand package and dependency management. In most software projects, you rely on external libraries or packages to save time and leverage work that has already been done by others. Managing these dependencies ensures that your project has access to the correct versions of these libraries, avoiding compatibility issues.</p> <p>In this project, our primary dependency is <code>mkdocs-material</code>, which enables us to build and style our static site. This package is available on PyPi, the Python Package Index, which is a repository of software for the Python programming language. PyPi hosts thousands of free, open source, third-party libraries that developers can use to add functionality to their projects. These libraries are installed using <code>pip</code>, a package manager for Python. Similar tools and repositories exist for other programming languages\u2014like <code>npm</code> for JavaScript, <code>cargo</code> for Rust, or <code>maven</code> for Java.</p> <p>To ensure your dependencies are always correctly installed and available, in standard Python projects relying on <code>pip</code>, requirements are traditionally listed out in a <code>requirements.txt</code> file in the project's root directory. This file is committed to your project's version control history so that as your project adds or updates dependencies, it is reflected in the project's history. This allows anyone working on the project to quickly set up their environment by installing the necessary dependencies with the <code>pip install</code> command. The dev container configuration you setup will automatically install dependencies from <code>requirements.txt</code> when the container is created. This allows anyone working on the project to have a complete environment setup in one step: starting a dev container.</p> <p>In summary, the the <code>devcontainer.json</code> file specifies configuration for a consistent development environment using a Docker image. The <code>requirements.txt</code> file ensures all needed Python package for our project are installed when the container is created. Together, these files automate the process of setting up a developer environment, making it easier for you and others to work on the project. </p> <p>Lets establish your static website development environment:</p>"},{"location":"resources/MkDocs/tutorial/#step-1-add-development-container-configuration","title":"Step 1. Add Development Container Configuration","text":"<ol> <li>In VS Code, open the <code>comp423-course-notes</code> directory. You can do this via: File &gt; Open Folder.</li> <li>Install the Dev Containers extension for VS Code.</li> <li>Create a <code>.devcontainer</code> directory in the root of your project with the following file inside of this \"hidden\" configuration directory:</li> </ol> <p><code>.devcontainer/devcontainer.json</code></p> <p>The <code>devcontainer.json</code> file defines the configuration for your development environment. Here, we're specifying the following:</p> <ul> <li><code>name</code>: A descriptive name for your dev container.</li> <li><code>image</code>: The Docker image to use, in this case, the latest version of a Python environment. Microsoft maintains a collection of base images for many programming language environments, but you can also create your own!</li> <li><code>customizations</code>: Adds useful configurations to VS Code, like installing the Python extension. When you search for VSCode extensions on the marketplace, you will find the string identifier of each extension in its sidebar. Adding extensions here ensures other developers on your project have them installed in their dev containers automatically.</li> <li><code>postCreateCommand</code>: A command to run after the container is created. In our case, it will use <code>pip</code> to install the dependencies listed in <code>requirements.txt</code>.</li> </ul> <pre><code>{\n  \"name\": \"COMP423 Course Notes\",\n  \"image\": \"mcr.microsoft.com/devcontainers/python:latest\",\n  \"customizations\": {\n    \"vscode\": {\n      \"settings\": {},\n      \"extensions\": [\"ms-python.python\"]\n    }\n  },\n  \"postCreateCommand\": \"pip install -r requirements.txt\"\n}\n</code></pre>"},{"location":"resources/MkDocs/tutorial/#step-2-add-requirementstxt-python-dependency-configuration","title":"Step 2. Add <code>requirements.txt</code> Python Dependency Configuration","text":"<p><code>requirements.txt</code></p> <p>The <code>requirements.txt</code> file lists the Python dependencies needed for the project. It should be in your project's root directory. Here, you only need to include <code>mkdocs-material</code> pinned to a specific minor version its current release:</p> <pre><code>mkdocs-material~=9.5\n</code></pre> <p>Pinning a dependency to a minor version ensures that the project will use the latest fixes, called patch releases, within that version. For example, <code>~=9.5</code> allows automatic upgrades from <code>9.5.49</code> to <code>9.5.50</code>, but prevents upgrades to <code>9.6</code> or beyond, ensuring stability while still benefiting from bug fixes and minor improvements. In larger software projects, this practice is valuable for maintaining a stable and reproducible development environment.</p>"},{"location":"resources/MkDocs/tutorial/#step-3-reopen-the-project-in-a-vscode-dev-container","title":"Step 3. Reopen the Project in a VSCode Dev Container","text":"<p>Reopen the project in the container by pressing <code>Ctrl+Shift+P</code> (or <code>Cmd+Shift+P</code> on Mac), typing \"Dev Containers: Reopen in Container,\" and selecting the option. This may take a few minutes while the image is downloaded and the requirements are installed.</p> <p>Once your dev container setup completes, close the current terminal tab (trash can), open a new terminal pane within VSCode, and try running <code>python --version</code> to see your dev container is running a recent version of Python without much effort! (As of this writing: 3.13 released in October of 2024.)</p>"},{"location":"resources/MkDocs/tutorial/#part-3-creating-the-static-site-with-material-for-mkdocs","title":"Part 3. Creating the Static Site with Material for MkDocs","text":""},{"location":"resources/MkDocs/tutorial/#step-1-initialize-mkdocs","title":"Step 1. Initialize MkDocs","text":"<p>Run the following commands in your terminal (inside the container):</p> <pre><code>mkdocs new .\n</code></pre> <p>This command works because <code>mkdocs</code> is installed in the container as part of the <code>requirements.txt</code> setup in the previous section. The <code>mkdocs</code> subcommand creates the basic file structure for your site, including a default <code>mkdocs.yml</code> configuration file and a <code>docs</code> folder.</p> <p>What is the <code>.</code> in that command?</p> <p>You should recall this from COMP211! It refers to the current working directory the terminal's shell process is in.</p> <p>The official documentation for creating a new site, which goes into more depth than this tutorial, can be found in the official documenation for Material for MkDocs, if you are interested in additional coverage.</p>"},{"location":"resources/MkDocs/tutorial/#step-2-configure-your-site","title":"Step 2. Configure Your Site","text":"<p>The <code>mkdocs.yml</code> file is a YAML configuration file. YAML stands for \"Yet Another Markup Language\" and is commonly used in software projects for configuration due to its simplicity and human-readable format. Unlike JSON, which was used in the <code>.devcontainer.json</code> file, YAML doesn\u2019t require brackets or quotes for every element, making it cleaner and easier to read for large configurations. While JSON is more rigid and structured, YAML's flexibility and readability make it popular for configuration files, especially in tools like MkDocs, and cloud deployment tools you will soon learn about, such as GitHub Actions and Kubernetes.</p> <p>Edit <code>mkdocs.yml</code> to look like this:</p> <pre><code>site_name: COMP423 Course Notes\ntheme:\n  name: material\n</code></pre> <p>Edit the <code>index.md</code> markdown file in the <code>docs</code> directory:</p> <p><code>docs/index.md</code></p> <pre><code># Welcome to Your Name's Course Notes\n\nThis is my home page. I will use it to organize and share my course notes.\n</code></pre> <p>Of course, substitute your name in the title.</p> <p>Markdown is a lightweight markup language that allows you to format text using simple, readable syntax. Files written in Markdown typically use the .md extension. It\u2019s widely used in the software industry for documentation, readme files, blogs, and more due to its simplicity and flexibility.</p> <p>In a MkDocs project, all your pages will be written in Markdown and then processed by MkDocs to generate HTML files for your website. This means you can write plain text and use Markdown\u2019s syntax for headings, lists, links, and more, without dealing directly with HTML.</p> <p>Here are some key benefits of Markdown:</p> <ul> <li>It\u2019s easy to read and write.</li> <li>It works well with version control systems like Git.</li> <li>It\u2019s supported by many platforms, including GitHub, where Markdown is used for README files.</li> </ul> <p>To learn more about Markdown, check out this comprehensive guide.</p>"},{"location":"resources/MkDocs/tutorial/#step-3-preview-your-site-locally","title":"Step 3. Preview Your Site Locally","text":"<p>Run the following command to start a local development server:</p> <pre><code>mkdocs serve\n</code></pre> <p>The <code>serve</code> subcommand launches a local development web server that monitors your files for changes. This means if you edit any of the files, the server will automatically refresh the page in your browser to reflect those changes. </p> <p>Open your browser and navigate to <code>http://127.0.0.1:8000</code> to see your site. Woo! You should see the contents of your <code>docs/index.md</code> file rendered in beautiful HTML.</p> <p>What is <code>127.0.0.1</code>?</p> <p><code>127.0.0.1</code> is the \"loopback\" address, meaning it always refers to your own computer. This address is commonly used for testing web applications locally. It also means that you cannot share your local development work directly (without others without using some additional tricks beyond our concerns right now). In the next section, you will learn how to deploy a production grade version of this site live on the web.</p> <p>To stop the server, return to your terminal and press <code>Ctrl+C</code>. This will terminate the <code>mkdocs serve</code> process.</p>"},{"location":"resources/MkDocs/tutorial/#part-4-deploying-with-github-pages","title":"Part 4. Deploying with GitHub Pages","text":"<p>In this section, you will set up an automated deployment process using GitHub Actions, a tool for Continuous Integration and Continuous Deployment (CI/CD). Setting up CI/CD for your project means that every time you make changes and push them to GitHub, a series of automated steps will run to \"test\", build, and deploy your website. This ensures your site is always up-to-date with the latest changes you make.</p> <p>Here\u2019s what you're about to do to configure this repository's CI/CD pipeline:</p> <ol> <li>Add a GitHub Actions Workflow: You'll create a workflow file that defines the automated steps for building and deploying your site on GitHub.</li> <li>Push Changes and Test the Workflow: Once everything is set up, you'll push your changes to GitHub and observe the deployment process in action.</li> </ol>"},{"location":"resources/MkDocs/tutorial/#setting-up-a-github-action-for-cicd","title":"Setting up a GitHub Action for CI/CD","text":""},{"location":"resources/MkDocs/tutorial/#step-1-add-a-github-action-for-cicd","title":"Step 1. Add a GitHub Action for CI/CD","text":"<p>Create a <code>.github/workflows/ci.yml</code> file in your repository. You can do this from a Terminal in your dev container with the commands:</p> <pre><code>mkdir -p .github/workflows\ncode .github/workflows/ci.yml\n</code></pre> <p>This file defines the steps for the CI/CD workflow.</p> <p><code>.github/workflows/ci.yml</code></p> <pre><code>name: Deploy to GitHub Pages\n\non:\n  push:\n    branches:\n      - main\n\npermissions:\n  contents: write\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-python@v5\n        with:\n          python-version: '3.x'\n      - name: Install dependencies\n        run: pip install -r requirements.txt\n      - name: Build and Deploy\n        run: mkdocs gh-deploy --force\n</code></pre> <ul> <li><code>on.push.branches</code>: Specifies that this workflow should run whenever changes are pushed to the <code>main</code> branch.</li> <li><code>permisisons.contents</code>: Specifies the GitHub Action will be able to write back to this repository, needed to update the <code>gh-pages</code> branch the static site content will generate to.</li> <li><code>steps</code>: These define the tasks to perform, such as checking out the code, setting up Python, installing dependencies, building the site, and deploying it. The details of GitHub action configuration are beyond our scope, but you can find the full GitHub Action documentation here.</li> </ul> <p>What does the step running <code>mkdocs gh-deploy --force</code> do?</p> <p>The <code>mkdocs gh-deploy --force</code> command builds your site into static files and pushes them to the <code>gh-pages</code> branch of your repository. This is a subcomand built into <code>mkdocs</code>. The <code>--force</code> flag ensures that any existing content in the <code>gh-pages</code> branch is overwritten, guaranteeing that the latest version of your site is deployed.</p>"},{"location":"resources/MkDocs/tutorial/#step-2-push-changes-and-deploy","title":"Step 2. Push Changes and Deploy","text":"<p>Now that your configuration is ready, let\u2019s test it out:</p> <p>(1) Add and commit your changes:</p> <pre><code>git add .\ngit commit -m \"Set up Material for MkDocs and GitHub Action\"\n</code></pre> <p>(2) Push the changes to GitHub:</p> <pre><code>git push origin main\n</code></pre> <p>(3) Navigate to the Actions tab in your GitHub repository to watch the workflow run. You\u2019ll see each step execute, and once the process completes, your site will be deployed to GitHub Pages.</p> <p>(4) After the GitHub Action completes, navigate to the <code>gh-pages</code> branch in your GitHub repository to view the deployed static files. These files represent your website as hosted by GitHub Pages.</p> <p>(5) To ensure your repository's Github Site is served from the <code>gh-pages</code> branch, go to your repository's Settings &gt; Pages, and select the <code>gh-pages</code> branch as the source for your GitHub Pages site. Once set, your site will soon be live at the URL below.</p> <p>(6) Visit your site at <code>https://&lt;your-username&gt;.github.io/comp423-course-notes</code> to see the changes live. Sometimes this can take a minute to update.</p> <p>Congratulations! You\u2019ve automated your deployment process with CI/CD. Now, every time you push to <code>main</code>, or merge Pull Requests into <code>main</code>, these steps will automatically be carried out resulting in your static website being regenerated and deployed. This \"push-to-deploy\"/\"merge-to-deploy\" git workflow is common in many industrial settings.</p>"},{"location":"resources/MkDocs/tutorial/#understanding-your-cicd-workflow","title":"Understanding your CI/CD Workflow","text":"<p>Now that your deployment is automated, let\u2019s break down what happen step by step when you make changes to this project in the future:</p> <ol> <li> <p>Commit Changes Locally: You edit your site\u2019s files and save your changes in your local Git repository by creating a commit.</p> </li> <li> <p>Push to GitHub: When you push your changes to the <code>main</code> branch on GitHub, the CI/CD pipeline is triggered automatically.</p> </li> <li> <p>GitHub Action Starts: GitHub detects the new commit and starts running the workflow you defined in <code>.github/workflows/ci.yml</code>.</p> </li> <li> <p>Workflow Steps Execute:</p> <ul> <li>The repository code is checked out to the runner environment.</li> <li>A Python environment is set up, and the dependencies listed in <code>requirements.txt</code> are installed.</li> <li>MkDocs builds the static site, converting your Markdown files into an HTML website.</li> <li>The <code>mkdocs gh-deploy</code> command deploys the site to the <code>gh-pages</code> branch.</li> </ul> </li> <li> <p>Site is Updated: Once the workflow completes, your GitHub Pages site automatically reflects the latest changes.</p> </li> </ol>"},{"location":"resources/MkDocs/tutorial/#why-this-matters-beyond-this-tutorial","title":"Why This Matters Beyond This Tutorial","text":"<p>CI/CD is not just for static sites\u2014it\u2019s a critical practice in modern software development. It ensures your code is tested, built, and delivered efficiently and consistently. This approach reduces manual work, catches errors early, and speeds up development.</p> <p>For example:</p> <ul> <li>In large software projects, CI/CD pipelines run tests on every commit to ensure code quality.</li> <li>For applications, pipelines can build and deploy to staging or production environments automatically.</li> </ul> <p>By setting up this workflow, you\u2019ve taken a first step toward understanding these industry-standard practices and how automation can enhance the reliability of your projects.</p>"},{"location":"resources/MkDocs/tutorial/#conclusion","title":"Conclusion","text":"<p>Congratulations! You\u2019ve successfully created a static website for your course notes using Material for MkDocs, configured a development environment, and set up automated deployment. This foundational skill can be applied to many open-source and professional projects. </p> <p>In the first exercise, you will expand your site with more pages and customizations!</p>"},{"location":"resources/apis/0-introduction/","title":"0. Communicating for Shared Understanding between Humans and Systems (APIs)","text":"<p>Communication is the foundation of software engineering. It\u2019s what allows groups of people with different roles, expertise, and perspectives to come together to achieve something bigger than any one person could accomplish alone. Whether it\u2019s a product manager explaining a feature request to an engineering team, designers aligning with software engineers to bring a vision to life, or site reliability engineers ensuring seamless deployments, every step of the software development life cycle (SDLC) relies on effective communication. </p> <p>This same principle applies to software systems. APIs\u2014Application Programming Interfaces\u2014are the tools that enable different pieces of software to exchange information, coordinate actions, and work together. Just as humans need structured communication to succeed in a project, systems need structured interfaces to achieve interoperability. </p> <p>In this sequence of readings, we\u2019ll explore how communication\u2014both among humans and between systems\u2014is the key to creating shared understanding. We\u2019ll emphasize that learning to communicate effectively in both domains is a skill that will not only make you a better software engineer but also prepare you for success in any career.</p> <ul> <li>Part 1 - Communication in the Software Development Lifecycle</li> <li>Part 2 - A Brief History of Communication between Computing Systems</li> <li>Part 3 - High-level API Concerns</li> <li>Part 4 - Introducing HTTP and REST APIs</li> </ul>"},{"location":"resources/apis/1-communication/","title":"1. Communication in the Software Development Lifecycle","text":"<p>Effective communication is critical throughout the software development life cycle (SDLC). Whether a client is requesting a feature or multiple teams are collaborating on a project, intentional communication strategies help ensure that everyone remains on the same page. Poor communication, on the other hand, can lead to misunderstandings, delays, and even project failure.</p>"},{"location":"resources/apis/1-communication/#how-communication-enables-collective-success","title":"How Communication Enables Collective Success","text":"<p>One of the most remarkable aspects of the SDLC is how groups of people with very different backgrounds and roles band together to achieve a goal bigger than anyone could take on individually. A successful project relies on shared understanding\u2014each person must know enough to contribute meaningfully, even if their expertise lies in a specific area. Everyone, from the client to the project manager, to the engineers and designers, needs to clearly understand the goals and desired outcomes of the project.</p> <p>Good communication helps:</p> <ul> <li>Clarify Goals: Ensuring everyone has a unified understanding of what success looks like.</li> <li>Distribute Knowledge: Allowing team members to understand the context they need to make informed decisions.</li> <li>Align Efforts: Making sure that all work, no matter how specialized, contributes to the same broader goal.</li> </ul>"},{"location":"resources/apis/1-communication/#intentional-communication-strategies","title":"Intentional Communication Strategies","text":"<p>Some high-level strategies and concerns are pervasive in software development. We will explore these in more depth as the course goes on, but it is worth highlighting a few now:</p> <ol> <li> <p>Using Shared Resources (e.g. artifacts like files and documents)</p> <ul> <li>Design documents, technical specifications, and wireframes help clarify ideas.</li> <li>These artifacts act as shared resources, ensuring all stakeholders are able to rally around the same ideas before they are built. This idea is not new to software development, think of blue prints and artistic renderings of buildings and spaces in the construction industry as a predecessor.</li> </ul> </li> <li> <p>Choosing the Right Medium for the Message</p> <ul> <li>Synchronous Communication: Meetings, video calls, or real-time collaboration are great for brainstorming or addressing urgent issues.</li> <li>Asynchronous Communication: Emails, project management tools, and documentation are better for detailed updates and tracking progress.</li> </ul> </li> <li> <p>Adjusting Formality Based on Context</p> <ul> <li>Formal communication, such as signed contracts or requirements documents, cement guarantees and expectations. This is especially important between two disparate parties or firms.</li> <li>Informal discussions, like Slack chats or quick hallway conversations, can promote collaboration and generate ideas. These are more useful internally, within a team or organization.</li> </ul> </li> <li> <p>Tightening Feedback Loops</p> <ul> <li>Regular check-ins, code reviews, and demos ensure that misunderstandings are caught early.</li> <li>Feedback helps teams refine their work, aligning closer to the original intent.</li> </ul> </li> </ol>"},{"location":"resources/apis/1-communication/#communication-across-roles","title":"Communication Across Roles","text":"<p>Each role in the SDLC brings unique perspectives and needs, making effective communication even more important.</p> <ul> <li> <p>Client to Project Manager: Clients communicate high-level goals, such as desired features or outcomes. A project manager translates these goals into actionable tasks for the development team. Without clarity, the team may deliver something that doesn\u2019t meet the client\u2019s expectations.</p> </li> <li> <p>Designers to Software Engineers: User interface (UI) designers create wireframes or mockups that software engineers implement. Miscommunication about design elements, like color schemes or interaction behaviors, can result in poor user experiences.</p> </li> <li> <p>Software Engineers to Site Reliability Engineers: Software engineers rely on site reliability engineers (SREs) to deploy software to production environments. Poorly communicated deployment requirements can lead to configuration errors, downtime, or failed releases.</p> </li> </ul> <p>As a foreshadowing, we will soon turn our attention toward communication between different layers of a software system, such as front-end and back-end. One hand-waiving analogy of a system layer is like a different role in a team: it has its own concerns and jobs different from the others yet it still needs to work in coordination with the others. Sometimes these layers are implemented in different programming languages and we will need to pay careful attention to how communication between these layers ensures no information is lost in translation.</p>"},{"location":"resources/apis/1-communication/#what-happens-when-communication-breaks-down","title":"What Happens When Communication Breaks Down","text":"<p>Poor communication can have serious consequences at every stage of development:</p> <ul> <li>Client Dissatisfaction: Vague requirements or misaligned priorities lead to deliverables that don\u2019t meet the client\u2019s needs.</li> <li>Missed Deadlines: Unclear expectations create confusion about what tasks need to be completed and when.</li> <li>Team Frustration: Miscommunication fosters blame and reduces morale, impacting productivity.</li> <li>Technical Debt: Lack of clarity around implementation can result in rushed, poorly designed solutions that need to be fixed later.</li> </ul>"},{"location":"resources/apis/1-communication/#benefits-of-good-communication","title":"Benefits of Good Communication","text":"<p>When communication is intentional and well-structured, it:</p> <ul> <li>Clarifies Goals and Outcomes: Ensures everyone knows what they\u2019re working toward and why it matters.</li> <li>Prevents Scope Creep: Clear requirements help avoid last-minute changes that derail timelines.</li> <li>Improves Collaboration: Shared understanding across teams reduces friction and promotes teamwork.</li> <li>Minimizes Rework: Aligned expectations mean less time spent correcting misunderstandings.</li> <li>Builds Trust: Transparent communication fosters trust between clients and development teams.</li> </ul> <p>Fred Brooks on Communication</p> <p>\"The hardest single part of building a software system is deciding precisely what to build. No other part of the conceptual work is so difficult as establishing the detailed technical requirements, including all the interfaces to people, to machines, and to other software systems. No other part of the work so cripples the resulting system if done wrong. No other part is more difficult to rectify later.\" </p> <p>\u2014 Fred Brooks, \"No Silver Bullet: Essence and Accidents of Software Engineering,\" 1986</p>"},{"location":"resources/apis/2-api-history/","title":"2. Advancements in Communication between Computing Systems","text":"<p>As we turn our attention to communication between systems, that software engineers design and implement, it is helpful to have some historical context. Just as structured communication enables humans to align on shared goals, advances in computing systems have focused on making the exchange of information between machines more structured, scalable, and reliable. This history lays the foundation for understanding how modern APIs play a central role in today\u2019s interconnected digital world.</p>"},{"location":"resources/apis/2-api-history/#the-early-days-batch-processing-and-punch-cards","title":"The Early Days: Batch Processing and Punch Cards","text":"<p>In the 1950s and 60s, computers were massive, room-sized machines, and communication with them was painstakingly slow. Users prepared instructions using punch cards\u2014thin cardboard sheets with holes representing binary commands. The cards were fed into the computer in batches, and the machine would process them before producing an output, often printed on paper. </p> <p>While revolutionary at the time, this method lacked interactivity. Communication was strictly one-way, requiring users to wait for results before making adjustments.</p>"},{"location":"resources/apis/2-api-history/#the-shift-to-real-time-interaction-time-sharing-systems","title":"The Shift to Real-Time Interaction: Time-Sharing Systems","text":"<p>In the 1960s, time-sharing systems introduced real-time interaction with computers. This is when shells, like the command-line interfaces software engineers (and you, in 211 and this course!) still use today, rose in prominence.</p> <p>These systems allowed multiple users to work on the same machine simultaneously via terminals. Communication became more dynamic, enabling developers to write, test, and debug programs interactively.</p> <p>This period also saw the rise of early message-passing protocols, as systems began to share data across connected machines. However, these interactions were often bespoke and required deep technical knowledge, limiting their accessibility to a small group of experts. There were no standards for information exchange between two systems or programs.</p>"},{"location":"resources/apis/2-api-history/#networking-revolution-the-arpanet-and-protocols","title":"Networking Revolution: The ARPANET and Protocols","text":"<p>The creation of the ARPANET in 1969\u2014a precursor to the internet\u2014marked a significant milestone in system communication. For the first time, computers located miles apart could exchange data. Early protocols like NCP (Network Control Protocol) and later TCP/IP (Transmission Control Protocol/Internet Protocol) laid the groundwork for modern networking by standardizing how systems should format and transmit messages.</p> <p>With standardized protocols, communication across systems became more predictable and scalable. These innovations enabled the development of distributed systems, where multiple computers could collaborate on a single task. It\u2019s not unlike how the advent of telephone systems unlocked new forms of collaboration and communication among people.</p>"},{"location":"resources/apis/2-api-history/#the-rise-of-the-web-http-and-html","title":"The Rise of the Web: HTTP and HTML","text":"<p>The invention of the World Wide Web in the 1990s transformed how systems\u2014and people\u2014interacted. HTTP (Hypertext Transfer Protocol) became the standard for requesting and transmitting resources over the web, while HTML (Hypertext Markup Language) provided a consistent way to display those resources.</p> <p>This period also saw the emergence of APIs in their earliest forms. Web APIs allowed applications to request data or functionality from other services, albeit in a relatively unstructured and inconsistent manner compared to today.</p>"},{"location":"resources/apis/2-api-history/#modern-apis-rest-and-beyond","title":"Modern APIs: REST and Beyond","text":"<p>In the early 2000s, REST (Representational State Transfer) emerged as a simpler, more flexible approach to API design. RESTful APIs leveraged familiar web methods, such as \"retrieving\" or \"updating\" resources, to create predictable and scalable communication between clients and servers.</p> <p>Today, APIs are fundamental to how most modern web and mobile applications function. Applications are often split into at least two conceptual parts: the front-end, which is what users interact with, and the back-end, which processes data and handles the core functionality. These two parts communicate via APIs. A front-end might send a request for a user's profile data, and the back-end would respond with the necessary details structured in an agreed-upon format. When you use an app like this, your request is communicated over the internet to a data center tens or hundreds of miles away, and the backend responds to it, all in a split second. It's a marvel of communication!</p> <p>APIs also power many popular services you use daily. Music services like Spotify use APIs to send requests from your app to their servers, fetching your playlists or suggesting new tracks. Social media platforms work similarly\u2014your app communicates with their API to load your feed, post updates, or send messages. </p> <p>Beyond individual applications, APIs also enable cross-application integration. For instance, logging into a platform using credentials from Google, Facebook, or GitHub is made possible by authentication APIs. Fitness apps syncing data with health dashboards or e-commerce platforms coordinating with payment processors are other examples of how APIs allow disparate systems to integrate with each other.</p>"},{"location":"resources/apis/2-api-history/#lessons-from-history","title":"Lessons from History","text":"<p>Each step in the evolution of communication in computing systems reflects a broader goal: making it easier for machines and humans to exchange information. Standardized protocols, structured formats, and accessible APIs have all contributed to this progress, ensuring that systems can collaborate effectively. These are key tools toward arriving at shared understanding between systems and people.</p>"},{"location":"resources/apis/3-api-design/","title":"3. Human Communication and API Design: A Shared Foundation","text":"<p>Building on the importance of communication in the software development life cycle, we now turn our attention to APIs\u2014Application Programming Interfaces. Just as intentional communication strategies help teams of humans align and collaborate, APIs serve as the structured communication layer that allows different software systems to work together effectively.</p>"},{"location":"resources/apis/3-api-design/#communication-as-a-bridge","title":"Communication as a Bridge","text":"<p>In both human and system communication, shared understanding is built through structured exchanges of information. Consider how people communicate:</p> <ul> <li>A sender conveys a message.</li> <li>A receiver interprets the message.</li> <li>A shared language or set of conventions ensures both parties understand each other.</li> <li>Feedback confirms whether the message was received as intended.</li> </ul> <p>Now consider how client-server APIs classically function:</p> <ul> <li>A client (the sender) sends a request to a server.</li> <li>The server (the receiver) processes the request.</li> <li>Both client and server rely on shared protocols and formats, such as predefined rules for requests and responses, to ensure clarity. API requests typically include:<ul> <li>\"who\" the recipient is. The who of an API request is typically a server address (e.g. <code>api.instagram.com</code>) and not at all \"who\" in the human sense.</li> <li>\"where\" the resource is found via routing the request once it reaches the server. Typically this includes some identifying information (e.g. a path like <code>/profiles/therealkrisjordan</code> or <code>/post/1234</code>).</li> <li>\"what\" the action being requested on this resource is (verb). Is the action asking for data about resource? Creating new or updating existing resources? Deleting a resource?</li> <li>Additional information needed to process the specific request. This information tends to be either metadata (such as what kind of format you would like in response or some identifying information of you, the sender) or data about the resource (such as a new profile bio when saving your social service profile).</li> </ul> </li> <li>The server\u2019s response serves as feedback, confirming the outcome of the interaction.<ul> <li>Status codes: did the request succeed or fail? If there was an error, what kind of error?</li> <li>Data requested: most requests are looking for information, so the response includes the data in the format requested.</li> <li>Metadata about the response that will be useful to the client when interpreting it.</li> </ul> </li> </ul> <p>The structure in both cases\u2014human and system\u2014is essential to avoiding misunderstandings and ensuring smooth collaboration.</p>"},{"location":"resources/apis/3-api-design/#analogies-in-communication","title":"Analogies in Communication","text":"<p>To help solidify these concepts, let\u2019s draw some direct parallels between communication in the SDLC and API design:</p> <ul> <li>Project Specifications and API Specifications: Just as an operating agreement or design document clarifies expectations for human collaborators, an API specification defines how systems should interact. An API can specify which operations are available, what input is required, and what kind of response to expect.</li> </ul> <p>OpenAPI Initiative</p> <p>In the past decade, there has been a serious push toward API specification standards via the Open API Initiative. We will be making use of OpenAPI standards soon in this course!</p> <ul> <li> <p>Language and Shared Formats: In human communication, language provides the structure for expressing ideas. In system communication, shared formats define how data is packaged, such as using standard data encodings (e.g. JSON - JavaScript Obect Notation or XML eXtensible Markup Language) to make the information predictable and easy to interpret.</p> </li> <li> <p>Feedback Loops in Teams and Systems: Teams rely on feedback to refine their work, whether through design critiques or user testing. Similarly, APIs provide feedback through structured responses that indicate success, failure, or additional actions required.</p> </li> </ul>"},{"location":"resources/apis/3-api-design/#empathy-in-api-design","title":"Empathy in API Design","text":"<p>Empathy is just as critical in API design as it is in human-to-human communication. In both, structure minimizes ambiguity and reduces the effort required to interpret messages. Imagine receiving a vague email like, \u201cPlease fix it ASAP,\u201d without knowing what \"it\" refers to or how urgent the issue really is. Similarly, an API that returns an error message like, \u201cSomething went wrong,\u201d leaves developers guessing about what needs to be fixed.</p> <p>API designers must consider the needs, constraints, and workflows of the developers who will use their APIs. This means thinking beyond technical functionality to focus on usability and developer experience. Here are some best practices when designing APIs that are a joy to use:</p> <ul> <li> <p>Clear Documentation: Developers should be able to understand how to use an API without guessing. Documentation should be well-organized and provide examples that illustrate typical use cases.</p> </li> <li> <p>Meaningful Feedback: If something goes wrong, an API should return detailed and actionable messages. For instance, instead of a generic \u201cInvalid request,\u201d it should specify, \u201cMissing required field: city.\u201d</p> </li> <li> <p>Consistency and Predictability: Endpoints and request structures should follow predictable patterns, reducing the mental effort needed to learn and use the API.</p> </li> <li> <p>Anticipating User Needs: Think about common workflows or challenges developers face and design the API to simplify these tasks. For example, providing optional filters or flexible ways to retrieve data can save time and effort for users.</p> </li> </ul> <p>These practices aren't restricted to API Design, they're generally applicable principles of human-centered design across many domains!</p> <p>Empathy ensures that APIs are not only functional but also intuitive, reducing frustration and increasing developer productivity. When designers think about the people behind the code, and who their systems serve, they create tools that foster collaboration and innovation.</p>"},{"location":"resources/apis/4-http/","title":"4. Key Concepts in HTTP","text":"<p>Have you ever wondered how your favorite apps communicate with servers behind the scenes? When you leave a comment on Instagram, how does the server know which post you\u2019re commenting on and what you wrote? In this section, we'll explore how modern software systems communicate via HTTP (Hypertext Transfer Protocol), focusing on APIs (Application Programming Interfaces) and the structure that makes it all work.</p>"},{"location":"resources/apis/4-http/#key-terms","title":"Key Terms","text":"<p>Understanding these concepts forms the foundation of all API interactions, whether you're building a simple weather app or a complex social media platform.</p> <ol> <li> <p>Sender (The Client): This is who initiates the communication - like your mobile app or web browser. The client is responsible for:</p> <ul> <li>Formatting requests correctly</li> <li>Managing user interactions</li> <li>Handling responses appropriately</li> <li>Retrying failed requests when necessary</li> </ul> </li> <li> <p>Receiver (The Server): This processes the request and sends back information. The server\u2019s responsibilities include:</p> <ul> <li>Validating incoming requests</li> <li>Processing data and managing resources</li> <li>Ensuring security</li> <li>Providing appropriate responses</li> </ul> </li> <li> <p>Medium (The Channel): How the message travels - in modern APIs, this is typically HTTP. The medium:</p> <ul> <li>Ensures reliable delivery of messages</li> <li>Handles connection management</li> </ul> </li> <li> <p>Message (The Request/Response): The actual information being exchanged. Messages must be properly formatted and complete with all necessary information.</p> </li> <li> <p>Feedback (The Server\u2019s Response): Confirmation that the message was received and processed. Good feedback:</p> <ul> <li>Confirms success or failure</li> <li>Provides helpful error messages</li> <li>Returns requested data</li> <li>Includes relevant metadata</li> </ul> </li> </ol> <p>A common, helpful analogy for APIs at a conceptual level is to think of it like ordering food at a restaurant:</p> <ul> <li>You (the sender/client) place an order.</li> <li>The waiter (the medium) carries the message back to the kitchen.</li> <li>Your order (the message) contains what you want.</li> <li>The kitchen (the receiver/server) processes it.</li> <li>The waiter (the medium) carries the food from the kitchen to you.</li> <li>The food arriving (the feedback) confirms your order was received and accurately processed.</li> </ul>"},{"location":"resources/apis/4-http/#http-the-medium-of-modern-apis","title":"HTTP: The Medium of Modern APIs","text":"<p>HTTP provides a standardized way for clients and servers to talk to each other. Understanding HTTP important for any software engineer working with web or mobile applications.</p>"},{"location":"resources/apis/4-http/#resources-the-nouns-of-http","title":"Resources: The Nouns of HTTP","text":"<p>In HTTP, everything is a resource - think of these as the \"things\" your API can interact with. Resources are fundamental to REST (Representational State Transfer), the most common architectural style for modern APIs.</p> <p>Examples of resources:</p> <ul> <li>A user profile</li> <li>A social media post</li> <li>A collection of photos</li> <li>A comment thread</li> </ul> <p>Each resource has its own URL (Uniform Resource Locator). URLs are technically opaque strings, but in real-world applications tend to be structured hierarchically, inspired by directory path strings, like:</p> <pre><code>https://api.instagram.com/users/123/posts/456/comments\n</code></pre> <p>Breaking down this URL:</p> <ul> <li><code>https://</code>: This is the protocol of the connection (cryptographically secure HTTP)</li> <li><code>api.instagram.com</code>: This is the domain that addresses \"who\" the request is sent to.</li> <li><code>users/123</code>: Identifies a specific user.</li> <li><code>posts/456</code>: A specific post by that user.</li> <li><code>comments</code>: The collection of comments on that post.</li> </ul>"},{"location":"resources/apis/4-http/#http-methods-the-verbs","title":"HTTP Methods: The Verbs","text":"<p>HTTP methods define what action you want to perform on a resource. Understanding each method\u2019s purpose and proper use is valuable:</p> HTTP Method Safety Idempotency Description GET Safe Idempotent Fetches information without modifying any resources on the server POST Not Safe Not Idempotent Creates new resources on the server, with each identical request potentially creating multiple resources PUT Not Safe Idempotent Completely replaces an existing resource, with repeated identical requests having the same effect PATCH Not Safe Idempotent Partially modifies an existing resource, only updating specified fields DELETE Not Safe Idempotent Removes a resource from the server, with repeated identical requests having the same effect <p>Safety in web APIs is like reading a book versus writing in it. When a method is \"safe,\" it means it only reads or looks at data without changing anything on the server - like how reading a book doesn't change its contents. GET is the only safe method since it just retrieves information, while methods like POST, PUT, PATCH, and DELETE are not safe because they modify data on the server, just like how writing in a book changes its contents.</p> <p>Idempotency is about whether doing something multiple times has the same effect as doing it once. It's a really important property in many system designs. Think of it like pressing the button at a crosswalk: the second or third time you push it before the lights change has no additional effect (as much as we wish it sped the process up!). Similarly, saving a file many times in a row in your editor does not create multiple files. Importantly, for well implemented checkout systems, pressing \"Complete Purchase\" many times does not result in duplicate orders going through. These operations are idempotent. GET, PUT, PATCH, and DELETE are idempotent because repeating the same request gives you the same result, while POST is not idempotent because each request creates something new - like how pressing \"send\" multiple times on an email might send multiple copies of the same message.</p>"},{"location":"resources/apis/4-http/#get","title":"GET","text":"<ul> <li>Examples:<ul> <li>Viewing a user's profile page</li> <li>Retrieving a list of blog posts</li> <li>Fetching search results</li> </ul> </li> <li>Common Use Cases:<ul> <li>Search operations</li> <li>Data retrieval</li> <li>Reading resources</li> <li>Querying system status</li> </ul> </li> </ul>"},{"location":"resources/apis/4-http/#post","title":"POST","text":"<ul> <li>Examples:<ul> <li>Adding a new comment to a blog post</li> <li>Creating a new user account</li> <li>Uploading a file to a server</li> </ul> </li> <li>Common Use Cases:<ul> <li>Form submissions</li> <li>File uploads</li> <li>Resource creation</li> <li>Data processing</li> </ul> </li> </ul>"},{"location":"resources/apis/4-http/#put","title":"PUT","text":"<ul> <li>Examples:<ul> <li>Updating an entire user profile</li> <li>Replacing a document with a new version</li> <li>Setting a complete configuration</li> </ul> </li> <li>Common Use Cases:<ul> <li>Full resource updates</li> <li>Complete replacements</li> <li>Configuration updates</li> <li>Version management</li> </ul> </li> </ul>"},{"location":"resources/apis/4-http/#patch","title":"PATCH","text":"<ul> <li>Examples:<ul> <li>Updating just a user's email address</li> <li>Modifying specific fields in a document</li> <li>Updating part of a configuration</li> </ul> </li> <li>Common Use Cases:<ul> <li>Partial updates</li> <li>Field-specific modifications</li> <li>Resource property adjustments</li> <li>Incremental changes</li> </ul> </li> </ul>"},{"location":"resources/apis/4-http/#delete","title":"DELETE","text":"<ul> <li>Examples:<ul> <li>Removing a comment from a post</li> <li>Deleting a user account</li> <li>Removing a file from storage</li> </ul> </li> <li>Common Use Cases:<ul> <li>Resource removal</li> <li>Cleanup operations</li> <li>Account deletion</li> <li>Content management</li> </ul> </li> </ul>"},{"location":"resources/apis/4-http/#anatomy-of-api-communication","title":"Anatomy of API Communication","text":"<p>Let\u2019s mock up the big ideas of what happens when you comment on a post on Instagram.</p>"},{"location":"resources/apis/4-http/#the-request-client-server","title":"The Request (Client \u2192 Server)","text":"<pre><code>POST https://api.instagram.com/posts/12345/comments\nContent-Type: application/json\nAuthorization: Bearer eyJhbGc...\n\n{\n    \"comment\": \"Great photo!\",\n    \"timestamp\": \"2024-01-26T10:30:00Z\",\n    \"source\": \"mobile_app\"\n}\n</code></pre> <p>This is a simple example of the textual \"envelope\" of an HTTP request contains and what is transmitted over the network from client to server.</p> <ul> <li> <p>Method and URL: The POST method indicates we\u2019re creating a new comment. The URL specifies exactly which resource (the post) we\u2019re interacting with.</p> </li> <li> <p>Headers: Headers provide essential metadata. Examples:</p> <ul> <li><code>Content-Type</code>: Tells the server what format the data is in.</li> <li><code>Authorization</code>: Proves who you are (usually a token).</li> </ul> </li> <li> <p>Body: Contains additional data about the request. In this case, it includes the comment text, the source of the action, and a timestamp.</p> </li> </ul>"},{"location":"resources/apis/4-http/#the-response-server-client","title":"The Response (Server \u2192 Client)","text":"<pre><code>HTTP/1.1 201 Created\nContent-Type: application/json\nCache-Control: no-cache\n\n{\n    \"success\": true,\n    \"message\": \"Comment added successfully\",\n    \"comment_id\": 789,\n    \"timestamp\": \"2024-01-26T10:30:01Z\"\n}\n</code></pre> <p>Key components explained:</p> <ul> <li> <p>Status Line: Indicates the HTTP version, status code (201 Created), and a brief status message. We will look at status codes in more depth shortly.</p> </li> <li> <p>Headers: Includes metadata about the response. Examples:</p> <ul> <li><code>Content-Type</code>: Format of the response (JSON).</li> <li><code>Cache-Control</code>: Instructions for how clients should cache the response (or not!)</li> </ul> </li> <li> <p>Body: Contains the actual response data, confirming the action was successful and providing additional context (e.g., the new comment ID).</p> </li> </ul>"},{"location":"resources/apis/4-http/#request-response-sequence-diagram","title":"Request Response Sequence Diagram","text":"<p>The above request, response flow can be visualized as follows:</p> <pre><code>sequenceDiagram\n    participant App as Instagram App (Client)\n    participant Server as Instagram Server\n\n    Note over App: User Leaves a Comment\n    App-&gt;&gt;Server: POST /posts/12345/comments\n    Note over Server: Comment Saved Successfully\n    Server--&gt;&gt;App: 201 Created (Success!)\n    Note over App: Comment Shows as Saved </code></pre> <p>This diagram shows:</p> <ol> <li>The client sending the comment to the server.</li> <li>The server processing the comment.</li> <li>A success response being returned to the client.</li> </ol>"},{"location":"resources/apis/4-http/#status-codes-convey-servers-handling-of-request","title":"Status Codes Convey Server's Handling of Request","text":"<p>When the server sends a response, the response starts with a status code. You've seen these in the wild: <code>404 Not Found</code> or <code>500 Internal Server Error</code>. There is an intention design to these \"century\" numberings. Responses within each 100-level range share something in common.</p> <ul> <li> <p>Informational (1xx): These are rarely used by API developers and are more for lower-level connection handling.</p> <ul> <li>101 Switching Protocols: Used when an HTTP connection is upgraded to a WebSocket connection.</li> </ul> </li> <li> <p>Success (2xx): Indicates that the request was successfully processed by the server.</p> <ul> <li>200 OK: Request succeeded.</li> <li>201 Created: Resource was created successfully.</li> </ul> </li> <li> <p>Redirection (3xx): Indicates the client needs to take additional action to complete their request.</p> <ul> <li>301 Moved Permanently: The resource has permanently moved to a new URL.</li> <li>302 Found: The resource is temporarily at a different URL.</li> <li>307 Temporary Redirect: Like 302, but the request method must not change.</li> </ul> </li> <li> <p>Client Errors (4xx): Indicates there is something wrong with what the client sending the request is requesting.</p> <ul> <li>400 Bad Request: Invalid syntax or parameters.</li> <li>401 Unauthorized: The request could not be authenticated to a user or the user no longer exists.</li> <li>403 Forbidden: The user making the request does not have permission to perform the requested action.</li> <li>404 Not Found: Resource doesn\u2019t exist.</li> </ul> </li> <li> <p>Server Errors (5xx): Indicates an error happened on the server's end but the problem was not the client's fault.</p> <ul> <li>500 Internal Server Error: Unexpected server error.</li> </ul> </li> </ul> <p>Now that you have a handle on the fundamental concepts of what comprises an HTTP request, we'll take at modern conventions and best practices for designing APIs with these concepts and following best practices.</p>"},{"location":"resources/apis/5-api-spec/","title":"5. Toward Designing and Formally Specifying APIs","text":"<p>Now that you have seen the key elements of HTTP at a conceptual level, across the entire request-response journey, let's focus in on how API designers generally use the inputs from a request. Additionally, let's look at how responses are designed.</p> <p>When working with HTTP APIs, there are multiple ways to provide input to a request, each serving a different purpose:</p> <ul> <li>Methods define the type of action the API request is performing.</li> <li>Paths define the structure of an API and uniquely identify resources.</li> <li>Query Parameters allow clients to filter, sort, or refine results without changing the resource's identity.</li> <li>Bodies are used to send structured data in requests, typically for creating or updating resources.</li> <li>Headers provide metadata about the request, such as authentication details or content type preferences.</li> </ul> <p>Understanding these inputs is essential for designing HTTP APIs that are intuitive, efficient, and scalable.</p>"},{"location":"resources/apis/5-api-spec/#introduction-to-rest","title":"Introduction to REST","text":"<p>REST (Representational State Transfer) defines a set of architectural principles for designing HTTP APIs that focus on resources and how to design interactions with them. </p> <p>REST emerged from Roy Fielding's 2000 PhD dissertation, where he formalized the architectural principles that had guided his work on the HTTP specifications. While working on HTTP standards, he observed that many distributed systems at the time were tightly coupled, requiring detailed knowledge of each other's internal implementations. His dissertation introduced REST as an architectural style that embraced the web's fundamental design - particularly its use of hyperlinks as resource identifiers, standard methods (such as GET, POST, PUT, DELETE, and so on), and stateless communication. What made REST revolutionary was that it showed how to build distributed systems that could evolve independently by following these principles, allowing clients and servers to evolve and change without breaking each other. This was in stark contrast to earlier approaches that required lockstep changes between clients and servers.</p> <p>A key characteristic of REST is that it's stateless\u2014each request from client to server must contain all the information needed to understand and process the request. The server shouldn't need to remember anything about previous requests.</p> <p>HTTP APIs that embrace this architectural style are often described as being RESTful.</p>"},{"location":"resources/apis/5-api-spec/#resources-and-their-role-in-restful-apis","title":"Resources and Their Role in RESTful APIs","text":"<p>In RESTful APIs, the nouns in your API are resources. Each resource is uniquely identified by a URL (Uniform Resource Locator), meaning every resource has its own address.</p> <p>You may know these as web addresses, like:</p> <ul> <li>https://csxl.unc.edu/api/organizations \u2192 Returns a list of CS student organizations in JSON.</li> <li>https://csxl.unc.edu/api/academics/section/term/25S \u2192 Returns a list of CS classes offered in Spring 2025.</li> </ul> <p>Could you easily see the structure of the JSON in the URLs above?</p> <p>Most web browsers don't have nice, automatic formatting of JSON data. If you open the links above and it's not easy to see the structure of the data, we strongly recommend installing a web browser plugin to format JSON data. They are super handy when designing and building your own APIs!</p> <p>In Google Chrome, for example, we recommend JSON Formatter. Other browsers have similar tools\u2014find one with good reviews and many installations.</p>"},{"location":"resources/apis/5-api-spec/#request-input-specifications","title":"Request Input Specifications","text":""},{"location":"resources/apis/5-api-spec/#methods-defining-actions","title":"Methods: Defining Actions","text":"<p>The method of an HTTP request tells the server what action is being performed on the resource. You previously read about the fundamental API methods in the last section, including GET, POST, PUT, PATCH, and DELETE. While we won't go into detail here, it's important to recognize that the method is an essential input to an HTTP request and characterizes the request's intent to read, write, delete, or update.</p>"},{"location":"resources/apis/5-api-spec/#paths-identifying-and-routing-requests","title":"Paths: Identifying and Routing Requests","text":"<p>The path of a URL is technically just an opaque string of characters. You could design APIs with any scheme you'd like, but most REST API designers today model it as a logical hierarchy, much like folders in a file system:</p> <ul> <li><code>/api/users</code> \u2192 Might represent a collection of users.</li> <li><code>/api/users/42</code> \u2192 Might represent a specific user with ID 42.</li> <li><code>/api/users/42/orders</code> \u2192 Might represent orders placed by the user with ID 42.</li> </ul> <p>A path tells you which resource you want to work with in an API. For example, <code>/api/users/42</code> points to a specific user.</p> <p>Paths often contain both static and dynamic parts. In the example above:</p> <ul> <li><code>/api/users/</code> is static - it's always written exactly this way</li> <li><code>42</code> is dynamic - it changes based on which user you want</li> </ul> <p>When you build an API, your framework (e.g. FastAPI in COMP423) handles routing - matching each incoming request to the right piece of code. The framework looks at two key inputs:</p> <ol> <li>The path (what resource you want)</li> <li>The HTTP method (what you want to do with it)</li> </ol> <p>For instance, sending <code>GET</code> vs <code>DELETE</code> to <code>/api/users/42</code> will trigger different actions, even though the path is the same. GET might retrieve the user's information, while <code>DELETE</code> might remove their account.</p> <p>Using a common delimiter character, like the <code>/</code> character in a path, communicates subparts of a path to both humans and the system. This convention allows us to visually read the parts of a path and it also allows for programs to parse the path in a straightforward manner by breaking the string up by its <code>/</code> characters.</p>"},{"location":"resources/apis/5-api-spec/#query-parameters-refining-requests","title":"Query Parameters: Refining Requests","text":"<p>HTTP API designers aim to use query parameters when you need to customize what data is returned back from an API resource. They are added to the end of a URL after the path and tell the server how to filter, sort, or modify the data before sending it back.</p> <p>Here's how they work in a URL:</p> <pre><code>www.bookstore.com/books?genre=fantasy&amp;sort=newest\n</code></pre> <p>The path of this request is <code>/books</code>, a resource that lists all books being sold by a hypothetical book store.</p> <p>The query parameter begans at the <code>?</code> following the path:</p> <ul> <li>Each parameter has a name and value joined by <code>=</code> </li> <li>Multiple parameters are connected with <code>&amp;</code></li> </ul> <p>Like parameter passing to a function, query parameters allow the same resource to inform its behavior and response. Common uses include:</p> <ul> <li>Filtering: <code>?genre=fantasy</code> (only return fantasy books)</li> <li>Sorting: <code>?sort=newest</code> (arrange by newest first) </li> <li>Pagination: <code>?page=2&amp;limit=10</code> (get 10 items from page 2)</li> <li>Searching: <code>?search=dragon</code> (find items containing \"dragon\")</li> </ul> <p>The server reads these parameters and adjusts what data it sends back based on them.</p> <p>APIs that use query parameters will often have default values for each parameter so that requests without them will still succeed. For example, when loading the first page of a product listing API, your request may not need the <code>page</code> parameter, but on pages <code>2</code> and <code>3</code> beyond, it does.</p> <p>Beyond APIs, query parameters are a fundamental part of the web. A common example is a Google search URL:</p> <ul> <li><code>https://www.google.com/search?q=REST%20API</code> \u2192 Searches Google for 'REST API'.\u00a0Here the <code>q</code> is the name of the query parameter, Google's short-hand for query, and <code>REST API</code> is the value.</li> </ul> <p>You, as the designer and implementer of an API, will decide whether any of your routes utilize query parameters and be responsible for modifying responses based on their values.</p>"},{"location":"resources/apis/5-api-spec/#path-and-query-parameter-design-conventions","title":"Path and Query Parameter Design Conventions","text":"<p>Over the past 25 years, API designers have found many conventions in deciding how to name parts of a path, and how to use path and query parameters together.</p> <p>\ud83c\udfaf Target nouns, not verbs - resources are things, not actions: <pre><code>\u2705 /articles\n\u274c /getArticles\n</code></pre></p> <p>\ud83c\udfaa Use plural nouns for collections: <pre><code>\u2705 /users\n\u274c /user-list\n\u2705 /users/123\n\u274c /user/123\n</code></pre></p> <p>\ud83c\udfad Pick a form and stick to it - be consistent with plurals: <pre><code>\u2705 /posts/123/comments/456\n\u274c /posts/123/comment/456\n</code></pre></p> <p>\ud83c\udf32 Don't nest too deeply: <pre><code>\u2705 /articles/123/comments\n\u274c /articles/123/comments/456/replies/789/likes\n</code></pre></p> <p>\ud83d\udc2a Use kebab-case or lowercase: <pre><code>\u2705 /blog-posts or /blogposts\n\u274c /blogPosts or /blog_posts\n</code></pre></p> <p>\ud83d\udd0d Filtering goes in queries - use parameters for modifiers: <pre><code>\u2705 /articles?status=published&amp;sort=date\n\u274c /published-articles-sorted-by-date\n</code></pre></p> <p>\ud83c\udfaf IDs belong in paths, not query parameters - directly access resources: <pre><code>\u2705 /users/123\n\u274c /users?id=123\n</code></pre></p> <p>\ud83d\udc68\u200d\ud83d\udc69\u200d\ud83d\udc67\u200d\ud83d\udc66 Family trees make sense - use nesting for real hierarchies: <pre><code>\u2705 /teams/123/members\n\u274c /members?teamId=123\n</code></pre></p> <p>As you get deeper into API design and implementation there are a few other best practice, as well, but if you merely followed these for the purposes of this course you will be doing great.</p>"},{"location":"resources/apis/5-api-spec/#bodies-sending-data-in-requests","title":"Bodies: Sending Data in Requests","text":"<p>For POST (creating) and PUT (updating) method requests, we need to send more complex data to the server. This data is sent in the body of the HTTP request, often in JSON format:</p> <pre><code>{\n  \"name\": \"Alice\",\n  \"email\": \"alice@example.com\"\n}\n</code></pre> <p>When designing the specification for an API, we will need to clearly define a schema for bodies. A schema defines exactly what \"shape\" of data our API expects in the request body, such as field names, data types, and structure. In the example above, the structure is a single JSON Object (denoted by the surrounding curly braces), the field names are <code>name</code> and <code>email</code>, and both fields expect <code>string</code> values assigned to them.</p> <p>Unlike paths or query parameters, bodies are not visible in the URL and can contain more complex structures like lists and nested objects. As such, sending <code>POST</code>/<code>PUT</code> requests to APIs is more involved than <code>GET</code> requests. Either you have to use a tool, which we'll look at an example of very soon, or you have to write some API client code.</p>"},{"location":"resources/apis/5-api-spec/#headers-metadata-for-requests","title":"Headers: Metadata for Requests","text":"<p>HTTP headers carry additional standard metadata about the request. The names of the example headers shown below are all defined by the HTTP standard. The API designer's use of headers is primarily choosing which standard headers to utilize, if any. </p> <ul> <li>Authentication is used to prove the request is made by an authorized user (e.g. Bearer Tokens for security):</li> </ul> <pre><code>Authorization: Bearer abc123xyz\n</code></pre> <ul> <li>Content-Type tells the server the data format in the request body (e.g., specifying JSON data format):</li> </ul> <pre><code>Content-Type: application/json\n</code></pre> <ul> <li>Accept indicates the client expects a certain data type in the response body (e.g., requesting a response in a specific format):</li> </ul> <pre><code>Accept: application/json\n</code></pre> <p>In the initial APIs you design, you will not be overly concerned with headers. Why? We will start with building some public APIs that do not attempt to authenticate a user. Additionally, all of our APIs will standardize around the <code>application/json</code> request body and response format. It's become pretty standard and is nice to work with. If you spend enough time implementing APIs, you may find it interesting to learn more about content negotiation which allows the client to request the same resource be responded in a specific data type (such as <code>XML</code> or <code>HTML</code> rather than <code>JSON</code>).</p> <p>Headers are also commonly used to help out with content caching, where clients give servers a hash of their cached content and servers can response \"nothing's changed, reuse your cached copy and we're not sending anything else back.\" Additionally, headers are used for some security features as well, like preventing an old phishing attack where an unsuspecting person would be presented with what looked like a benign form, press submit on the form, and actually have the user submitting a POST request sent to their bank's web site to transfer money from their bank account or make a purchase on an web store. That is referred to as \"cross-site request forgery\" or CSRF. Headers can play a role in protecting APIs against it.</p> <p>In some avante garde APIs, designers may introduce their own custom headers, which you can spot as different from standard headers using an <code>X-</code> prefix, such as <code>X-API-KEY</code>, but this is rare and certainly not something you should consider when designing early APIs. If you were ever to think, \"hmm should I design a custom header for this?\" the answer is probably no and the extra information should be bundled in a request either as a query parameter or additional field in the request body.</p>"},{"location":"resources/apis/5-api-spec/#response-output-specifications","title":"Response Output Specifications","text":"<p>After a client makes a request to a server, the client needs to know what kind of response(s) to expect back in order to properly handle the response. What is the happy path? What is expected when something goes wrong? Typically response specifications are pairings of response code and response body schema. For example, if a client provides a well formed request to search for a user in a directory, it can expect to receive back a <code>200 OK</code> response code and a JSON response body with a user schema. If a client fails to provide a necessary query parameter, perhaps a <code>400 Bad Request</code> response code is sent with a JSON response body that includes an error schema with different fields than a user schema indicating what went wrong.</p>"},{"location":"resources/apis/5-api-spec/#response-status-code","title":"Response Status Code","text":"<p>These were covered in more detail in the previos reading. Typically your job as an API designer is to specify which codes a resource routes (method + path) may respond with. </p> <p>Success Responses (200-299):</p> <ul> <li>You must specify what data will be returned (the response schema)</li> <li>Example: A 200 response returning user data needs a schema defining the user object structure</li> </ul> <p>Redirection Responses (300-399):</p> <ul> <li>No schema needed</li> <li>The next location is sent in the response headers instead</li> <li>Example: A 301 response includes a header pointing to the new URL</li> </ul> <p>Client Error Responses (400-499):</p> <ul> <li>Need a schema for error information</li> <li>Many API frameworks provide default error schemas</li> <li>Example: A 400 response needs a schema showing how error messages are formatted</li> </ul> <p>Server Error Responses (500-599):</p> <ul> <li>These represent unexpected failures</li> <li>Examples: Server crashes, out-of-memory errors, database connection failures</li> <li>Generally don't need custom schemas since these are unplanned errors</li> <li>Your framework typically handles how these errors are formatted</li> </ul> <p>As an API designer, you'll mainly focus on defining schemas for success responses (200s) and client errors (400s), since these are the planned, normal operations of your API.</p>"},{"location":"resources/apis/5-api-spec/#response-body-schemas","title":"Response Body Schemas","text":"<p>Just like with request body schemas discussed above, an API Designer is tasked with specifying the shape of data clients can expect in response to their request. This is very analagous to specifying the return type of a function or method when programming. In most modern API frameworks, including the one you will learn in this course (FastAPI) the way we specify request and response body schemas is exactly the same and will be very comfortable to you. Why? Because they'll just be class definitions!</p>"},{"location":"resources/apis/5-api-spec/#response-headers","title":"Response Headers","text":"<p>Like request headers, your initial API design work will not be overly concerned with response headers. Why? We'll always respond with a content-type of JSON. Additionally, many advanced response headers (cache control and compression) are handled by middleware and configuration, not explicitly our concern when designing the structure of an API. It's unlikely you'll need 300-level response codes in your first APIs, but these would be a reason you would care about headers: when you redirect a client because a resource URL has moved that information is sent back via a <code>Location</code> header. When the time comes, trust a quick documentation search or LLM prompt will fill you in.</p>"},{"location":"resources/apis/5-api-spec/#kris-can-we-please-just-code-up-an-api","title":"Kris, can we please just code up an API?","text":"<p>Yes! I promise if I believed starting with writing API code first, before these concepts were introduced and vaguely familiar, that it is easy to fail to get lost in the details. Modern API frameworks, like FastAPI, go to great lengths to make the developer experience as convenient and terse as possible. Some of these inputs (like the difference between a dynamic path part and a query parameter) can be hard to spot the differences of, or know why to use one over the other, when writing your first API implementation code. Keep these inputs and specification concerns in mind as we dive in next!</p>"},{"location":"resources/apis/6-fast-api-tutorial/","title":"6. FastAPI and Pydantic Tutorial","text":"<p>FastAPI is a modern, fast (high-performance), standards-first web framework for Python. It's designed around modern Python features such as type annotations (like you used in COMP110). FastAPI helps you both specify and build RESTful HTTP APIs quickly.</p> <p>Pydantic is a library used by FastAPI for data modeling and validation. It is how we will specify the schemas for request and response body data. It enforces type hints at runtime and yields user-friendly errors.</p> <p>Since you are now comfortable with HTTP methods, paths, query parameters, and so on, from the previous parts of this reading, you're in great shape to dive in!</p>"},{"location":"resources/apis/6-fast-api-tutorial/#1-getting-started","title":"1. Getting Started","text":"<p>In a terminal on your host machine, outside of any other <code>git</code> repositories, follow the following steps:</p> <ol> <li> <p>Clone the tutorial repository: Start by cloning the repository at https://github.com/comp423-25s/fastapi-tutorial.git.</p> </li> <li> <p>Open the repository in a VS Code Dev Container. The dev container is based on a modern Microsoft Dev Container image, which we have already used once in this course, so it should load quickly and install the necessary dependencies from <code>requirements.txt</code>. </p> </li> <li> <p>Read the <code>requirements.txt</code> file. Notice that we are taking a dependency on <code>fastapi[standard]</code> package (PIP package repository page). The other two packages, <code>black</code> and <code>pylint</code> are tools used to automatically format your Python code using consistent style (<code>black</code>) and lint check your code for common code smells or issues. We'll learn more about these kinds of tools soon, but they're configured in the dev container settings file if you are curious.</p> </li> <li> <p>Open main.py. This is the entrypoint of our API app and the tutorial starts meow .</p> </li> </ol>"},{"location":"resources/apis/6-fast-api-tutorial/#2-first-route-hello-world","title":"2. First Route: Hello World","text":"<p>There's only one way to venture into new territory in programming: hello, world! Let\u2019s start with the simplest possible route. Update your <code>main.py</code>:</p> <pre><code>from fastapi import FastAPI\n\napp = FastAPI()\n\n@app.get(\"/\")\ndef read_root() -&gt; str:\n    return \"Hello, world!\"\n</code></pre>"},{"location":"resources/apis/6-fast-api-tutorial/#what-does-appget-mean","title":"What Does <code>@app.get(\"/\")</code> Mean?","text":"<ul> <li>Decorator: If you\u2019re new to decorators, think of <code>@something</code> as a way to wrap or register the function that follows. In this case:<ul> <li><code>@app.get(\"/\")</code> tells FastAPI that this function (<code>read_root</code>) handles GET requests to the root path (<code>\"/\"</code>).</li> <li>The function name <code>read_root</code> is arbitrary\u2014choose a meaningful name for your own clarity.</li> </ul> </li> <li>When you return a string (like <code>\"Hello, world!\"</code>), FastAPI automatically converts it into an HTTP response with the body containing that string.</li> </ul>"},{"location":"resources/apis/6-fast-api-tutorial/#3-running-the-development-server","title":"3. Running the Development Server","text":"<p>To run your app in development, use the following command (from within the <code>fastapi-tutorial</code> folder):</p> <pre><code>fastapi run main.py --reload\n</code></pre> <p>By default, FastAPI\u2019s dev server:</p> <ul> <li>Runs at <code>http://127.0.0.1:8000</code> (port 8000). Note: If you have any other dev servers running on this same port (e.g. your MkDocs project's dev server) see the Ports tab in VSCode to learn what port this container's 8000 was mapped to on your host machine.</li> <li>The <code>--reload</code> argument causes the server to watch your files. If you make changes, it auto-reloads so you don\u2019t have to stop and restart the server on every change you make to your code.</li> </ul> <p>Behind the scenes, FastAPI is using a Python package called Uvicorn to handle lower-level HTTP concerns. This is beyond your concern, but if you see anything about <code>uvicorn</code> when reading about FastAPI just know it's a foundational HTTP layer that FastAPI sits above in the architecture. </p> <p>Whenever a request hits <code>GET /</code>, it calls our <code>read_root()</code> function.</p> <p>Take a look at your Python code and be sure you can identify where the following HTTP API dimensions are specified: the HTTP method (1), the path (2), and the response body schema (3). Click the annotation icon, the plus symbol, to expand the answers.</p> <ol> <li> <p>The HTTP method is specified in the <code>@app.get</code> annotation (<code>GET</code>). If it makes it easier to remember, HTTP method specification in FastAPI is implemented as a method call on the FastAPI <code>app</code> object.</p> </li> <li> <p>The path is <code>/</code>, commonly called a root path since it has no parts beyond the slash, and it is specifed as the first parameter of the <code>@app.get()</code> method call.</p> </li> <li> <p>The response body schema is specified as the return type of the route handler function. In this case it is <code>str</code> as the returned value is <code>\"Hello, world!\"</code>.</p> </li> </ol>"},{"location":"resources/apis/6-fast-api-tutorial/#4-adding-another-static-route","title":"4. Adding Another Static Route","text":"<p>Let\u2019s add a second route, say, <code>GET /about</code> which returns some simple text. Update your <code>main.py</code>:</p> <pre><code>from fastapi import FastAPI\n\napp = FastAPI()\n\n@app.get(\"/\")\ndef read_root() -&gt; str:\n    return \"Hello, world!\"\n\n@app.get(\"/about\")\ndef read_about() -&gt; str:\n    return \"This is a simple HTTP API.\"\n</code></pre> <p>Try visiting <code>http://localhost:8000/about</code>. You should see the alternate message!</p>"},{"location":"resources/apis/6-fast-api-tutorial/#5-introducing-a-pydantic-model-and-listing-posts","title":"5. Introducing a Pydantic Model and Listing Posts","text":"<p>Next, let\u2019s introduce a Pydantic model to represent our data. These models serve a dual purpose: first they give us a Python class we can use throughout our server-side code. Second, in conjunction with FastAPI, they will automatically create a schema for our API specifications.</p> <p>We\u2019ll use a simple \"Post\" resource as an example throughout this tutorial. Let's start by returning a list of posts from a global dictionary that we\u2019ll pre-populate with a couple sample posts.</p> <ol> <li>Define the <code>Post</code> model as a subclass of <code>pydantic.BaseModel</code>. Be sure to add the <code>import</code> statement for <code>BaseModel</code>. Define it to have two attributes: <code>id</code> and <code>content</code>.</li> <li>Create a global dictionary <code>posts_db</code> containing two posts keyed by their IDs.</li> <li>Add a route <code>GET /posts</code> to list all posts.</li> </ol> <p>Update <code>main.py</code> with the following:</p> <pre><code>from fastapi import FastAPI\nfrom pydantic import BaseModel\n\napp = FastAPI()\n\nclass Post(BaseModel):\n    id: int\n    content: str\n\n# Prepopulate dictionary of posts\nposts_db = {\n    1: Post(id=1, content=\"Hello FastAPI!\"),\n    2: Post(id=2, content=\"Writing my second post!\")\n}\n\n@app.get(\"/\")\ndef read_root() -&gt; str:\n    return \"Hello, world!\"\n\n@app.get(\"/about\")\ndef read_about() -&gt; str:\n    return \"This is a simple HTTP API.\"\n\n@app.get(\"/posts\")\ndef list_posts() -&gt; list[Post]:\n    return list(posts_db.values())\n</code></pre>"},{"location":"resources/apis/6-fast-api-tutorial/#how-this-works","title":"How This Works","text":"<ul> <li>We store two example posts in a global dictionary, <code>posts_db</code>, keyed by their ID.</li> <li>The route <code>GET /posts</code> returns <code>list(posts_db.values())</code>, which effectively returns all posts as a list.</li> <li>Notice how each value in <code>posts_db</code> is already an instance of <code>Post</code>. When FastAPI sees these objects, it converts them to JSON automatically.</li> </ul> <p>Notice the return type of the <code>list_posts</code> function is a <code>list</code> of <code>Post</code> objects. This is specifying the response body schema. Try visiting this route in your browser to confirm it is working. If you do not see well formatted JSON that is easy to read, try going back to the previous part of this reading and installing a JSON Viewer plugin in your web browser.</p>"},{"location":"resources/apis/6-fast-api-tutorial/#6-adding-a-dynamic-route-to-get-a-single-post","title":"6. Adding a Dynamic Route to Get a Single Post","text":"<p>Now let\u2019s introduce our first dynamic route. For a URL like <code>\"/posts/1\"</code>, we want to look up the post with <code>id=1</code> in our dictionary and return the <code>Post</code> object with this ID. </p> <p>Add the following import and route definition to your <code>main.py</code> file:</p> <pre><code># ... Update FastAPI Imports ...\nfrom fastapi import FastAPI, HTTPException\n\n# ... Earlier App Stays Same ... \n\n@app.get(\"/posts/{post_id}\")\ndef get_post(post_id: int) -&gt; Post:\n    if post_id in posts_db:\n        return posts_db[post_id]\n    raise HTTPException(status_code=404, detail=\"Post not found\")\n</code></pre>"},{"location":"resources/apis/6-fast-api-tutorial/#try-a-happy-path","title":"Try a Happy Path","text":"<p>Try navigating to <code>/posts/1</code> and <code>/posts/2</code> and convince yourself you can trace the flow of information. Specifically, look at how the path is specified with a dynamic part named <code>post_id</code> and how that path part corresponds to the function parameter of the same name. The value is then used to lookup a post with a given ID in the dictionary.</p>"},{"location":"resources/apis/6-fast-api-tutorial/#try-an-unhappy-path","title":"Try an Unhappy Path","text":"<p>Try navigating to <code>/posts/3</code> and seeing the 404 Response. Your browser won't show you the response code directly, but you can open up your browser's Developer Tools and look at your Network history (try reloading) to see the 404 is being sent. Notice this is achieved programatically in FastAPI by raising an <code>HTTPException</code> with a <code>status_code</code> keyword parameter.</p>"},{"location":"resources/apis/6-fast-api-tutorial/#try-an-invalid-path","title":"Try an Invalid Path","text":"<p>Finally, navigate to <code>/posts/abc</code>. Because we declared <code>post_id: int</code>, FastAPI automatically checks if <code>\"abc\"</code> can be converted to an integer. It cannot, so the framework responds with an HTTP 422 Unprocessable Entity error, including a helpful error message about the invalid type. This automatic validation is one of the many reasons FastAPI is a joy to work with compared to its predecessors! Edge case handling like this used to require more boilerplate code from engineers.</p>"},{"location":"resources/apis/6-fast-api-tutorial/#7-understanding-routing-in-modern-api-frameworks","title":"7. Understanding Routing in Modern API Frameworks","text":"<p>Now that you\u2019ve seen both a static route (<code>\"/posts\"</code>) and a dynamic route (<code>\"/posts/{post_id}\"</code>), let\u2019s briefly discuss how routing works in a modern framework like FastAPI. At a high-level, the routing algorithm works like this:</p> <ol> <li>Match the HTTP method (GET, POST, PUT, DELETE, etc.).</li> <li>Match the path pattern (<code>\"/\"</code>, <code>\"/about\"</code>, <code>\"/posts\"</code>, <code>\"/posts/{post_id}\"</code>, etc.).<ul> <li>Routes are checked in the order they are defined which can be surprising. If you define a route like <code>/posts/{post_id}</code> and then a route like <code>/posts/stats</code> follows it, the first route will always be matched (and error). To avoid this common issue, specify routes with static path parts before the dynamic path parts.</li> </ul> </li> <li>Handle parameters (like <code>post_id</code>) including type conversion and validation.</li> <li>Call the function associated with that route.</li> <li>Return a response which might be JSON, HTML, or something else.</li> </ol> <p>Like everything, there is a bit more more machinery behind the scenes, but understanding routing at this level of details is sufficient for now.</p>"},{"location":"resources/apis/6-fast-api-tutorial/#8-automatic-documentation-with-openapi","title":"8. Automatic Documentation with OpenAPI","text":"<p>One major benefit of FastAPI is its automatic generation of OpenAPI documentation. OpenAPI was previously known as Swagger, which was an objectively awful name, so this is a welcomed development in the community. By default, FastAPI sets up:</p> <ul> <li>An OpenAPI specification at <code>/openapi.json</code>.</li> <li>An OpenAPI-based web interface at <code>/docs</code>.</li> </ul> <p>With your FastAPI dev server is running, navivate to:</p> <ul> <li><code>/docs</code> \u2014 a graphical user interface where you can see all endpoints, query them, and see sample requests and responses.</li> <li><code>/openapi.json</code> \u2014 the raw JSON specification for your API.</li> </ul> <p>Because we used <code>pydantic.BaseModel</code> for <code>Post</code>, the schema's model shape will be visible in <code>/docs</code>, including field types and potential validation error states.</p> <p>Why is an OpenAPI spec valuable?</p> <ul> <li>It standardizes your API contract, so other developers or tools (like code generators) know exactly how to consume your endpoints.</li> <li>The <code>/docs</code> interface provides a quick way to try out your endpoints. This will be valuable in the next section.</li> </ul>"},{"location":"resources/apis/6-fast-api-tutorial/#openapi-ui-in-the-wild-csxluncedu","title":"OpenAPI UI in the Wild: CSXL.unc.edu","text":"<p>To hopefully drive home the point that what you are learning is both real and used in the wild, try opening up this URL in a new tab: https://csxl.unc.edu/docs.</p> <p>This is the API for the CSXL web application. Many routes require an authentication token. If you want to try those routes, in a separate tab open up the CSXL website, login, and go to your user profile. Under profile actions, click \"Copy\" on the Bearer Token (which is an authorization key for your user). Paste that in to the <code>/docs</code> unlock screen. Then try running the <code>GET /api/profile</code> API endpoint and you should see your data.</p> <p>Some other fun routes include public ones like listing student organizations or classes in a given semester.</p> <p>If you've used office hours via the CSXL, or applied to be a TA, or reserved a room or checked into the XL Coworking space for a desk to work at... you've already used this API without knowing it! If you scroll around you can see the API end points powering coworking, office hours, and more.</p>"},{"location":"resources/apis/6-fast-api-tutorial/#9-adding-a-post-route","title":"9. Adding a POST Route","text":"<p>Let\u2019s make our API a bit more dynamic by allowing clients to create new posts. We\u2019ll maintain our dictionary <code>posts_db</code> but now add a route for POST. We can do something like this:</p> <pre><code># Update FastAPI Imports\nfrom fastapi import FastAPI, HTTPException, status\n\n# ... Keep other routes the same ...\n\n@app.post(\"/posts\", status_code=status.HTTP_201_CREATED)\ndef create_post(post: Post):\n    if post.id in posts_db:\n        raise HTTPException(status_code=400, detail=\"Post with this ID already exists\")\n    posts_db[post.id] = post\n    return post\n</code></pre>"},{"location":"resources/apis/6-fast-api-tutorial/#walkthrough-of-the-post-route","title":"Walkthrough of the POST Route","text":"<ul> <li>Request Body: FastAPI automatically parses the incoming JSON body into a <code>Post</code> object (thanks to Pydantic). Notice how simple this is! We specified a parameter to the function of a Pydantic model type, there is no conflicting name in a dynamic path part, so FastAPI convention infers this must be the schema of the data in the request body.</li> <li>We \"store\" that post in <code>posts_db</code> using the post\u2019s <code>id</code> as the key.</li> <li>By specifying <code>status_code=status.HTTP_201_CREATED</code>, FastAPI will return a 201 Created status code upon success.</li> <li>We also added a small check to ensure that an existing post with the same ID doesn\u2019t get overwritten.</li> </ul> <p>Open your browser to the API UI page <code>/docs</code>, or reload it (this page will not automatically refresh upon saving your work in the editor). Scroll to the <code>POST /posts</code> endpoint. You can:</p> <ol> <li>Click Try it out.</li> <li>Provide a sample JSON body, e.g.:    <pre><code>{\n  \"id\": 3,\n  \"content\": \"My brand new post!\"\n}\n</code></pre></li> <li>Click Execute and see the response information.</li> </ol> <p>You can then go to the <code>GET /posts/{post_id}</code> endpoint in <code>/docs</code> (or directly at <code>/posts/3</code>) to verify the newly created post.</p> <p>There are a few other activities for you to try here:</p> <ol> <li>Try posting the same JSON and seeing the response code.</li> <li>Try posting a JSON body that is just <code>{\"id\": 4}</code> and seeing the response FastAPI produces. (WOW!)</li> <li>Look at the specific response status code of the happy path (201) in the <code>/docs</code> UI. Notice where this is coming from in the definition. Take a look at how this is specified in the decorator as an additional parameter. There are other ways of responding with a specific status code, but this is preferred in a case like this.</li> </ol> <p>Your 'Database' of Posts Will Reset</p> <p>We are not actually using a \"database\" in this tutorial; just a dictionary stored in our module's global memory a sa simplification. As such, every time your FastAPI server stops and restarts, this dictionary is reset to its initialized contents. That means each time you change your <code>main.py</code> file below, and the server automatically reloads, you will lose any changes made via the API.</p> <p>In a coming unit, we will learn how to connect our API to persistent databases that live in a layer outside of our code such that when we stop and restart our server the data is securely stored and accessible again as soon as our server starts back up.</p>"},{"location":"resources/apis/6-fast-api-tutorial/#10-adding-put-and-delete","title":"10. Adding PUT and DELETE","text":"<p>Finally, let\u2019s round out our basic CRUD functionality (Create, Retrieve, Update, Delete) with PUT (update) and DELETE HTTP method routes. Here\u2019s a simple approach, using our dictionary to check for existence by key:</p> <pre><code># ... previous code remains the same ...\n\n@app.put(\"/posts/{post_id}\")\ndef update_post(post_id: int, updated_post: Post) -&gt; Post:\n    if post_id not in posts_db:\n        raise HTTPException(status_code=404, detail=\"Post not found\")\n    posts_db[post_id] = updated_post\n    return updated_post\n\n@app.delete(\"/posts/{post_id}\", status_code=status.HTTP_204_NO_CONTENT)\ndef delete_post(post_id: int) -&gt; None:\n    if post_id not in posts_db:\n        raise HTTPException(status_code=404, detail=\"Post not found\")\n    del posts_db[post_id]\n    return None # 204 = No Content\n</code></pre>"},{"location":"resources/apis/6-fast-api-tutorial/#put-update-a-resource","title":"PUT: Update a Resource","text":"<p>At the HTTP specification level, PUT is meant to replace the resource at the specified URL. Here, our resource is <code>\"/posts/{post_id}\"</code>. When the client requests <code>PUT /posts/5</code>, for example, we expect the request body to provide the new <code>id</code> and <code>content</code> fields for post <code>5</code> (or whichever post ID is specified). If that post doesn\u2019t exist, we respond with a 404 Not Found.</p>"},{"location":"resources/apis/6-fast-api-tutorial/#delete-remove-a-resource","title":"DELETE: Remove a Resource","text":"<p>Similarly, DELETE aligns directly with the idea of removing the resource at the URL. When a client requests <code>DELETE /posts/5</code>, we remove post <code>5</code> from our <code>posts_db</code>. A successful removal returns a 204 No Content, which communicates that the request succeeded, but there\u2019s no response body.</p>"},{"location":"resources/apis/6-fast-api-tutorial/#testing-put-and-delete-in-the-openapi-ui","title":"Testing PUT and DELETE in the OpenAPI UI","text":"<ol> <li>Open the documentation: Navigate to <code>http://localhost:8000/docs</code>. You\u2019ll see your new <code>PUT</code> and <code>DELETE</code> endpoints under the <code>/posts/{post_id}</code> section.</li> <li>Try PUT:<ul> <li>Expand PUT /posts/{post_id}.</li> <li>Click Try it out.</li> <li>Enter a valid <code>post_id</code> (e.g., <code>1</code>) in the path parameter box.</li> <li>Provide a JSON body with the <code>id</code> and <code>content</code> fields. For instance:     <pre><code>{\n\"id\": 1,\n\"content\": \"Updated content via PUT!\"\n}\n</code></pre></li> <li>Execute the request and verify that the response shows the updated post.</li> <li>Try using the <code>GET</code> routes (list or by ID) to confirm the update is reflected following the update.</li> </ul> </li> <li>Try DELETE:<ul> <li>Expand DELETE /posts/{post_id}.</li> <li>Click Try it out.</li> <li>Enter the <code>post_id</code> for the post you want to remove.</li> <li>Execute, and you\u2019ll see a 204 response indicating success (no body returned).</li> <li>If you try a <code>post_id</code> that doesn\u2019t exist, you\u2019ll get a 404 Not Found.</li> <li>Try using the <code>GET</code> routes (list or by ID) to confirm the <code>POST</code> as deleted from your in-memory \"database\".</li> </ul> </li> </ol> <p>With PUT and DELETE, you now have the full set of HTTP operations to manage a simple resource.</p>"},{"location":"resources/apis/6-fast-api-tutorial/#summary-and-next-steps","title":"Summary and Next Steps","text":"<p>Congratulations! You\u2019ve:</p> <ol> <li>Declared routes with static paths (<code>\"/\"</code>, <code>\"/about\"</code>).</li> <li>Introduced Pydantic models (<code>Post</code>) and used a global dictionary to store and retrieve posts.</li> <li>Created routes to list all posts, get a specific post by ID (dynamic route), and handled invalid IDs.</li> <li>Learned how FastAPI automatically validates path parameters.</li> <li>Explored how FastAPI auto-generates OpenAPI docs at <code>\"/docs\"</code>.</li> <li>Implemented POST, PUT, and DELETE to complete the CRUD operations set.</li> </ol>"},{"location":"resources/apis/6-fast-api-tutorial/#best-practices-beyond-this-tutorial","title":"Best Practices Beyond This Tutorial","text":"<ul> <li>Organize your files: Real projects separate routers, models, and database logic into different modules.</li> <li>Use databases: Instead of an in-memory dictionary, integrate a real database system for persistence.</li> <li>Validation and error handling: Explore more Pydantic features to ensure robust data validation. One place where we did not fully specify our APIs above, for the sake of not getting bogged down in error cases, is when we responded with error status codes but did not specify this in the route decorator. In the next assignment, we will fully specify all expected response types in our route handler functions.</li> <li>Deployment to the Web: You have successfully deployed a static website to the web. Deploying a dynamic web application, like this API, requires some more machinery because our API doesn't just result in static files it results in a running server program. We will learn more about deploying an application like this to the cloud soon.</li> </ul> <p>With these fundamentals, you have a solid handle on building a basic API with FastAPI. Enjoy experimenting, and happy coding!</p>"},{"location":"resources/backend-architecture/0-layered-architecture/","title":"0. Layered Architecture: Separating Concerns in Software Design","text":""},{"location":"resources/backend-architecture/0-layered-architecture/#introduction","title":"Introduction","text":"<p>One of the oldest and most enduring patterns in software engineering is a layered architecture. This pattern enforces a structured separation of concerns, ensuring that each layer of a system only depends on the layer directly beneath it. This approach provides a clean interface between layers and serves as a barrier of abstraction, helping to manage complexity in large systems.</p> <p>A crucial characteristic of layered architecture is that lower layers should have no explicit awareness of higher layers. This means that a foundational layer does not (and should not) know of the higher-level layer that is built on top of it.</p> <p>In this chapter, we will explore layered architecture in the context of building a RESTful backend API using FastAPI. Our goal is to introduce a new layer: the business logic services layer, and understand why it exists and how it interacts with the other layers. Our HTTP API layer will sit above your services layer.</p>"},{"location":"resources/backend-architecture/0-layered-architecture/#what-is-business-logic-and-why-is-it-called-that","title":"What is Business Logic and Why is it Called That?","text":"<p>The services layer is commonly referred to as business logic because it encapsulates the domain-specific rules and workflows that define how an application operates. The term \"business logic\" stems from the idea that this layer contains the core operations that are specific to the application's purpose or domain, regardless of the technical details of how the system is accessed or stored.</p> <p>More precisely, business logic models the application's concerns using simpler, domain-specific objects rather than exposing technical implementation details. By defining these rules in a dedicated layer, we create a more maintainable and adaptable system. This separation allows us to reason about and modify the business rules independently from concerns like HTTP, databases, or external APIs.</p> <p>The HTTP routing layer serves as a facade or translator between the external world and the business logic. This means that it handles incoming requests, extracts necessary parameters, calls the relevant business logic methods, and then formats the output for delivery as an HTTP response. This layer should contain minimal logic of its own, acting only as an interface to the core functionality contained within the business logic layer.</p>"},{"location":"resources/backend-architecture/0-layered-architecture/#motivation-for-separating-concerns","title":"Motivation for Separating Concerns","text":"<p>So far, we have learned about FastAPI routes and how they handle HTTP requests. However, if we write all of our application logic directly inside route handlers, several problems arise:</p> <ol> <li>Tightly Coupled Code \u2013 Routes become entangled with business logic, making the system difficult to modify or extend.</li> <li>Lack of Reusability \u2013 Business logic cannot be easily reused in different contexts, such as CLI tools or background tasks.</li> <li>Difficult Testing \u2013 Testing business rules independently becomes challenging when they are mixed with HTTP concerns.</li> <li>Error Handling Complexity \u2013 If errors are raised directly within route handlers, managing appropriate HTTP responses becomes messy and inconsistent.</li> </ol> <p>To address these issues, we introduce a business logic services layer, which abstracts core application logic away from the HTTP concerns handled by FastAPI routes.</p>"},{"location":"resources/backend-architecture/0-layered-architecture/#layered-architecture-in-our-api","title":"Layered Architecture in Our API","text":"<p>Our API will follow a three-layered architecture:</p> <ol> <li>Routes Layer (Facade/Translator Layer): Responsible for handling HTTP requests and responses. Routes gather inputs, call services, and return results.</li> <li>Service Layer (Business Logic Layer): Contains core domain logic, independent of FastAPI. This layer operates on domain-specific objects and ensures that all application logic is encapsulated here.</li> <li>Persistence Layer (Coming Soon): Handles persistence and retrieval of data, usually via a database. Services interact with this layer but do not concern themselves with storage details. At this stage in the course, we will not concern ourselves with persistence. However, know that it is on the horizon and will be another layer!</li> </ol>"},{"location":"resources/backend-architecture/0-layered-architecture/#simplified-example-user-lookup","title":"Simplified Example: User Lookup","text":"<p>Consider the following, hand-waving example of what this architectural strategy is trying to avoid:</p>"},{"location":"resources/backend-architecture/0-layered-architecture/#mainpy-without-a-services-layer-bad-practice","title":"<code>main.py</code> Without a Services Layer (Bad Practice)","text":"<pre><code>from fastapi import FastAPI, HTTPException\nfrom models import User\n\napp = FastAPI()\n\n@app.get(\"/users/{user_id}\")\ndef get_user(user_id: int):\n    user = database.find_user_by_id(user_id)\n    if not user:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n    return user\n</code></pre> <p>In this example, the route directly accesses the database, performs a lookup, and raises an HTTPException. This mixes business logic (checking if the user exists) with FastAPI-specific concerns (HTTPException and status codes).</p>"},{"location":"resources/backend-architecture/0-layered-architecture/#mainpy-with-a-services-layer-better-practice","title":"<code>main.py</code> with a Services Layer (Better Practice)","text":"<pre><code>from fastapi import FastAPI, HTTPException\nfrom services import UserService, UserDoesNotExistError\nfrom models import User\n\napp = FastAPI()\nuser_service = UserService()\n\n@app.get(\"/users/{user_id}\")\ndef get_user(user_id: int):\n    try:\n        return user_service.get_user(user_id)\n    except UserDoesNotExistError:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n</code></pre>"},{"location":"resources/backend-architecture/0-layered-architecture/#servicespy-the-service-layer-better-practice","title":"<code>services.py</code> the Service Layer (Better Practice)","text":"<pre><code>from models import User\n\nclass UserDoesNotExistError(Exception):\n    pass\n\nclass UserService:\n    def get_user(self, user_id: int) -&gt; User:\n        user = database.find_user_by_id(user_id)\n        if not user:\n            raise UserDoesNotExistError(\"User does not exist\")  # Raises a domain-specific error\n        return user\n</code></pre>"},{"location":"resources/backend-architecture/0-layered-architecture/#key-improvements","title":"Key Improvements:","text":"<ol> <li>The service layer has no knowledge of HTTP. It operates purely on domain-specific objects and raises domain-specific errors (e.g., <code>UserDoesNotExistError</code>).</li> <li>The route handler translates errors into HTTP responses, keeping the API\u2019s interface clean and predictable.</li> <li>Business logic is reusable. The UserService could be used elsewhere, such as in a background job, without modification.</li> </ol>"},{"location":"resources/backend-architecture/0-layered-architecture/#sequence-diagram-of-layers","title":"Sequence Diagram of Layers","text":"<p>Study the following diagram to understand how these layers serve specific purposes and separate concerns.</p> <pre><code>sequenceDiagram\n    participant Client\n    participant API Routing\n    participant Service\n\n    Client-&gt;&gt;API Routing: HTTP GET /users/1\n    API Routing-&gt;&gt;Service: UserService.get_user(1) \n    Service--&gt;&gt;API Routing: User Data Model or throws UserDoesNotExistError\n    API Routing--&gt;&gt;Client: 200 OK (JSON user data) or 404 Not Found</code></pre>"},{"location":"resources/backend-architecture/0-layered-architecture/#characteristics-of-a-well-separated-service-layer","title":"Characteristics of a Well-Separated Service Layer","text":"<p>When designing a services layer, keep the following principles in mind:</p> <ul> <li>No FastAPI-specific imports: The service layer should not reference HTTP concerns (e.g., <code>HTTPException</code>).</li> <li>Works with domain models: Services should receive and return domain-specific objects (e.g., Pydantic models) instead of raw dictionaries or ORM objects.</li> <li>Handles business rules: Any domain-specific logic (e.g., checking if a user has permission to perform an action) should reside in the service layer.</li> <li>Raises domain-specific errors, not HTTP exceptions: The service layer should raise application-specific exceptions, like <code>UserDoesNotExistError</code> or <code>ValueError</code>. The routes layer should handle them and translate them into proper HTTP responses.</li> </ul>"},{"location":"resources/backend-architecture/0-layered-architecture/#looking-ahead-dependency-injection","title":"Looking Ahead: Dependency Injection","text":"<p>So far, our <code>UserService</code> is instantiated directly inside our routes file. This works but is not scalable. In the next reading, you will be introduced to Dependency Injection, a technique that allows us to cleanly manage dependencies like <code>UserService</code> while keeping our code modular and testable.</p>"},{"location":"resources/backend-architecture/1-dependency-injection/","title":"1. Introduction to Dependency Injection in FastAPI","text":""},{"location":"resources/backend-architecture/1-dependency-injection/#what-is-dependency-injection","title":"What is Dependency Injection?","text":"<p>Dependency Injection (DI) is a widely used design pattern that promotes modular, testable, and maintainable code. It is a core principle in many modern application frameworks across various programming languages, including Java (Spring), Python (FastAPI), and TypeScript (Angular). The primary idea behind DI is instead of you constructing dependencies inside a function or class body, you declare them as special parameters. When the application framework calls your function, such as a route, its DI system constructs the argument values behind the scenes and \"injects\" them as arguments. This process is called dependency injection.</p> <p>This concept plays a role in modern layered architectures like you just read about. We previously introduced a business logic services layer that encapsulates domain-specific logic and separates it from the routing layer (which handles HTTP requests and responses). Dependency Injection provides a clean and structured way to introduce and manage dependencies between these layers, keeping them loosely coupled and testable.</p>"},{"location":"resources/backend-architecture/1-dependency-injection/#why-use-dependency-injection","title":"Why Use Dependency Injection?","text":"<p>Dependency Injection helps solve common software design challenges, making applications:</p> <ul> <li>More Maintainable: By loosely coupling dependencies between parts of a system, changes in one part of the application don\u2019t require modifying other parts. Loosely coupled components make it easier to replace or upgrade individual parts of a system without affecting the rest. This reduces the risk of unintended side effects and promotes a more modular and extensible architecture.</li> <li>Easier to Test: With DI, dependencies can be replaced with mock implementations, making unit tests isolated and reliable.</li> <li>More Flexible: By programming to an interface rather than a concrete implementation, different implementations of a dependency can be injected dynamically, allowing for easy configuration changes.</li> <li>Reduces Code Duplication: Centralizing dependency management prevents repeated instantiation of services throughout the codebase.</li> </ul> <p>You\u2019ve actually already encountered DI in FastAPI! Every time a request includes path parameters, query parameters, or request bodies... where did the argument values come from? FastAPI injected them into your route handlers automatically! Now, let\u2019s take this one step further: what if we wanted to inject a custom service into our application to handle business logic?</p>"},{"location":"resources/backend-architecture/1-dependency-injection/#how-does-dependency-injection-work-in-fastapi-routing","title":"How Does Dependency Injection Work in FastAPI Routing?","text":"<p>When a request is received in a FastAPI application, the following steps occur:</p> <ol> <li>Request Routing: FastAPI matches the incoming request's URL and HTTP method to the appropriate route handler function.</li> <li>Dependency Resolution: Before calling the route function, FastAPI checks for any declared dependencies using <code>Depends()</code>. It determines what dependencies are needed and resolves how to instantiate them in a correct order. An injected dependency may have its own injected dependencies that need to be resolved and instantiated first!</li> <li>Dependency Instantiation: If a dependency is a class or function, FastAPI instantiates it (if needed) and injects it into the route function.</li> <li>Function Execution: The route function is called with the injected dependencies passed in as arguments to the routed function's parameters.</li> </ol>"},{"location":"resources/backend-architecture/1-dependency-injection/#tutorial-dependency-injection-in-fastapi","title":"Tutorial: Dependency Injection in FastAPI","text":"<p>To follow along with this quick tutorial on dependency injection, from your host machine's terminal clone the course FastAPI Tutorial repository again, but name the cloned directory <code>di-tutorial</code>:</p> <pre><code>git clone https://github.com/comp423-25s/fastapi-tutorial di-tutorial\n</code></pre> <p>The last argument of <code>di-tutorial</code> is what causes <code>git</code> to clone to a specific directory name on your machine.</p> <p>GitHub's <code>gh</code> CLI Program</p> <p>Now that you are comfortable with fundamental <code>git</code> commands, you may want to install GitHub's <code>gh</code> tool on your host machine. Instructions here: https://cli.github.com</p> <p>The <code>gh</code> tool allows you to interact with GitHub's REST API from your command line. You can do things like create new GitHub repositories, list issues, and nearly anything you can do from the GitHub web page.</p> <p>Once you have <code>gh</code>, you can achieve the clone command above with:</p> <pre><code>gh repo clone comp423-25s/fastapi-tutorial di-tutorial\n</code></pre> <p>Open the repo directory in a VS Code Dev Container.</p>"},{"location":"resources/backend-architecture/1-dependency-injection/#step-1-defining-models","title":"Step 1: Defining Models","text":"<p>Let's implement a Rock, Paper, Scissors API! Create a new file in the project's root directory named <code>models.py</code>. We'll define our Pydantic data models here. Review the code below and then copy it into <code>models.py</code>:</p> models.py<pre><code>from enum import Enum\nfrom datetime import datetime\nfrom typing import Annotated, TypeAlias\nfrom pydantic import BaseModel, Field\n\n\nclass Choice(str, Enum):\n    rock = \"rock\"\n    paper = \"paper\"\n    scissors = \"scissors\"\n\n\nChoiceField: TypeAlias = Annotated[\n    Choice,\n    Field(\n        description=\"Choice of rock, paper, or scissors.\",\n        examples=[\"rock\", \"paper\", \"scissors\"],\n    ),\n]\n\n\nclass GamePlay(BaseModel):\n    user_choice: ChoiceField\n\n\nclass GameResult(BaseModel):\n    timestamp: Annotated[datetime, Field(description=\"When the game was played.\")]\n    user_choice: ChoiceField\n    api_choice: ChoiceField\n    user_wins: Annotated[bool, Field(description=\"Did the user win the game?\")]\n</code></pre> <p>Using a <code>TypeAlias</code> for repeated type annotations</p> <p>Notice <code>ChoiceField</code> is defined as a <code>TypeAlias</code> for the annotated type of <code>Choice</code> such that it contains the <code>Field</code> information with an API description.</p> <p>When you find an annotated type is repeated in multiple places in your Pydantic models or FastAPI routes, using a <code>TypeAlias</code> to cut down on the repetition and make the code more readable is a best practice.</p> <p>In Python, a protocol is similar to an interface in Java. It defines a contract that a class must follow without enforcing inheritance. This allows for better flexibility and testability.</p>"},{"location":"resources/backend-architecture/1-dependency-injection/#step-2-defining-a-game-service","title":"Step 2: Defining a <code>Game</code> Service","text":"<p>Now let's define a service class that handles the serious \"business logic\" of rock paper scissors. Review the contents below and copy the contents to a new file named <code>services.py</code>:</p> services.py<pre><code>from datetime import datetime\nfrom random import choice as random_choice\nfrom models import GamePlay, GameResult, Choice\n\n\nclass GameService:\n    \"\"\"Service for processing game plays.\n\n    This class provides functionality to simulate a game between a user and the API.\n    \"\"\"\n\n    def play(self, gameplay: GamePlay) -&gt; GameResult:\n        \"\"\"Play a game round.\n\n        Args:\n            gameplay (GamePlay): An object encapsulating the user's choice.\n\n        Returns:\n            GameResult: The outcome of the game including user and API choices, and win flag.\n        \"\"\"\n        api_choice: Choice = self._random_choice()\n\n        return GameResult(\n            timestamp=datetime.now(),\n            user_choice=gameplay.user_choice,\n            api_choice=api_choice,\n            user_wins=self._does_user_win(gameplay.user_choice, api_choice),\n        )\n\n    def _random_choice(self) -&gt; Choice:\n        \"\"\"Select a random choice for the API.\n\n        Returns:\n            Choice: A randomly chosen game option.\n        \"\"\"\n        return random_choice(list(Choice))\n\n    def _does_user_win(self, user_choice: Choice, api_choice: Choice) -&gt; bool:\n        \"\"\"Determine if the user wins based on choices.\n\n        Args:\n            user_choice (Choice): The user's chosen option.\n            api_choice (Choice): The API's chosen option.\n\n        Returns:\n            bool: True if the user wins, False otherwise.\n        \"\"\"\n        result: tuple[Choice, Choice] = (user_choice, api_choice)\n        winning_results: set[tuple[Choice, Choice]] = {\n            (Choice.rock, Choice.scissors),\n            (Choice.paper, Choice.rock),\n            (Choice.scissors, Choice.paper),\n        }\n        return result in winning_results\n</code></pre> <p>Notice that this <code>services.py</code> module knows nothing about HTTP or FastAPI. Its imports are data models and some library functionality for randomization. This is just plain-old Python! This is the \"core\" logic of our little app, though, and you can easily imagine how writing unit tests for it would be straightforward.</p>"},{"location":"resources/backend-architecture/1-dependency-injection/#step-3-establishing-a-fastapi-route-to-play-the-game","title":"Step 3: Establishing a FastAPI Route to Play the Game!","text":"<p>Now that we have a service defined, how do we add a route that uses dependency injection to utilize it? Similar to how we declare parameters of routes that are populated by dynamic <code>Path</code> parts, <code>Query</code> parameters, or <code>Body</code> payloads.</p> <p>What HTTP method would you choose for the game playing REST API endpoint?</p> <p>We will model playing a round of this game with a <code>POST</code> method. Even though we are not (yet) storing a history of games or creating anything, playing a game is not idempotent: we get back a new result each time we play. Not only do the <code>api_choice</code> and <code>user_wins</code> fields update, the <code>timestamp</code> reflects the latest game play.</p>"},{"location":"resources/backend-architecture/1-dependency-injection/#starting-without-dependency-injection","title":"Starting Without Dependency Injection","text":"<p>Update your <code>main.py</code> file to reflect the following. Note: this example does not yet rely upon dependency injection! We will refactor this to make use of dependency injection next.</p> main.py<pre><code>\"\"\"FastAPI main entrypoint file.\"\"\"\n\nfrom typing import Annotated, TypeAlias\nfrom fastapi import FastAPI, Body, Depends\nfrom models import GamePlay, GameResult\nfrom services import GameService\n\napp = FastAPI()\n\n\n@app.post(\"/play\")\ndef play(\n    user_choice: Annotated[\n        GamePlay,\n        Body(description=\"User's choice of rock, paper, or scissors.\"),\n    ],\n) -&gt; GameResult:\n    # Here we construct a GameService *without* dependency injection...\n    game_svc: GameService = GameService() # (1)!\n    return game_svc.play(user_choice)\n</code></pre> <ol> <li>Notice that fully inside the body of this function is where we declare a local variable of type <code>GameService</code> and construct it. If we later wanted to use a different object, which conformed to the interface <code>GameService</code> implements, how would we do so? We couldn't without changing this source code! Being able to swap out implementations is very useful in one common software engineering practice we will soon embrace: unit testing. In unit testing, to isolate the behavior of a single function, dependency injection gives you the ability to substitute fake dependencies in such that you are only testing the unit(s) of code you care about.</li> </ol> <p>Check for understanding: Why is line 19 problematic? Why do we want to use dependency injection instead?</p> <p>Try to answer this question for yourself before clicking the annotation symbol at the end of line 19 to reveal the answer.</p>"},{"location":"resources/backend-architecture/1-dependency-injection/#refactor-to-dependency-injection","title":"Refactor to Dependency Injection","text":"<p>The updated definition of the <code>play</code> function provides an example with FastAPI's dependency injection utilized:</p> main.py<pre><code>@app.post(\"/play\")\ndef play(\n    user_choice: Annotated[\n        GamePlay,\n        Body(description=\"User's choice of rock, paper, or scissors.\"),\n    ],\n    game_svc: Annotated[GameService, Depends()],\n) -&gt; GameResult:\n    return game_svc.play(user_choice)\n</code></pre> <p>Be sure to run the FastAPI server and try out the route from the OpenAPI <code>/docs</code> user interface!</p> <p>Notice on line 17 we added an additional parameter to the <code>play</code> function definition. Its type is <code>Annotated[GameService, Depends()]</code>. The <code>Depends()</code> call is what declaratively signals to FastAPI this is a dependency injected parameter. How does it know to construct an instance of <code>GameService</code>? Because it's annotating the type <code>GameService</code>. </p> <p>There are other ways of using <code>Depends</code>, too, like giving it a factory function and specifying the construction elsewhere. You can also specify the annotated type to be a <code>Protocol</code> (similar to a Java interface) and giving a concrete classname as an argument to <code>Depends</code>. That's how COMP301 should have taught you to approach a similar problem. However, we will adhere to a software engineering goal: don't overengineer until you have good reason to!</p> <p>This is dependency injection! There is a HUGE win here: your dependency is now a parameter passed in, or injected, from the outside. It is not hardwired in to the route body. Thus, if you wanted to unit test this function, you could easily supply a mock instance of a <code>GameService</code> and isolate the function's behavior. That said, this example is so trivial that the notion of isolating it for a unit test is a bit silly. </p>"},{"location":"resources/backend-architecture/1-dependency-injection/#step-4-adding-functionality","title":"Step 4. Adding Functionality","text":"<p>Let's record a history of games played since the service was last restarted. We will use global module memory for this, but realize this is only a stopgap solution until we learn more about data persistence.</p> services.py<pre><code># ... the import statements above remain the same ...\n\n# This is *NOT* a database, just a hack for now...\n_db: list[GameResult] = []\n\nclass GameService:\n    \"\"\"Service for processing game plays.\n\n    This class provides functionality to simulate a game between a user and the API.\n    \"\"\"\n\n    def play(self, gameplay: GamePlay) -&gt; GameResult:\n        \"\"\"Play a game round.\n\n        Args:\n            gameplay (GamePlay): An object encapsulating the user's choice.\n\n        Returns:\n            GameResult: The outcome of the game including user and API choices, and win flag.\n        \"\"\"\n        api_choice: Choice = self._random_choice()\n        result = GameResult(\n            timestamp=datetime.now(),\n            user_choice=gameplay.user_choice,\n            api_choice=api_choice,\n            user_wins=self._does_user_win(gameplay.user_choice, api_choice),\n        )\n        _db.append(result)\n        return result\n\n    def get_results(self) -&gt; list[GameResult]:\n        \"\"\"Get all game results.\n\n        Returns:\n            list[GameResult]: A list of all game results.\n        \"\"\"\n        return _db\n\n    # ... the \"private\" helper methods remain the same ...\n</code></pre> <p>Notice, we are using a simple global variable in the module to store results. Why not use an instance variable in the <code>GameService</code>? FastAPI's dependency injection system constructs a new instance of <code>GameService</code> on each request. With a little more effort we could get around this with something like the singleton design pattern, to ensure only one instance of <code>GameService</code> is shared across all requests, but that's beyond the scope of this tutorial.</p> <p>Let's add a route for listing the history of games played to <code>main.py</code>.</p> main.py<pre><code>@app.get(\"/results\")\ndef log(game_svc: Annotated[GameService, Depends()]) -&gt; list[GameResult]:\n    return game_svc.get_results()\n</code></pre> <p>After saving, your FastAPI server reloads so global memory is cleared. Try playing a few games and then trying out your <code>/results</code> route. You can access it both from the <code>/docs</code> UI as well as from the browser directly, since the route's method is <code>GET</code>.</p>"},{"location":"resources/backend-architecture/1-dependency-injection/#cleaning-up-the-types","title":"Cleaning Up the Types","text":"<p>There's one last minor tweak to make to help clean this up. You will find this useful as you write many routes which depend on the same service. Let's use a <code>TypeAlias</code> for our dependency injected <code>GameService</code> rather than repeat this annotated type everywhere. Try making the following changes in <code>main.py</code>:</p> main.py<pre><code>\"\"\"FastAPI main entrypoint file.\"\"\"\n\nfrom typing import Annotated, TypeAlias\nfrom fastapi import FastAPI, Body, Depends\nfrom models import GamePlay, GameResult\nfrom services import GameService\n\napp = FastAPI()\n\nGameServiceDI: TypeAlias = Annotated[GameService, Depends()]\n\n\n@app.post(\"/play\")\ndef play(\n    user_choice: Annotated[\n        GamePlay,\n        Body(description=\"User's choice of rock, paper, or scissors.\"),\n    ],\n    game_svc: GameServiceDI,\n) -&gt; GameResult:\n    return game_svc.play(user_choice)\n\n\n@app.get(\"/results\")\ndef log(game_svc: GameServiceDI) -&gt; list[GameResult]:\n    return game_svc.get_results()\n</code></pre> <p>Ah, that's not only a little easier on the eyes, but since the <code>TypeAlias</code> is defined in one place we could now customize <code>Depends()</code> and have more control over how the <code>GameService</code> dependency gets injected across all of these routes. If we wanted to move toward a singleton pattern, for example, we could do so here.</p>"},{"location":"resources/backend-architecture/1-dependency-injection/#the-power-of-dependency-injection-in-fastapi","title":"The Power of Dependency Injection in FastAPI","text":"<p>Congratulations on completing a first foray into dependency injection (DI) in FastAPI\u2014starting from its core principles and working through a hands-on example with a Rock, Paper, Scissors. You\u2019ve now seen how DI promotes modularity, testability, and maintainability in your applications. Instead of hardwiring dependencies, we leveraged FastAPI's <code>Depends()</code> function to keep our code clean and flexible.</p> <p>Through this tutorial, you've learned how to:</p> <ul> <li>Define business logic services that remain independent of the HTTP framework.</li> <li>Use FastAPI\u2019s DI system to inject dependencies in a structured way.</li> <li>Improve testability by allowing easy substitution of dependencies.</li> <li>Reduce code duplication and enhance maintainability.</li> </ul> <p>In time, you will learn some more advanced uses of DI in FastAPI:</p> <ul> <li>Services which inject other services into their constructors. This works just like you'd expect, but still feels magical! Since our services will ultimately depend on a database layer, we will inject the database dependencies into the service.</li> <li>A nicer way of declaring routes which have many query parameters using <code>Depends</code>. Read more here.</li> <li>Singleton dependencies which have only one instance shared across all requests.</li> </ul> <p>By adopting dependency injection, you're setting yourself up for scalable and maintainable application development. Whether you're working on a small personal project or a large-scale system, mastering DI ensures that your code remains clean, modular, and future-proof. Now, take what you\u2019ve learned, and complete exercise 01's service layer using dependency injection best practices!</p>"},{"location":"resources/backend-architecture/2-testing/","title":"2. Introduction to Testing","text":""},{"location":"resources/backend-architecture/2-testing/#why-is-testing-important","title":"Why is Testing Important?","text":"<p>Software can be fragile. One small change can break something else without warning. Testing brings stability and trust. It confirms that your code works as expected, your bug fixes stick, and that new features don\u2019t undo old ones. There are many reasons for testing software, but some of the top reasons for testing are:</p> <ul> <li>Acceptance and Verification: Tests show that your software meets user needs and business goals. You can point to a test and say, \u201cYes, this works as intended.\u201d</li> <li>Regression Prevention: With automated tests, you\u2019ll know if new code breaks existing functionality. This saves you from introducing the same bug again and again. When you fix a bug, writing a test locks in the fix. If that bug ever shows up again, the test fails and alerts you.</li> <li>Confidence in Code Changes: With good test coverage, refactoring or adding new features feels safer. You don\u2019t have to worry as much about sneaky breakage.</li> </ul> <p>A great test suite isn\u2019t just about catching bugs\u2014it transforms the way you write code. When you have fast, reliable tests, you can experiment freely, refactor fearlessly, and build new features with confidence. Instead of worrying about whether a change might break something unexpected, you get immediate feedback. Green tests? You\u2019re good to go. Red tests? You know exactly where to look. This is especially valuable in a team setting where you might not have written the original code or its tests. With a strong test suite, you don\u2019t have to rely on gut instinct or deep dives into unfamiliar code; the tests will tell you if your changes introduce problems.</p> <p>Good tests also reinforce clean abstraction layers. When a module or API has solid test coverage, you can trust its interface without constantly checking its implementation. This means you can operate at a higher level, focusing on solving the problem at hand rather than getting bogged down in lower-level details. It\u2019s a massive boost to developer productivity and experience\u2014when the foundational layers are proven to work well with testing, and they \"just work\" in practice, you can build on top of them with confidence.</p>"},{"location":"resources/backend-architecture/2-testing/#types-of-software-tests","title":"Types of Software Tests","text":"<p>Not all tests are created equal, and choosing the right type of test for a given scenario is crucial. A well-balanced test suite includes different types of tests, each serving a specific purpose. Understanding their strengths, limitations, and trade-offs allows you to write intentional tests\u2014tests that prove something meaningful and valuable about your codebase.</p>"},{"location":"resources/backend-architecture/2-testing/#the-importance-of-intentional-testing","title":"The Importance of Intentional Testing","text":"<p>Testing isn't just about writing tests for the sake of it; it's about proving that your code behaves correctly under the conditions that matter most. Before writing a test, ask yourself:</p> <ul> <li>What am I trying to prove?   Are you checking that a function returns the right output? That two components communicate correctly? That your system handles heavy load?  </li> <li>Why is this test valuable?   Does it provide meaningful feedback? Will it catch real-world issues?  </li> <li>Where should I set the test\u2019s boundaries?   Should I isolate a single function, or does the value come from testing multiple pieces together?  </li> </ul> <p>When you\u2019re intentional about testing, you avoid redundant or low-value tests and focus on what truly increases confidence in your software.</p>"},{"location":"resources/backend-architecture/2-testing/#common-types-of-tests","title":"Common Types of Tests","text":"<p>Each type of test provides different insights into your software. Here\u2019s a breakdown of the most common ones:</p> <ul> <li> <p>Unit Tests Unit tests focus on individual functions or methods in isolation. They are fast, reliable, and help confirm that small pieces of logic work correctly. If a unit test fails, you know exactly where the problem is. </p> <ul> <li>Strengths: Quick to run, easy to debug, useful for pinpointing issues in logic.  </li> <li>Limitations: They only test small pieces of the system and don\u2019t guarantee that components work well together.  </li> <li>Best for: Business logic, calculations, pure functions, and methods with clear inputs and outputs.  </li> </ul> </li> <li> <p>Integration Tests These verify that multiple parts of the system work together as expected. An integration test might check how your API interacts with a service, or how a service interacts with a database, or, generally whether two or more units of code coordinate correctly.  </p> <ul> <li>Strengths: Helps catch real-world interaction issues that unit tests miss.  </li> <li>Limitations: If integration test includes external systems, they are slower than unit tests. Failures can be harder to diagnose since scope is inclusive of many parts of the system.  </li> <li>Best for: Dependencies between services, database interactions, API calls, authentication flows, and so on.  </li> </ul> </li> <li> <p>End-to-End (E2E) Tests E2E tests simulate a user\u2019s experience through the entire system, from frontend clicks to backend responses and database updates. These tests confirm that everything works together in a real-world scenario.  </p> <ul> <li>Strengths: Provides high confidence that the entire system functions correctly.  </li> <li>Limitations: Slow, complex to set up, and brittle\u2014small UI changes can break them.  </li> <li>Best for: Critical user flows, such as signups, payments, and login/logout sequences.  </li> </ul> </li> <li> <p>Performance Tests / Profiling Performance tests, often technically referred to as profiling, measure how fast the system responds and how efficiently it handles requests. These tests help ensure that the software remains performant under normal and peak conditions.  </p> <ul> <li>Strengths: Helps detect slow response times, memory leaks, and bottlenecks.  </li> <li>Limitations: Requires specialized tools and environments to get accurate results.  </li> <li>Best for: Response time benchmarks, caching strategies, and database query optimization.  </li> </ul> </li> <li> <p>Load Tests A type of performance test that determines how well the system handles high levels of traffic. Load tests simulate many users interacting with the system simultaneously to expose potential crashes, slowdowns, race conditions and more.  </p> <ul> <li>Strengths: Helps anticipate scaling issues before they impact real users.  </li> <li>Limitations: Can be expensive and time-consuming to run effectively.  </li> <li>Best for: Large-scale web applications, APIs, and cloud services.  </li> </ul> </li> <li> <p>Security Tests Security tests probe the system for vulnerabilities like SQL injection, cross-site scripting (XSS), and authentication flaws.  </p> <ul> <li>Strengths: Helps identify potential security risks before attackers do.  </li> <li>Limitations: Often requires specialized security expertise and tools.  </li> <li>Best for: Web applications, authentication systems, and applications that handle sensitive data.</li> </ul> </li> </ul>"},{"location":"resources/backend-architecture/2-testing/#making-testing-trade-offs","title":"Making Testing Trade-offs","text":"<p>There\u2019s no one-size-fits-all approach to testing. Each type has trade-offs: unit tests are fast but limited in scope, while E2E tests are comprehensive but slow. Writing too many of the wrong kinds of tests can be as bad as writing none at all.</p> <p>In this tutorial, we focus on unit and integration tests because they provide a strong balance of speed, reliability, and practical value. They help you validate business logic and confirm that your system components interact correctly without the overhead of full E2E testing.</p> <p>The key takeaway? Test intentionally. Every test you write should prove something important about your software.</p>"},{"location":"resources/backend-architecture/2-testing/#integration-testing-a-fastapi-backend","title":"Integration Testing a FastAPI Backend","text":"<p>Integration tests verify that different parts of your system work together correctly. For our FastAPI application, this means testing the complete request flow: from HTTP request handling through routing, dependency injection, and down to service implementation.</p>"},{"location":"resources/backend-architecture/2-testing/#understanding-pytest","title":"Understanding <code>pytest</code>","text":"<p>Before diving into FastAPI testing, let's understand pytest - Python's premier testing framework. pytest uses simple conventions to discover and run tests:</p> <ul> <li>Test files must be named <code>test_*.py</code> or <code>*_test.py</code></li> <li>Test functions must start with <code>test_</code></li> </ul> <p>The <code>pytest</code> module is installed standard on Microsoft's Dev Container, but it's just <code>pip</code> package you can install and add to <code>requirements.txt</code>, on systems that do not bundle it. You can run <code>pytest</code> from the terminal in several ways:</p> <pre><code># Run all tests in current directory and subdirectories\npytest\n\n# Run tests with detailed output\npytest -v\n\n# Run tests in a specific file\npytest test_main.py\n\n# Run a specific test\npytest test_main.py::test_play_route\n</code></pre>"},{"location":"resources/backend-architecture/2-testing/#basic-fastapi-integration-test-setup","title":"Basic FastAPI Integration Test Setup","text":"<p>Let's start with a basic integration test for our Rock, Paper, Scissors game. Create a file named <code>test_main.py</code>:</p> test_main.py<pre><code>from fastapi.testclient import TestClient\nfrom main import app\n\nclient = TestClient(app)\n\ndef test_play_route_integration():\n    \"\"\"Test that the /play endpoint handles basic gameplay correctly.\"\"\"\n    response = client.post(\"/play\", json={\"user_choice\": \"rock\"})\n\n    # Verify HTTP-level details\n    assert response.status_code == 200\n    assert response.headers[\"content-type\"] == \"application/json\"\n\n    # Verify response structure\n    data = response.json()\n    assert \"user_choice\" in data\n    assert \"api_choice\" in data\n    assert \"user_wins\" in data\n    assert \"timestamp\" in data\n\n    # Verify data types and constraints\n    assert data[\"user_choice\"] == \"rock\"  # Our input is preserved\n    assert data[\"api_choice\"] in [\"rock\", \"paper\", \"scissors\"]\n    assert isinstance(data[\"user_wins\"], bool)\n</code></pre> <p>This test verifies several integration points:</p> <ol> <li>FastAPI correctly routes the <code>POST</code> request to the <code>/play</code> endpoint</li> <li>The endpoint successfully deserializes JSON into our <code>GamePlay</code> model</li> <li>The dependency injection system provides a <code>GameService</code> instance</li> <li>The service processes the game and returns a valid result</li> <li>FastAPI successfully serializes the <code>GameResult</code> back to JSON</li> </ol> <p>Notice something this test does not prove: the logic of who wins. This illustrates one of the key benefits and downsides of an integration test versus a unit test: the benefit is you have confidence everything comes together from request-to-response in one test. The downside is it would be very cumbersome to try and fully test logic in this way. Sure, you could write a loop that plays the game enough times and re-encode the winning logic to test a winner, but that's thinking about an integration test at the wrong level of abstraction. That style of test is more suited for a unit test, which we will explore shortly.</p>"},{"location":"resources/backend-architecture/2-testing/#unit-testing","title":"Unit Testing","text":"<p>Let's dive into unit testing! While integration tests give us confidence that all the pieces work together, unit tests help us verify that individual components work correctly in isolation. This granular approach makes it easier to pinpoint issues when tests fail and often leads to better designed components.</p> <p>Typically, you will write unit tests before writing integration tests, but since we will introduce some new techniques for isolating behavior in unit tests, we wanted to start with the bigger picture and then zoom in to emphasize the contrasts before getting into the details.</p>"},{"location":"resources/backend-architecture/2-testing/#unit-testing-the-game-service","title":"Unit Testing the Game Service","text":"<p>Let's start by testing the core game logic in our <code>GameService</code> class. Since this service needs to make random choices, we'll use Python's <code>unittest.mock.patch</code> to temporarily replace the random choice behavior during our tests and control it ourselves:</p> test_services.py<pre><code>from unittest.mock import MagicMock\nfrom services import GameService\nfrom models import Choice, GamePlay, GameResult\nfrom datetime import datetime, UTC\n\n\ndef create_mock_game_service(choice_to_return: Choice) -&gt; GameService:\n    \"\"\"Create a GameService with a mocked _random_choice method\"\"\"\n    service = GameService()\n    service._random_choice = MagicMock(return_value=choice_to_return)\n    return service\n\n\ndef test_game_service_rock_beats_scissors():\n    # Create a service that will return scissors\n    service = create_mock_game_service(Choice.scissors)\n    result = service.play(GamePlay(user_choice=Choice.rock))\n\n    assert result.user_choice == Choice.rock\n    assert result.api_choice == Choice.scissors\n    assert result.user_wins is True\n    service._random_choice.assert_called_once()\n\n\ndef test_game_service_scissors_loses_to_rock():\n    service = create_mock_game_service(Choice.rock)\n    result = service.play(GamePlay(user_choice=Choice.scissors))\n\n    assert result.user_choice == Choice.scissors\n    assert result.api_choice == Choice.rock\n    assert result.user_wins is False\n    service._random_choice.assert_called_once()\n\n\ndef test_game_service_draw():\n    service = create_mock_game_service(Choice.paper)\n    result = service.play(GamePlay(user_choice=Choice.paper))\n\n    assert result.user_choice == Choice.paper\n    assert result.api_choice == Choice.paper\n    assert result.user_wins is False  # Draws count as API wins\n    service._random_choice.assert_called_once()\n\n\ndef test_game_service_all_combinations():\n    \"\"\"Test all possible game combinations systematically\"\"\"\n    # Define all possible combinations and expected results\n    test_cases = [\n        (Choice.rock, Choice.scissors, True),  # Rock beats scissors\n        (Choice.rock, Choice.paper, False),  # Rock loses to paper\n        (Choice.rock, Choice.rock, False),  # Rock ties rock (API wins)\n        (Choice.paper, Choice.rock, True),  # Paper beats rock\n        (Choice.paper, Choice.scissors, False),  # Paper loses to scissors\n        (Choice.paper, Choice.paper, False),  # Paper ties paper (API wins)\n        (Choice.scissors, Choice.paper, True),  # Scissors beats paper\n        (Choice.scissors, Choice.rock, False),  # Scissors loses to rock\n        (Choice.scissors, Choice.scissors, False),  # Scissors ties scissors (API wins)\n    ]\n\n    for user_choice, api_choice, expected_win in test_cases:\n        # Create a service that will return the API choice we want to test\n        service = create_mock_game_service(api_choice)\n        result = service.play(GamePlay(user_choice=user_choice))\n\n        assert result.user_choice == user_choice\n        assert result.api_choice == api_choice\n        assert result.user_wins == expected_win, (\n            f\"Failed when user played {user_choice.value} \"\n            f\"against API's {api_choice.value}\"\n        )\n        service._random_choice.assert_called_once()\n</code></pre>"},{"location":"resources/backend-architecture/2-testing/#understanding-patchobject","title":"Understanding patch.object","text":"<p>The <code>patch.object</code> decorator/context manager is a powerful feature in Python's <code>unittest.mock</code> library that temporarily replaces attributes or methods during testing. Let's break down what's happening:</p> <pre><code>with patch.object(GameService, '_random_choice', return_value=Choice.scissors):\n    service = GameService()\n    # ... test code ...\n</code></pre> <p>This code:</p> <ol> <li>Temporarily replaces, or patches, the <code>_random_choice</code> method on the <code>GameService</code> class</li> <li>Any instance of <code>GameService</code> created within the <code>with</code> block will use the patched version</li> <li>The patched version always returns <code>Choice.scissors</code> (or whatever we specify as the <code>return_value</code> of the method)</li> <li>When the <code>with</code> block ends, the original method is restored</li> </ol> <p>Patching is particularly useful when testing code that has external dependencies or non-deterministic behavior (like randomization). By patching, we make the behavior predictable during testing while preserving the actual implementation for normal use.</p>"},{"location":"resources/backend-architecture/2-testing/#unit-testing-route-functions","title":"Unit Testing Route Functions","text":"<p>Now let's look at unit testing the FastAPI route functions. These tests focus on the route function itself, isolated from both HTTP concerns and service implementation. We will isolate the routing concerns by calling the functions directly and manually controlling the arguments (FastAPI routes are just plain-old functions, after all!). Additionally, we will isolate the service by mocking it, a technique best seen and explained with some real usage:</p> test_main_unit.py<pre><code>    # Verify how the service was used\n    mock_service.play.assert_called_once_with(GamePlay(user_choice=Choice.rock))\n</code></pre>"},{"location":"resources/backend-architecture/2-testing/#understanding-magicmock","title":"Understanding MagicMock","text":"<p>MagicMock is a powerful class in Python's <code>unittest.mock</code> library that creates objects that can pretend to be anything. Here's what makes it special:</p> <ol> <li> <p>Automatic Method Creation: MagicMock automatically creates mock methods and attributes as you try to use them. When we access <code>mock_service.play</code>, MagicMock creates a play attribute that is itself a MagicMock. In doing so, as shown, you can also control the value returned by calling this mock method.</p> </li> <li> <p>Call Tracking: MagicMock records all calls made to it, including:</p> <ul> <li>How many times it was called</li> <li>What arguments were used</li> <li>In what order calls occurred</li> </ul> </li> <li> <p>Verification Methods: MagicMock provides methods to verify how it was used:</p> <ul> <li><code>assert_called()</code> - Was it called at all?</li> <li><code>assert_called_once()</code> - Was it called exactly once?</li> <li><code>assert_called_with(args)</code> - Was it called with specific arguments?</li> <li><code>assert_called_once_with(args)</code> - Was it called once with specific arguments?</li> </ul> </li> </ol> <p>In our route test, <code>mock_service.play.assert_called_once_with(GamePlay(user_choice=Choice.rock))</code> proves that:</p> <ol> <li>The route called the service's play method exactly once</li> <li>It passed exactly the Choice.rock argument</li> <li>It didn't call any other methods on the service</li> </ol> <p>This verification is valuable because it proves that:</p> <ul> <li>The route correctly forwards the user's choice to the service</li> <li>It doesn't call the service multiple times</li> <li>It doesn't modify the choice before passing it to the service</li> <li>It doesn't call any other service methods it shouldn't</li> </ul> <p>Admittedly, given how simple this route function is, unit testing it can feel a bit silly. Indeed, it's far more code to isolate the unit test than the actual implementation itself. The earlier tests proved more valuable things to our system. So, why write unit tests for such simple functions? If you had the integration test we started with, there probably isn't a valid reason to in this case! We didn't really prove anything useful other than more tightly encoding dependencies which already exist in our system. In large enough teams, though, policies of \"every public function or method must be tested\" is an axiom that helps prevent code bases from slipping into the dangerous territory of being untested.</p> <p>So, when does unit testing a route function make more sense? Primarily when there is actual logic in the route function. This is common when you are returning a non-200 status code and helps verify expected responses. Or perhaps there's some additional logic the route is doing to pre-process inputs. For our purposes, if a route function just returns a method call and you already have an integration test: don't worry about the unit test.</p>"},{"location":"resources/backend-architecture/2-testing/#different-approaches-for-different-needs","title":"Different Approaches for Different Needs","text":"<p>Notice we're using different mocking approaches for different parts of our system:</p> <ol> <li> <p>We used <code>patch</code> to:</p> <ul> <li>Override some internal method (such as randomization)</li> <li>The patched method is an implementation detail</li> <li>We want to isolate the service's game logic</li> </ul> </li> <li> <p>We used <code>MagicMock</code> to:</p> <ul> <li>Verify interaction patterns between route and service</li> <li>Isolate the route from the service that is normally dependency injected</li> <li>We care about the interface of <code>GameService</code> in the unit tests for the route, not implementation. The implementation is tested in <code>GameService</code> unit tests.</li> </ul> </li> </ol> <p>This illustrates an important testing principle: choose your testing tools based on what you're trying to prove about your code. Sometimes you need to control behavior (patch), sometimes you need to verify interactions (MagicMock), and sometimes you might need both, which MagicMock can also do.</p>"},{"location":"resources/backend-architecture/2-testing/#the-limitations-of-tests","title":"The Limitations of Tests","text":"<p>While testing is essential for software quality, we must understand its fundamental limitations. Tests provide confidence, not certainty, and even the most comprehensive test suite cannot guarantee bug-free software. The sheer number of possible input combinations, environmental factors, and user behaviors makes complete testing impossible. Tests themselves can be flawed, suffering from false positives that pass when they should fail, or false negatives that fail when they should pass. Perhaps most insidiously, tests might continue passing while no longer validating what they were intended to check due to changing assumptions about system behavior or business rules.</p>"},{"location":"resources/backend-architecture/2-testing/#test-driven-development-and-practical-strategies","title":"Test-Driven Development and Practical Strategies","text":"<p>Test-Driven Development (TDD) offers a structured approach to address many testing challenges through its Red-Green-Refactor cycle:</p> <ol> <li>Red: Write a failing test that defines the desired behavior</li> <li>Green: Write just enough code to make the test pass</li> <li>Refactor: Improve the code while maintaining passing tests</li> </ol> <p>This methodology helps prevent over-engineering while ensuring code meets requirements. Different projects demand different testing approaches - critical systems require comprehensive testing at all levels, while rapid prototypes might focus only on key functionality.</p> <p>When working with AI tools for testing, treat them as helpful starting points rather than complete solutions. While AI can quickly generate test cases and identify edge cases, human oversight remains crucial for ensuring tests are meaningful and align with project requirements.</p>"},{"location":"resources/backend-architecture/2-testing/#the-economics-and-culture-of-testing","title":"The Economics and Culture of Testing","text":"<p>Testing represents a significant investment in time, technical infrastructure, and knowledge. Not every piece of code needs the same level of testing, and not every test provides equal value. Success requires building a culture that values testing while remaining pragmatic about testing efforts.</p>"},{"location":"resources/backend-architecture/2-testing/#summary","title":"Summary","text":"<p>Testing is a fundamental skill. If you invest time and energy into learning how to test well it will pay dividends in your career. Throughout this chapter, we've explored how different types of tests\u2014from unit tests that verify individual components to integration tests that ensure systems work together\u2014serve distinct but complementary purposes. We've seen how testing transforms development itself: with a strong test suite, you can refactor confidently, catch regressions early, and build more reliable software. More importantly, we've learned that effective testing isn't about achieving perfect coverage or following rigid rules\u2014it's about writing intentional tests that prove something meaningful about your code. As you apply these testing practices in your work, you'll find yourself writing more maintainable code, catching issues earlier, and delivering features with greater confidence.</p>"},{"location":"resources/backend-architecture/3-ci-cd/","title":"3. Introduction to CI/CD","text":"<p>Modern software development moves fast. Teams need to deliver features quickly, fix bugs rapidly, and maintain high-quality code\u2014all while ensuring deployments are smooth and reliable. This is where CI/CD comes in.  </p> <ul> <li>Continuous Integration (CI) automates the process of running tests on new code changes whenever they are pushed to a central repository. This ensures that issues are caught early and developers get fast feedback. It can also be used during a Pull Request workflow to prevent a branch from being merged into <code>main</code> until it passes all tests.</li> <li>Continuous Deployment (CD) takes things a step further by automating the deployment of every successfully tested change directly into production\u2014without manual intervention. This allows teams to ship updates multiple times a day with confidence.  </li> </ul> <p>Continuous Delivery vs. Continuous Deployment</p> <p>Continuous Delivery ensures that every tested change is ready for deployment but still requires a manual approval step before going live. Continuous Deployment, on the other hand, removes this manual step and automatically pushes changes to production once they pass all verification checks.  </p> <p>In this tutorial, we\u2019re focusing on Continuous Deployment, where code moves to production immediately after passing CI tests.  </p>"},{"location":"resources/backend-architecture/3-ci-cd/#why-cicd-matters","title":"Why CI/CD Matters","text":"<p>Manually running tests and deploying software can be slow, inconsistent, and prone to human error. CI/CD automates these critical steps, leading to:  </p> <ul> <li>Faster development cycles \u2013 Developers can push changes more frequently without worrying about breaking things.  </li> <li>Less anxiety \u2013 Automated testing and deployment remove the guesswork, making releases predictable and repeatable.  </li> <li>Higher confidence \u2013 If every change is tested and verified before it reaches production, teams can move forward with fewer worries about stability.  </li> </ul> <p>By embracing automation, teams shift from a culture of hesitation and uncertainty to one of confidence and speed. Instead of fearing deployment days, developers can focus on building great software.  </p>"},{"location":"resources/backend-architecture/3-ci-cd/#how-continuous-integration-ci-works","title":"How Continuous Integration (CI) Works","text":"<p>CI ensures that every code change is automatically tested before being merged or deployed. When a developer pushes code, a CI system:  </p> <ol> <li>Detects the change  </li> <li>Automatically runs tests  </li> <li>Reports results, allowing developers to catch and fix issues early  </li> <li>Prevents merging into the main branch (if using pull requests) or deployment if tests fail  </li> </ol> <p>A tool like GitHub Actions can be used to define workflows that trigger these tests on every push or pull request. If tests fail, CI can block the code from being merged or stop the deployment process, ensuring that only properly tested changes move forward.  </p>"},{"location":"resources/backend-architecture/3-ci-cd/#how-continuous-deployment-cd-works","title":"How Continuous Deployment (CD) Works","text":"<p>Once CI verifies that code changes pass all tests, CD ensures those changes are automatically deployed to production without human intervention. A system like OKD (OpenShift Kubernetes Distribution) or Kubernetes can handle deployment by:  </p> <ol> <li>Being notified of <code>CI</code> successfully passing all tests on <code>main</code> and receiving a webhook callback</li> <li>A <code>BuildConfig</code> begins a new <code>Build</code> by pulling repository and building a Docker image</li> <li>The Docker image is pushed to an <code>ImageStream</code></li> <li>The <code>ImageStream</code> notifies a <code>Deployment</code> that a new image is available</li> <li>The <code>Deployment</code> spins up a new <code>Pod</code> (Container) based on the image</li> <li>Once the new <code>Pod</code> is available, it turns off the old <code>Pod</code> running the previous version</li> </ol> <p>With Continuous Deployment, every change that passes CI and merged to <code>main</code> is deployed to production and live, allowing teams to ship updates faster, reduce the risk of large releases, and catch issues early.  </p>"},{"location":"resources/backend-architecture/3-ci-cd/#cicd-demo-pipeline-tutorial","title":"CI/CD Demo Pipeline Tutorial","text":"<p>In the next tutorial, you\u2019ll configure a full CI/CD pipeline for a sample repository, using GitHub Actions for CI and Kubernetes (via OKD) for CD. Get ready to see automation in action!</p>"},{"location":"resources/backend-architecture/3-ci-cd/#cloning-the-starter-repository","title":"Cloning the Starter Repository","text":"<p>Individually, accept the following GitHub Classroom assignment: https://classroom.github.com/a/7izSQo1P</p> <p>Then, on your host machine outside of any other project, clone your repository. Open this repository in VSCode and then open it in a VS Code Dev Container.</p> <p>If you are on Windows and the build fails, open <code>.devcontainer/post-create.sh</code> and check the line ending setting for this file. It needs to be <code>LF</code> not <code>CRLF</code>. If you see <code>CRLF</code> in the bottom right of the screen, click it, select <code>LF</code> and then save the file and rebuild the container.</p> <p>Before continuing, a few things to open and check out:</p> <ol> <li>In the <code>.devcontainer/devcontainer.json</code> the <code>postCreateCommand</code> runs the <code>bash</code> script named <code>post-create.sh</code></li> <li>In the <code>.devcontainer/post-create.sh</code> script, you will notice the first set of steps \"Installs the <code>oc</code> CLI tool.\" This <code>oc</code> tool is what we will use to communicate with your production setup in the cloud. This script also installs our Python packages from <code>requirements.txt</code></li> <li>Open a new terminal in VSCode and run <code>pytest</code> to see that tests pass.</li> <li>Open up <code>main.py</code> to see that this app simply produces the current times in two timezones. You can try running the app locally with <code>fastapi dev --reload</code>. Navigate to the root URL and <code>/docs</code> to see the app in question is very simple.</li> </ol> <p>Now you are ready to setup continuous integration and continuous deployment!</p>"},{"location":"resources/backend-architecture/3-ci-cd/#continuous-integration-demo","title":"Continuous Integration Demo","text":"<p>Continuous Integration is controlled by a GitHub Action. Since our project's test are written in Pytest, we want the CI system to run <code>pytest</code> as part of its workflow. We've already set you up well for this, normally you'd have to create the following directory structure and <code>yml</code> file, but for your part to get this going you need to:</p> <ol> <li>Open <code>.github/workflows/test.yml</code></li> <li>Read the names of each step to see how the worklflow builds up</li> <li>Find the commented lines:     <pre><code>- name: Test with pytest (CI)\n    run: pytest\n</code></pre></li> <li>Uncomment those lines.</li> </ol> <p>Save the file then make a git commit, on <code>main</code>, with these changes. Then, push your changes to <code>origin</code>.. For this tutorial, to keep the focus on what's important, we will make all commits and pushes to <code>main</code>. In a full industrial CI/CD pipeline, you would take this further and be sure pushes are only happening on branches and merged in to <code>main</code>, following CI success, via pull requests.</p> <p>Now, go open the repository you just setup and pushed to in your web browser on GitHub. Look for the Actions tab. Click it and look to see the most recent workflow run. It may still be running or have finished with a green check. Click it. Click through to <code>test</code>. Then take a look at the steps of this workflow looking specifically for <code>Test with pytest (CI)</code>. Expand that step. Here you can see the 3 tests passed! GitHub actions ran your tests on their machines as part of this CI process. Since everything passed, <code>pytest</code>'s process exited with status code 0, and GitHub Actions uses that as a signal that your CI workflow succeeded. Once it does, and any steps following succeed, you will see a green check!</p> <p>If you navigate back to the \"Code\" tab in GitHub, then you will also see a small green check just above your list of files, following your commit message. Click it and you can see this check is part of the indication that continuous integration succeeded thanks to our \"Run Python Tests\" workflow succeeding. (Notice: that name came from the name we gave the workflow at the top of the <code>test.yml</code> action specification.)</p>"},{"location":"resources/backend-architecture/3-ci-cd/#continuous-deployment-demo","title":"Continuous Deployment Demo","text":"<p>Setting up deployment takes some more effort because we need to stand up a production cloud environment. Our production environment will be UNC Cloud Apps' \"OKD\" cluster, set up just for our course!</p> <p>You need to be connected to Eduroam, or connected to UNC VPN (instructions here), in order to successfully use OKD. If you are on a home network, UNC guest, or other network, be sure to connect via VPN.</p> <p>Login to <code>OKD</code> by going to: https://console.apps.unc.edu</p> <p>(If your login does not succeed, it's likely because you did not previously register for Cloud Apps. You can do so by going to https://cloudapps.unc.edu/ and following the Sign Up steps. It can take up to 15 minutes following Sign Up for the OKD link above to work correctly. In the interim, feel free to follow along with your neighbor.)</p> <p>Once logged in you sould see OKD in the upper-left corner. If you see \"Red Hat\", be sure you opened the link above.</p> <p>Now that you are logged in, go to the upper-right corner and click your ONYEN and go to the \"Copy Login Command\" link. Click Display Token. In this, copy the command in the first text box. Paste it into your dev container's terminal (which has the <code>oc</code> command-line application for interfacing with a Red Hat Open-Shift Kubernetes cluster installed).</p> <p>Before proceeding, switch to your personal OKD project using your ONYEN. For example, if your ONYEN is \"jdoe\", run: <pre><code>oc project comp590-140-25sp-jdoe\n</code></pre></p> <p>If the above command fails, restart the steps above! The following will not work until you are able to access your project via <code>oc</code>.</p>"},{"location":"resources/backend-architecture/3-ci-cd/#deploying-to-okd-using-cicd-integrated-deploymentconfig","title":"Deploying to OKD using CI/CD (Integrated DeploymentConfig)","text":"<p>This guide shows you how to deploy this FastAPI project to OKD following a successful CI/CD test run using an integrated DeploymentConfig that includes its own BuildConfig and ImageStream. In this setup, after tests pass in GitHub Actions, the build is automatically triggered on OKD. The BuildConfig uses the <code>Dockerfile</code> from the repository, and the resulting image is deployed automatically with the app name set to <code>comp423-cicd-demo</code>.</p>"},{"location":"resources/backend-architecture/3-ci-cd/#1-generating-a-personal-access-token-for-your-private-repository","title":"1. Generating a Personal Access Token for Your Private Repository","text":"<p>OKD needs to be able to clone your private repository from GitHub. In order to do so, you will generate a Personal Access Token (legacy) and configure your OKD project to use this access token.</p> <p>Follow these steps to create a Personal Access Token (PAT) with read access for your repository:</p> <ol> <li> <p>Sign in to GitHub </p> <ul> <li>Go to GitHub and log in with your account.</li> </ul> </li> <li> <p>Navigate to Developer Settings </p> <ul> <li>Click on your profile picture (top-right corner) and select Settings.</li> <li>In the left sidebar, click on Developer settings.</li> </ul> </li> <li> <p>Access Personal Access Tokens </p> <ul> <li>Click on Personal access tokens.</li> <li>Select Tokens (classic).</li> </ul> </li> <li> <p>Generate a New Token </p> <ul> <li>Click the \"Generate new token\" button.</li> <li>For classic tokens, click \"Generate new token (classic)\".</li> <li>Provide a descriptive name for the token (e.g., \"OKD-Repo-ReadAccess\").</li> </ul> </li> <li> <p>Select the Scope </p> <ul> <li>Under \"Select scopes\", check the <code>repo</code> scope.</li> </ul> </li> <li> <p>Generate and Copy the Token </p> <ul> <li>Click \"Generate token\".</li> <li>Copy the generated token to your clipboard immediately. You won't be able to see it again later.</li> </ul> </li> </ol>"},{"location":"resources/backend-architecture/3-ci-cd/#2-register-your-github-pat-with-a-secret-stored-in-okd","title":"2. Register your GitHub PAT with a Secret Stored in OKD","text":"<p>From the built-in terminal in your dev container:</p> <ol> <li>Create a GitHub access secret    Create a secret in OKD that contains your GitHub username and a personal access token (PAT) with appropriate repo rights. Remove the surrounding less than and greater than signs when substituting your personal GitHub username and PAT in the command below:    <pre><code>oc create secret generic comp423-cicd-git-credentials \\\n    --from-literal=username=&lt;your-github-username&gt; \\\n    --from-literal=password=&lt;your-github-pat&gt; \\\n    --type=kubernetes.io/basic-auth\n</code></pre></li> <li>Label the Secret    Add the label \"app=comp423-cicd-demo\" to make it easier to delete everything related to this demo later on:    <pre><code>oc label secret comp423-cicd-git-credentials app=comp423-cicd-demo\n</code></pre></li> </ol>"},{"location":"resources/backend-architecture/3-ci-cd/#3-create-an-integrated-deployment-with-buildconfig-imagestream-and-source-secret","title":"3. Create an Integrated Deployment (with BuildConfig, ImageStream, and Source Secret)","text":"<p>OKD's <code>new-app</code> command is a handy all-in-one command to create an application from a repository that handles setting up the app's <code>BuildConfig</code>, <code>ImageStream</code>, and <code>Deployment</code> behind the scenes.</p> <pre><code>oc new-app . \\\n--name=comp423-cicd-demo \\\n--source-secret=comp423-cicd-git-credentials \\\n--strategy=docker \\\n--labels=app=comp423-cicd-demo\n</code></pre> <p>Explanation:  </p> <ul> <li>The <code>--source-secret=comp423-cicd-git-credentials</code> flag directs OKD to use the secret you created to clone the private repo.</li> <li>The <code>--labels=app=comp423-cicd-demo</code> parameter tags the created BuildConfig, ImageStream, and DeploymentConfig with a common label, \"app=comp423-cicd-demo\".</li> </ul> <p>Over in OKD, in the web browser, you should look to see the application appear in your project. You should find its build status and track the build.</p>"},{"location":"resources/backend-architecture/3-ci-cd/#4-expose-the-service","title":"4. Expose the Service","text":"<p>Your OKD pods are securely only accessible to you, or other users you give access to, and not the general public. To begin the process of exposing a pod to the public, we need to expose a route to it in OKD. The following <code>create route</code> will automatically generate a route URL securely connecting your service to the outside world:</p> <pre><code>oc create route edge --service=comp423-cicd-demo\n</code></pre> <p>Routes can also be created with custom hostnames, but the automatic name is sufficient for this tutorial.</p> <p>After doing so, once your project successfully builds, you can run the following command:</p> <pre><code>oc get route comp423-cicd-demo\n</code></pre> <p>What this will do is show you the public route to your app running in production. Try opening this URL in your browser or your phone. This is live on the public internet!</p>"},{"location":"resources/backend-architecture/3-ci-cd/#5-setting-up-continuous-deployment-using-a-webhook-callback-from-github-actions-to-okd","title":"5. Setting up Continuous Deployment Using a Webhook Callback from GitHub Actions to OKD","text":"<p>A webhook callback is a mechanism by which OKD can be triggered to start a new build when it receives an HTTP POST request. In this setup, after your tests pass on GitHub Actions, a POST request is sent to the webhook URL configured in your OKD BuildConfig. This webhook URL contains a secret token that ensures only authorized calls (i.e. from your GitHub Actions) can trigger a build. </p> <p>To configure this:</p> <ol> <li>To get the webhook URL:    <pre><code>oc describe bc/comp423-cicd-demo | grep -C 1 generic\n</code></pre></li> <li>To get the webhook secret token:    <pre><code>oc get bc comp423-cicd-demo -o yaml | grep -C 1 generic\n</code></pre>    Look for the \"generic\" trigger section and note the secret token.</li> <li>In your GitHub repository, add this full URL as a secret named <code>WEBHOOK_URL</code>:</li> <li>Go to Settings &gt; Security &gt; Secrets and Variables &gt; Actions &gt; Repository Secrets &gt; New Repository Secret.</li> <li>Set the name to <code>WEBHOOK_URL</code> and paste in the full URL. The full URL is comprised of the URL template found in the command above and substituting the secret into the path. This secret in your repository is what will be referenced in the next GitHub Action variable. Note: you will NOT put the URL directly into the action definition!</li> <li>In your GitHub Actions workflow, uncomment the following step to use <code>curl</code> to send a POST request to trigger a new build:    <pre><code>- name: Trigger OKD Build via Webhook\n  if: success()\n  run: |\n    curl -X POST \"${{ secrets.WEBHOOK_URL }}\"\n</code></pre>    This step uses the webhook URL to trigger a build only when prior steps succeed, thanks to the <code>if</code> condition where <code>success()</code> is established by the workflow steps prior.</li> </ol> <p>You can try testing this by modifying something simple in your application that will not break the tests. For example, perhaps just switch the ordering in <code>main.py</code> of the two timezones in the <code>TIMEZONES</code> constant. Make a commit with the changes to your app and <code>test.yml</code>. Push the commit to <code>main</code> (we can circumvent best practices about branching for educational purposes here!) When you open your GitHub repository, you can see the action flow through the steps. In one of the final steps you will see \"Deploy to production\". If you then go look at OKD, you will see a new build is kicked off and working to build a new production image. Once it completes, the image is deployed to your app and it is live on the web! This is continuous integration (via testing) and continuous deployment (contingent on tests passing)! These flows are common in industrial software engineering settings.</p>"},{"location":"resources/backend-architecture/3-ci-cd/#summary","title":"Summary","text":"<p>This setup allows a robust CI/CD pipeline where any push or PR to the main branch runs tests via GitHub Actions. After successful tests, a secure webhook callback is sent to OKD to start a build. The configuration ensures the Dockerfile (from the \".production\" directory) is used and the application (tagged with \"app=comp423-cicd-demo\") is deployed with minimal manual intervention, while keeping sensitive tokens secure within GitHub Secrets.</p> <p>Happy deploying!</p>"},{"location":"resources/backend-architecture/3-ci-cd/#cleaning-up-cicd-demo-components-on-okd","title":"Cleaning Up CI/CD Demo Components on OKD","text":"<p>When you're ready to clean up all the components created by this deployment, you can delete them all in one step by using the label selector:</p> <pre><code>oc delete all -l app=comp423-cicd-demo\noc delete secret -l app=comp423-cicd-demo\n</code></pre> <p>These commands will remove all resources (Deployment, BuildConfig, ImageStream, Service, Route, and secrets) tagged with \"app=comp423-cicd-demo\" while leaving your OKD project intact for future work.</p>"},{"location":"resources/database/1-sql/","title":"1. Introduction to Relational Databases &amp; SQL","text":""},{"location":"resources/database/1-sql/#what-is-a-relational-database","title":"What is a Relational Database?","text":"<p>A relational database is a way to store and organize data in a structured format using tables. Each table consists of rows (records) and columns (fields). The power of relational databases comes from their ability to establish relationships between tables, allowing for efficient data retrieval and consistency.</p> <p>Unlike temporary data storage solutions, relational databases persist data to disk, meaning information is retained even after the database system shuts down. This persistence makes relational databases essential for applications that require long-term data storage, such as banking systems, e-commerce platforms, and content management systems.</p>"},{"location":"resources/database/1-sql/#a-brief-history-of-relational-databases-and-sql","title":"A Brief History of Relational Databases and SQL","text":"<p>The concept of relational databases was introduced by Edgar F. Codd in 1970 while working at IBM. He proposed the relational model, which organizes data into structured tables and uses mathematical relational algebra for querying and manipulating data.</p> <p>Before relational databases, most systems used hierarchical or network databases, which were rigid and difficult to scale. Codd\u2019s relational model revolutionized database management by making data more flexible and easier to query.</p> <p>The Structured Query Language (SQL) was later developed in the 1970s at IBM as a way to interact with relational databases. It became the standard language for querying and managing relational data and was eventually adopted by major database systems.</p>"},{"location":"resources/database/1-sql/#modern-popular-relational-databases","title":"Modern, Popular Relational Databases","text":"<p>Today's most popular relational databases include:</p> <ul> <li>PostgreSQL (open-source, widely used for modern applications)</li> <li>MySQL (common in web applications)</li> <li>SQLite (lightweight, used in mobile and embedded systems)</li> <li>Microsoft SQL Server (enterprise-level database solution)</li> <li>Oracle Database (widely used in large corporations)</li> </ul>"},{"location":"resources/database/1-sql/#key-abstractions-in-a-relational-database","title":"Key Abstractions in a Relational Database","text":"<p>A relational database management system (RDBMS) provides a structured way to store and manipulate data. At the core of an RDBMS are the following key abstractions:</p>"},{"location":"resources/database/1-sql/#tables","title":"Tables","text":"<p>A table is the fundamental structure in an RDBMS. It represents a collection of related data and is analogous to a spreadsheet or a well-organized list. Each table consists of columns (fields) that define the types of data stored and rows (records) that contain actual data entries.</p>"},{"location":"resources/database/1-sql/#columns-fields","title":"Columns (Fields)","text":"<p>A column defines the type of data that a table can store for a particular attribute. Each column has a data type that constrains the values it can hold, ensuring consistency and efficiency.</p> <p>Columns can have constraints such as: - NOT NULL \u2013 Ensures the column cannot have empty values. - UNIQUE \u2013 Guarantees that all values in the column are distinct. - CHECK \u2013 Enforces a condition on the column's values. - DEFAULT \u2013 Assigns a default value if no explicit value is provided.</p> <p>Some columns also have fixed maximum widths for storage efficiency. For example, a <code>VARCHAR(255)</code> column ensures that no value stored exceeds 255 characters. Limiting column widths helps optimize performance because it enables more efficient indexing, improves retrieval speed, and reduces overall memory consumption.</p> <p>Here is a table of common PostgreSQL data types:</p> Data Type Description <code>INTEGER</code> Whole numbers (e.g., 1, 2, 3) <code>SERIAL</code> Auto-incrementing integer (commonly used for primary keys) <code>TEXT</code> Variable-length string (unlimited size) <code>VARCHAR(n)</code> String with a maximum length of <code>n</code> characters <code>BOOLEAN</code> True or False values <code>DATE</code> Stores dates (YYYY-MM-DD) <code>TIMESTAMP</code> Stores date and time information <code>DECIMAL(p, s)</code> Precise fixed-point decimal numbers <code>REAL</code> / <code>DOUBLE PRECISION</code> Floating-point numbers"},{"location":"resources/database/1-sql/#rows-records","title":"Rows (Records)","text":"<p>A row represents a single entry in a table, storing a unique combination of values across all the columns. Each row corresponds to a distinct instance of the entity the table models.</p> <p>An analogy to Object-Oriented Programming (OOP) can be helpful here: - A table is like a class definition in OOP. - Columns define the attributes of the class. - Rows are like instances (objects) created from the class.</p> <p>For example, consider a <code>users</code> table: <pre><code>CREATE TABLE users (\n    id SERIAL PRIMARY KEY,\n    name TEXT NOT NULL,\n    email TEXT UNIQUE NOT NULL\n);\n</code></pre> This is similar to defining a <code>User</code> class in OOP: <pre><code>class User:\n    def __init__(self, id, name, email):\n        self.id = id\n        self.name = name\n        self.email = email\n</code></pre> Each row in the <code>users</code> table represents a different <code>User</code> object with unique values for <code>id</code>, <code>name</code>, and <code>email</code>.</p>"},{"location":"resources/database/1-sql/#primary-keys","title":"Primary Keys","text":"<p>A primary key uniquely identifies each row in a table, ensuring that no two rows have the same identifier. The choice of primary key depends on the scale and nature of the data.</p> <p>For smaller datasets, using an <code>INTEGER</code> or <code>SERIAL</code> column as a unique ID is common. However, for very large-scale databases\u2014such as those storing tweets, Instagram posts, or large-scale event logs\u2014alternative schemes like UUIDs (Universally Unique Identifiers) or timestamp-based IDs are often used. These approaches provide a much larger range of unique identifiers and offer benefits such as distributed uniqueness and time-ordering properties.</p> <p>For our purposes, since we are working with small datasets, we will primarily use serial integers as primary keys.</p>"},{"location":"resources/database/1-sql/#understanding-sql-a-domain-specific-language-for-databases","title":"Understanding SQL: A Domain-Specific Language for Databases","text":"<p>SQL (Structured Query Language) is a programming language designed specifically for interacting with relational databases. Unlike general-purpose programming languages like Python or Java, SQL is domain-specific, meaning it is specialized for tasks related to storing, retrieving, and manipulating structured data.</p> <p>SQL enables users to:</p> <ul> <li>Define and modify database structures.</li> <li>Insert, update, and delete data within those structures.</li> <li>Query and retrieve meaningful information efficiently.</li> </ul> <p>SQL is divided into two main categories:</p>"},{"location":"resources/database/1-sql/#1-ddl-data-definition-language","title":"1. DDL (Data Definition Language)","text":"<p>DDL is responsible for defining and managing the structure of a database. Commands in this category affect the schema of a database, such as creating, modifying, and deleting tables.</p>"},{"location":"resources/database/1-sql/#common-ddl-commands","title":"Common DDL Commands:","text":"<ul> <li><code>CREATE TABLE</code> \u2013 Defines a new table structure.</li> <li><code>ALTER TABLE</code> \u2013 Modifies an existing table.</li> <li><code>DROP TABLE</code> \u2013 Deletes a table and all its data.</li> </ul> <p>Example:</p> <pre><code>CREATE TABLE users (\n    id SERIAL PRIMARY KEY,\n    name TEXT NOT NULL,\n    email TEXT UNIQUE NOT NULL\n);\n</code></pre>"},{"location":"resources/database/1-sql/#2-dml-data-manipulation-language","title":"2. DML (Data Manipulation Language)","text":"<p>DML is used to work with the data inside database tables. These commands allow users to insert new records, update existing ones, delete data, and query stored information.</p>"},{"location":"resources/database/1-sql/#common-dml-commands","title":"Common DML Commands:","text":"<ul> <li><code>INSERT INTO</code> \u2013 Adds new records to a table.</li> <li><code>UPDATE</code> \u2013 Modifies existing records.</li> <li><code>DELETE</code> \u2013 Removes records.</li> <li><code>SELECT</code> \u2013 Retrieves data from tables.</li> </ul> <p>Example:</p> <pre><code>INSERT INTO users (name, email) VALUES ('Alice', 'alice@email.com');\nSELECT * FROM users;\n</code></pre> <p>By mastering both DDL and DML, you gain the ability to design, manage, and interact with relational databases effectively. Understanding these distinctions helps clarify how SQL serves both structural and operational purposes in database management.</p>"},{"location":"resources/database/1-sql/#experimenting-with-sql-in-a-postgresql-docker-container","title":"Experimenting with SQL in a PostgreSQL Docker Container","text":"<p>To follow along with this tutorial, you can run PostgreSQL inside a Docker container.</p>"},{"location":"resources/database/1-sql/#step-1-pull-and-run-postgresql","title":"Step 1: Pull and Run PostgreSQL","text":"<p>From your host machine's terminal run the following command to start a PostgreSQL container:</p> <pre><code>docker run \\\n  --name postgres \\\n  --env POSTGRES_PASSWORD=mysecretpassword \\\n  --publish 5432:5432 \\\n  --detach \\\n  postgres:latest\n</code></pre> <p>Explanation of flags:</p> <ul> <li><code>--name postgres</code> \u2192 Names the container postgres.</li> <li><code>--env POSTGRES_PASSWORD=mysecretpassword</code> \u2192 Sets the default password for the PostgreSQL instance.</li> <li><code>--publish 5432:5432</code> \u2192 Maps port 5432 from the container to the host, allowing connections.</li> <li><code>--detach</code> \u2192 Runs the container in detached mode, meaning it runs in the background.</li> <li><code>postgres:latest</code> \u2192 Specifies the PostgreSQL image to use, with <code>latest</code> pulling the most recent stable version.</li> </ul>"},{"location":"resources/database/1-sql/#where-is-the-data-stored","title":"Where is the Data Stored?","text":"<p>When using a Docker container without explicit volume mapping, PostgreSQL stores its data inside the container\u2019s filesystem. This means that even if you stop and restart the container, your data will still be available. However, if the container is removed, the data will be lost.</p> <p>For production environments, best practice is to mount a volume to ensure that database files persist independently of the container lifecycle. However, for simplicity in this tutorial, we are relying on the container's internal storage.</p>"},{"location":"resources/database/1-sql/#step-2-connect-to-postgresql","title":"Step 2: Connect to PostgreSQL","text":"<p>To interact with the running PostgreSQL container, use the following command which runs the CLI <code>psql</code> Postgres client:</p> <pre><code>docker exec \\\n  --interactive \\\n  --tty \\\n  --user postgres \\\n  postgres \\\n  psql\n</code></pre> <p>This command does not start a new container; it connects to the existing detached container named <code>postgres</code> and runs the <code>psql</code> command inside it.</p>"},{"location":"resources/database/1-sql/#exiting-postgresql","title":"Exiting PostgreSQL","text":"<p>To quit <code>psql</code>, type:</p> <pre><code>\\q\n</code></pre>"},{"location":"resources/database/1-sql/#stopping-restarting-and-removing-the-postgresql-container","title":"Stopping, Restarting, and Removing the PostgreSQL Container","text":"<p>If you need to stop the PostgreSQL container but keep the data intact, run:</p> <pre><code>docker stop postgres\n</code></pre> <p>To restart the container and restore access to the database, use:</p> <pre><code>docker start postgres\n</code></pre> <p>This ensures that all changes made to the database remain intact between restarts.</p> <p>If you no longer need the container and want to permanently delete it, along with all stored data, run:</p> <pre><code>docker rm postgres\n</code></pre> <p>Important: Removing the container deletes all stored data since we are not using a volume in this tutorial. In real applications, using a Docker volume ensures data persistence beyond container removal. Now that you have PostgreSQL running inside Docker, you can start writing SQL commands.</p>"},{"location":"resources/database/1-sql/#basics-of-sql-creating-tables-inserting-data-and-querying-with-select","title":"Basics of SQL: Creating Tables, Inserting Data, and Querying with SELECT","text":"<p>Now that we have PostgreSQL running inside Docker, let's explore some basic SQL commands. We'll cover:</p> <ul> <li>Creating tables</li> <li>Inserting data</li> <li>Querying data with SELECT</li> <li>Filtering results with WHERE</li> <li>Sorting and limiting query results</li> <li>Joining related tables</li> </ul>"},{"location":"resources/database/1-sql/#creating-a-table","title":"Creating a Table","text":"<p>A table in SQL is defined using the <code>CREATE TABLE</code> statement. Each table consists of columns, where each column has a specific data type.</p> <p>Let's create a <code>users</code> table:</p> <pre><code>CREATE TABLE users (\n    id SERIAL PRIMARY KEY,\n    name TEXT NOT NULL,\n    email TEXT UNIQUE NOT NULL,\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n);\n</code></pre>"},{"location":"resources/database/1-sql/#explanation","title":"Explanation:","text":"<ul> <li><code>id SERIAL PRIMARY KEY</code> \u2192 A unique, auto-incrementing identifier.</li> <li><code>name TEXT NOT NULL</code> \u2192 A required text field.</li> <li><code>email TEXT UNIQUE NOT NULL</code> \u2192 Ensures emails are unique and required.</li> <li><code>created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP</code> \u2192 Automatically stores the time the record was created.</li> </ul>"},{"location":"resources/database/1-sql/#inserting-data","title":"Inserting Data","text":"<p>To add records to a table, use <code>INSERT INTO</code>:</p> <pre><code>INSERT INTO users (name, email) VALUES ('Alice', 'alice@email.com');\nINSERT INTO users (name, email) VALUES ('Bob', 'bob@email.com');\nINSERT INTO users (name, email) VALUES ('Charlie', 'charlie@email.com');\n</code></pre>"},{"location":"resources/database/1-sql/#retrieving-data-with-select","title":"Retrieving Data with <code>SELECT</code>","text":"<p>To retrieve all records from a table:</p> <pre><code>SELECT * FROM users;\n</code></pre> <p>This returns:</p> id name email created_at 1 Alice alice@email.com 2025-03-02 12:00:00 2 Bob bob@email.com 2025-03-02 12:01:00 3 Charlie charlie@email.com 2025-03-02 12:02:00"},{"location":"resources/database/1-sql/#filtering-results-with-where","title":"Filtering Results with <code>WHERE</code>","text":"<p>Use <code>WHERE</code> to filter results based on conditions.</p>"},{"location":"resources/database/1-sql/#find-a-specific-user-by-email","title":"Find a specific user by email:","text":"<pre><code>SELECT * FROM users WHERE email = 'alice@email.com';\n</code></pre>"},{"location":"resources/database/1-sql/#find-all-users-whose-names-start-with-b","title":"Find all users whose names start with \"B\":","text":"<pre><code>SELECT * FROM users WHERE name LIKE 'B%';\n</code></pre>"},{"location":"resources/database/1-sql/#find-users-created-after-a-specific-date","title":"Find users created after a specific date:","text":"<pre><code>SELECT * FROM users WHERE created_at &gt; '2025-03-01';\n</code></pre>"},{"location":"resources/database/1-sql/#sorting-and-limiting-query-results","title":"Sorting and Limiting Query Results","text":""},{"location":"resources/database/1-sql/#sort-users-by-name-ascending","title":"Sort users by name (ascending):","text":"<pre><code>SELECT * FROM users ORDER BY name ASC;\n</code></pre>"},{"location":"resources/database/1-sql/#get-the-most-recently-created-user","title":"Get the most recently created user:","text":"<pre><code>SELECT * FROM users ORDER BY created_at DESC LIMIT 1;\n</code></pre>"},{"location":"resources/database/1-sql/#conclusion","title":"Conclusion","text":"<p>In this chapter, we explored the fundamentals of relational databases and SQL. We then covered key relational database concepts, including tables, columns, rows, and primary keys. Additionally, we demonstrated SQL queries for creating tables, inserting data, retrieving data using SELECT, filtering with WHERE, sorting, and limiting results.</p> <p>Understanding relational databases and SQL is useful for managing and persisting structured data efficiently. In the next reading, we will look at creating relationships between tables with foreign keys and introducing the concept of transactions. Each of these concepts is an important feature of a relational database system.</p>"},{"location":"resources/exercises/ex01-api-design/","title":"EX01. API Design and Implementation","text":""},{"location":"resources/exercises/ex01-api-design/#breakdown-of-parts","title":"Breakdown of Parts","text":"<p>Part 1. You only need to implement the route decorators and function signatures, NOT the actual implementation of the API.</p> <p>Part 2. You wll implement the API and deploy it to a production environment.</p>"},{"location":"resources/exercises/ex01-api-design/#app-overview-the-pastebin-url-shortener","title":"App Overview: The Pastebin + URL Shortener","text":"<p>In this lab, you and a partner will collaborate to design and implement a service that combines:</p> <ul> <li>A Pastebin-style API (store text snippets and retrieve them by a unique URL).</li> <li>A URL-shortening API (submit a long URL and receive a short, redirectable URL).</li> </ul> <p>These two functionalities must share a common opaque namespace for links, presenting unique design challenges regarding how to store and retrieve resources come implementation time.</p> <p>This application will be able to generate shortened URLs for sharing content such as:</p> <ol> <li>Pastbin Example: https://pastebin.com/uYCCWaxy</li> <li>URL Shortener Example: https://go.unc.edu/Xj9b6</li> </ol> <p>This application design will feature three personas:</p> <ol> <li> <p>Sue Sharer is someone who wants to distribute content easily. She might be a student sharing notes, a blogger sharing a quote, or a prankster hiding a Rickroll. Sue values convenience, control, and customization, which is why she wants options like vanity URLs and expiration times.</p> </li> <li> <p>Cai Clicker is the person who receives and opens links. They might be a friend reading a shared snippet, a recruiter reviewing a resume, or an unsuspecting victim of a disguised meme. Cai values seamlessness and reliability\u2014when they click a link, they expect to either see content immediately or be redirected without confusion.</p> </li> <li> <p>Amy Admin is responsible for monitoring and managing all active resources. She is a community manager. Amy values visibility, control, and order, ensuring that shared content remains appropriate and awareness of high-traffic links.</p> </li> </ol>"},{"location":"resources/exercises/ex01-api-design/#user-journey-examples","title":"User Journey Examples","text":"<p>An journey may combine a few user stories in order to give a complete start-to-finish example of a feature's use. Since you may not be familiar with the point of a pastebin-like service, or URL shortener, consider these journeys before reading the user stories in a more standalone presentation.</p>"},{"location":"resources/exercises/ex01-api-design/#sue-sharer-creates-a-text-snippet","title":"Sue Sharer Creates a Text Snippet","text":"<ol> <li>Sue wants to share a quote from a book with a friend.  </li> <li>She submits the text: <pre><code>\"Not all those who wander are lost.\"\n</code></pre></li> <li>The system generates a random URL path and responds with the information Sue needs to share the URL.</li> <li>Sue shares this link with her friend.  </li> <li>Cai Clicker clicks the link, which looks something like <code>https://&lt;your-apps-hostname&gt;/xYzA12</code> and sees the text snippet: <pre><code>\"Not all those who wander are lost.\"\n</code></pre></li> </ol>"},{"location":"resources/exercises/ex01-api-design/#sue-sharer-creates-a-shortened-url","title":"Sue Sharer Creates a Shortened URL","text":"<ol> <li>Sue wants to prank a friend by disguising a Rick Astley video link.  </li> <li>She submits the long URL below and a vanity path of <code>exam-solutions</code>: <pre><code>https://www.youtube.com/watch?v=dQw4w9WgXcQ\n</code></pre></li> <li>The system generates a link with the vanity path and responds with the information Sue needs to share the URL. </li> <li>Sue shares this link with her friend: <code>https://&lt;your-apps-hostname&gt;/exam-solutions</code> </li> <li>Cai Clicker clicks the link and is redirected to: <pre><code>https://www.youtube.com/watch?v=dQw4w9WgXcQ\n</code></pre></li> </ol>"},{"location":"resources/exercises/ex01-api-design/#required-user-stories","title":"Required User Stories","text":"<ol> <li>Sue Sharer<ol> <li>As Sue Sharer, I want to create a new text snippet with an optional expiration time and the ability to request a custom vanity URL, so that I can control how long it is available and share a more meaningful link.</li> <li>As Sue Sharer, I want to create a shortened URL with an optional expiration time and the ability to request a custom vanity URL, so that I can control how long it is available and share a more meaningful link.</li> </ol> </li> <li>Cai Clicker<ol> <li>As Cai Clicker, I want to open a shared text snippet by clicking its unique link, so that I can read the content that was provided to me.</li> <li>As Cai Clicker, I want to open a shortened URL by clicking its unique link, so that I am automatically redirected to the original long URL.</li> </ol> </li> <li>Amy Admin<ol> <li>As Amy Admin, I want to see a list of all active resources (text snippets and shortened URLs) and filter by type or view counts greater than some low threshold, so that I can oversee what content is currently being shared.  </li> <li>As Amy Admin, I want to see how many times each resource has been accessed, so that I can monitor usage and identify high-traffic resources.</li> <li>As Amy Admin, I want to update the content of an active text snippet or change the target of a shortened URL, so that I can correct or modify existing resources when necessary.  </li> <li>As Amy Admin, I want to delete any active resource from the system, so that I can remove content that should no longer be available.  </li> </ol> </li> </ol>"},{"location":"resources/exercises/ex01-api-design/#path-requirement-specifications","title":"Path Requirement Specifications","text":"<p>User stories 2.a. and 2.b. above are the only stories which we will very specificaly share an API requirement, as follows:</p> <p>These two stories should both share the same opaque route, including method and path. The method is <code>GET</code> and the <code>path</code> in FastAPI route path syntax is <code>/{resource_identifier}</code>. This means that there is a single shared path pattern for retrieving both types of resources.</p> <ul> <li>When a user accesses a generated or vanity URL, the system must determine whether it corresponds to a text snippet or a shortened URL.</li> <li>The user should not be able to infer whether a given URL points to a text snippet or a redirection just by looking at it.</li> </ul>"},{"location":"resources/exercises/ex01-api-design/#no-authentication-enforced","title":"No Authentication Enforced","text":"<p>The concerns of how to authenticate a user, like Amy Admin, and authorize various actions, is beyond your concern in this initial API design. You should proceed with all routes publicly available, unprotected. Later, we'll learn strategies for authenticating and authorizing various actions at the HTTP API level.</p>"},{"location":"resources/exercises/ex01-api-design/#phase-1-api-design","title":"Phase 1: API Design","text":""},{"location":"resources/exercises/ex01-api-design/#getting-started","title":"Getting Started","text":"<p>To begin work on EX01, you and your partner will need to accept a GitHub classroom with your assigned Team Name (in the form of <code>team_0_NN</code>) found in the pairings sheet. First look up your team name by your PID and copy it. Then go accept the GitHub classroom assignment by following this link. Search for your team name and if it already exists, join it. If you are the first of your pair to begin, create the team with the assigned team name.</p>"},{"location":"resources/exercises/ex01-api-design/#create-a-branch-for-individual-api-design","title":"Create a Branch for Individual API Design","text":"<p>Clone the project, open your project in a dev container, and create a branch for your individual API design. Name your branch something that includes your onyen or github username.</p>"},{"location":"resources/exercises/ex01-api-design/#individual-api-design","title":"Individual API Design","text":"<p>In your branch created above, go ahead and stub out an HTTP API, making use of FastAPI routes and Pydantic models as necessary, that satisfy the user stories. Use the <code>/docs</code> user interface to review your routes. Your objectives are:</p> <ul> <li>Define Endpoints: Specify all the HTTP routes required for the required user stories above.</li> <li>Design Data Models: Create Pydantic models that define the structure of request bodies and responses.</li> <li>Clear OpenAPI Documentation: Fully document important your API using the OpenAPI standards discussed below.</li> <li>Establish Conventions: Ensure consistent naming and documentation throughout your API design.</li> </ul>"},{"location":"resources/exercises/ex01-api-design/#openapi-specification-requirements","title":"OpenAPI Specification Requirements","text":"<p>FastAPI and Pydantic have special constructs which allow you to more fully specify your API and its documentation to produce the standards-based <code>OpenAPI.json</code> spec powering the <code>/docs</code> user interface.</p> <p>You are required to add specification and documentation to your API design along each of the following dimensions. You can find examples of how each is done following this overview list:</p> <ul> <li>FastAPI Application: Ensure your app is properly instantiated with required metadata.</li> <li>Route-level: Always include a summary and description; document response bodies thoroughly.</li> <li>Route Parameters:<ul> <li>Path parameters: Must have descriptions and optional validations.</li> <li>Query parameters: Must have descriptions and can include validations.</li> <li>Body parameters: Must have descriptions and <code>openapi_examples</code> for clear request body documentation.</li> </ul> </li> <li>Pydantic Fields: Every field should include a description and an example (or examples) to aid API consumers.</li> </ul>"},{"location":"resources/exercises/ex01-api-design/#fastapi-application-level-documentation","title":"FastAPI Application-level Documentation","text":"<p>Instantiate your FastAPI app using the <code>FastAPI</code> constructor. You must provide a <code>title</code>, <code>contact</code>, <code>description</code>, and <code>openapi_tags</code> (for organizing routes), as shown below. Notice that the description is markdown and you can use a docstring to give your API documentation </p> <p>Example:</p> <pre><code>app = FastAPI(\n    title=\"EX01 API Design\",\n    contact={\n        \"name\": \"Parter A, Partner B\",\n        \"url\": \"https://github.com/comp423-25s/&lt;your-team-repo&gt;\",\n    },\n    description=\"\"\"\n## Introduction\n\nYour introduction text to your API goes here, in **markdown**.\nWrite your own brief intro to what his API is about.\n\"\"\",\n    openapi_tags=[\n        {\"name\": \"Sue\", \"description\": \"Sue Sharer's API Endpoints\"},\n        {\"name\": \"Cai\", \"description\": \"Cai Clicker's API Endpoints\"},\n        {\"name\": \"Amy\", \"description\": \"Amy Admin's API Endpoints\"},\n    ],\n)\n</code></pre> <p>After you've more fully configured your <code>app</code>, as shown above, try reloading your OpenAPI UI by navigating to <code>/docs</code> in your dev server. You should see the information above being used to improve the documentation generated. The tags added will allow you to organize your routes based on the intended user. In real APIs, tags are generally used to cluster endpoints for a specific feature together; here we're using them to organize by persona served.</p>"},{"location":"resources/exercises/ex01-api-design/#route-level-decorator-specification","title":"Route-level Decorator Specification","text":"<p>Define endpoints using FastAPI\u2019s route decorators (e.g., <code>@app.get</code>, <code>@app.post</code>). Each route must include a summary, description, and tag. The tag corresponds to the <code>openapi_tags</code> you specified above and will be a persona name. If your route returns response codes besides <code>200</code>, such as <code>404</code>, you need to specify the responses field as shown below. For a given status code, the description is required and the model (Pydantic subclass) is only necessary if the response returns a body.</p> <p>Example:</p> <pre><code>from typing import Annotated\n\nclass MessageResponse(BaseModel):\n    message: Annotated[str, Field(\n        description=\"Information conveyed ot user\", examples=[\"Hi!\"]\n    )]\n\n# ...\n\n@app.get(\n    \"/items/{item_id}\",\n    summary=\"Retrieve an Item\",\n    description=\"Get details of an item by its ID.\",\n    responses={\n        404: {\n            \"description\": \"Item not found\",\n        }\n    },\n    tags=[\"Shopping\"]\n)\ndef get_item(item_id: int) -&gt; MessageResponse:\n    if item_id &gt; 0:\n        return MessageResponse(message=\"Item found!\")\n    else:\n        raise HTTPException(status_code=404, detail=\"Item not found!\")\n</code></pre>"},{"location":"resources/exercises/ex01-api-design/#dynamic-path-parameters","title":"Dynamic Path Parameters","text":"<p>For dynamic segments in the URL (path parameters), use <code>Path</code>. Include a description and any additional keyword parameters found in the official documentation you believe would be helpful in specifying and documenting your path (useful ideas: 1. <code>examples</code> list of example values you might expect for the parameter, 2. validation such as <code>min_length</code> or <code>gt</code> (greater than) as shown below).</p> <p>Example:</p> <pre><code>from fastapi import FastAPI, Path\nfrom typing import Annotated\n\n# ...\n\n@app.get(\"/users/{user_id}\")\ndef get_user(\n    user_id: Annotated[int, Path(\n        description=\"The unique ID of the user\",\n        gt=0,\n        examples=[1, 423]\n    )]\n) -&gt; User:\n    ...\n</code></pre>"},{"location":"resources/exercises/ex01-api-design/#query-parameters","title":"Query Parameters","text":"<p>For query parameters (appended to the URL), use <code>Query</code>. Each query parameter must include a description, should probably include a default value, and can optionally include additional examples and validation rules, if needed. See the official documentation on supported keyword parameters when specifying and documenting query parameters.</p> <p>Example:</p> <pre><code>from fastapi import FastAPI, Query\nfrom typing import Annotated\n\n# ...\n\n@app.get(\"/search\")\ndef search_items(\n    q: Annotated[str, Query(\n        description=\"The product search query\",\n        examples=[\"jordans\"]\n    )] = \"\" # Default value is empty string\n) -&gt; SearchResults:\n    ...\n</code></pre>"},{"location":"resources/exercises/ex01-api-design/#documenting-pydantic-model-fields","title":"Documenting Pydantic Model Fields","text":"<p>Within your Pydantic models, use the <code>Field</code> function to document each field. Every field must have a description and examples list to aid API consumers.</p> <p>Example:</p> <pre><code>from pydantic import BaseModel, Field\nfrom typing import Annotated\n\nclass Item(BaseModel):\n    name: Annotated[str, Field(\n        description=\"Name of Product\",\n        examples=[\"UNC Jersey\", \"UNC Socks\"]\n    )]\n    price: Annotated[float, Field(\n        description=\"Sales Price\",\n        examples=[75.0, 20.0]\n    )]\n</code></pre>"},{"location":"resources/exercises/ex01-api-design/#request-body-parameters","title":"Request Body Parameters","text":"<p>For request body parameters (used in <code>POST</code>/<code>PUT</code>/<code>PATCH</code> requests), define a Pydantic model and use <code>Body</code> to add metadata. The body parameter must include a description and openapi_examples. These examples help make testing out the API in <code>/docs</code> easier, as you will see when you try it out. You can also add validation rules if needed.</p> <p>Example:</p> <pre><code>from fastapi import FastAPI, Body\nfrom typing import Annotated\n\n# ... Same Item model as above ...\n\n@app.post(\"/items\")\ndef create_item(\n    item: Annotated[Item, Body(\n        description=\"The product to create\",\n        openapi_examples={\n            \"Air Jordans\": {\n                \"summary\": \"Air Jordan 1 Mid SE\",\n                \"description\": \"Sample product to create\",\n                \"value\": {\n                    \"name\": \"Air Jordan 1 Mid SE\",\n                    \"price\": 134.99\n                },\n            }\n        }\n    )]\n) -&gt; Item:\n    ...\n</code></pre>"},{"location":"resources/exercises/ex01-api-design/#a-note-on-model-design-and-typing","title":"A Note on Model Design and Typing","text":"<p>In your design space for implementing your models, there are likely a few paths worth considering. The design challenge you are confronted with is your API involves two different kinds of resources (text versus links) and they have differences in behaviors, validations, and so on. However, they also share some things in common (such as the namespace for their shortened paths once created, the expiration, and the access counter).</p> <ol> <li>(Do not do this!) Unimodel - Single model shared by both types. This solution is taking on technical debt and becomes gnarly to maintain and extend.</li> <li>(Discouraged) Traditional Inheritance Hierarchy - a single resource subclass of <code>BaseModel</code> which is then subclassed for your specific resources.</li> <li>(Recommended) Discriminated Type Unions - models use a common string field to communicate their type. This is useful because once a Python or JavaScript object is serialized into JSON for transfer over an API, only the field names and values of an object are transferred. By encoding type into a field, it's easier to work with. This strategy has emerged in many dynamic programming languages and is recommended in Pydantic and our front-end language TypeScript.</li> </ol> <p>To learn more about discriminated type unions in Pydantic, see the [official Pydantic documentation]. Additionally, feel free to search or have an interactive learning conversation with ChatGPT to gain a better understanding. Here's an example prompt I tried in ChatGPT that gave a solid introduction. As always, with LLM generated content, read carefully and vigilantly: it doesn't always tell the complete story, the correct story, or have a complete understanding of what exactly you are doing.</p>"},{"location":"resources/exercises/ex01-api-design/#collaboration-for-phase-1","title":"Collaboration for Phase 1","text":"<p>Each of you should individually draft a design of your API in FastAPI on your own branches (branch naming specified after the Getting Started section above). You should both push your branches to GitHub.</p> <p>Once you are ready to merge your branches to form a unified API for your team, we do not recommend actually attempting a merge in <code>git</code>. You are welcomed to, but at your own peril. Since you both worked in <code>main.py</code>, and made design decisions independently, the merge conflict resolution will be gnarly.</p> <p>Instead of attempting a <code>git</code> merge, we strongly suggest pair programming, and starting over by going back to your <code>main</code> branch on one of your machines. Start a new branch based on <code>main</code> that is <code>pair-api-design</code>. On the other of your machines, have open both of your branches in GitHub to easily view how each of you approached the design and try to form a consensus on how to approach. You will be well served by each reading each other's design and then attempting to whiteboard your final approach before diving into code. Once you are complete, push your final <code>pair-api-design</code> to GitHub and submit your teams' reflection for Phase 1 on Gradescope.</p>"},{"location":"resources/exercises/ex01-api-design/#sanity-checks","title":"Sanity Checks","text":"<p>Questions to consider in the context of your API:</p> <ul> <li>Have we ensured that our design addresses every required user story for Sue, Cai, and Amy?</li> <li>Are our naming conventions for endpoints, models, and fields consistent and descriptive enough for all personas?</li> <li>How does our design distinguish between a text snippet and a URL shortener resource when using the same <code>/{resource_identifier}</code> endpoint?</li> <li>Are we including required metadata (e.g., summaries, descriptions, examples) for every endpoint and model field so that a developer can easily understand our API?</li> <li>How have we documented error responses (like 404 for missing resources) in our endpoints?</li> <li>Is the route design intuitive for both API users and maintainers?</li> <li>How easily can our design be extended in the future if new requirements are added?</li> </ul>"},{"location":"resources/exercises/ex01-api-design/#phase-1-submission-and-reflection-questions","title":"Phase 1 Submission and Reflection Questions","text":"<ul> <li>Gradescope submission will include:<ul> <li>Permalink to branches of both partners</li> <li>Permalink to the final <code>pair-api-design</code> branch</li> </ul> </li> <li>Brief reflection question:<ul> <li>What challenges did we encounter when comparing our individual designs, developing a single design, and pair programming our joint, final design?</li> </ul> </li> </ul>"},{"location":"resources/exercises/ex01-api-design/#key-takeaways","title":"Key Takeaways","text":"<ol> <li> <p>Designing for Users and Use Cases</p> <p>Through this assignment, you\u2019ve gained experience designing an API that serves multiple types of users with distinct needs. You\u2019ve seen how clear, user-focused API design is essential\u2014not just for making the system functional but also for ensuring a smooth experience for different personas. This mirrors real-world software development, where balancing the needs of end users, system administrators, and stakeholders is key to building successful products.</p> </li> <li> <p>Writing Clear, Professional API Documentation</p> <p>By leveraging FastAPI\u2019s OpenAPI documentation, you\u2019ve practiced writing API specs that go beyond just making things work\u2014you\u2019ve created an API that is easy for others to understand, test, and use. In industry, well-documented APIs are what enable teams to scale, integrate with other systems, and onboard new developers quickly. This attention to detail will serve you well in any software engineering or product development role.</p> </li> <li> <p>Navigating Design Constraints</p> <p>You\u2019ve tackled a unique design challenge: storing and retrieving two different resource types (text snippets and URL redirects) while keeping a shared, opaque namespace. This required careful thinking about data modeling and routing logic. Real-world software design often involves trade-offs like these, where multiple features must coexist within a unified system without exposing unnecessary complexity to users.</p> </li> <li> <p>Collaborating on Software Design in a Team Environment</p> <p>By independently designing an API and then merging your ideas into a unified implementation, you\u2019ve practiced an essential part of professional software development: balancing individual contributions with collaborative decision-making. You\u2019ve navigated trade-offs, discussed design choices, and worked toward a shared vision\u2014skills that are essential in any software engineering role.</p> </li> <li> <p>Designing the Interface First for Human-Centered Development</p> <p>By focusing on the API interface before implementation, you\u2019ve embraced a human-centered approach\u2014prioritizing how users interact with the system rather than getting lost in internal details. This ensures the design is intuitive, valuable, and easy to integrate. A well-defined interface also enables parallel development: frontend teams can build against the spec while backend teams implement functionality, making collaboration more efficient. In real-world projects, this approach reduces wasted effort, improves usability, and accelerates development, ultimately leading to better software.</p> </li> </ol>"},{"location":"resources/exercises/ex01-api-design/#phase-2-implementation","title":"Phase 2: Implementation","text":"<p>In this phase of the exercise, you will implement a service layer in order to have a functional API. All of your Phase 2 business logic should be in the service layer. Your routes should only address HTTP concerns and otherwise delegate control to your service(s).</p> <p>Before beginning on Phase 2, you should complete the following readings and submit them on Gradescope:</p> <ul> <li>Layered Architecture</li> <li>Dependency Injection in FastAPI</li> </ul> <p>To get started on Phase 2, create a new branch named <code>phase2-services</code> and collaborate on it. If you and your partner work together with pair programming, working on this branch together is fine. If you are working async, start your own separate branches and be sure both of you attempt to complete this phase independently.</p> <p>By the end of Phase 2, you should be able to use the <code>/docs</code> UI to complete the stories of this exercise from each user's perspective. Of importance, you should also be able to follow Cai's stories directly in the web browser and be presented with plaintext or redirected to another URL by visiting the shortened URL. Finally, visit tracking and link expiration implementation is left as a challenge for extra credit.</p> <p>Phase 2 should have <code>pytest</code> integration tests cover Sue Sharer and Cai Clicker's stories. You should also write unit tests that cover Sue Sharer and Cai Clicker's stories. See the introduction to testing reading for more guidance on testing. Testing Amy's stories is left as an extra credit opportunity.</p>"},{"location":"resources/exercises/ex01-api-design/#implementation-extra-credit","title":"Implementation Extra Credit","text":"<ul> <li>1 point of extra credit for integration testing and unit testing Amy's stories</li> <li>1 point of extra credit for implementing click tracking in a way that's demonstrable and unit tested</li> <li>1 points of extra credit for successfully implementing resource experiation in a way that's demonstrable and unit tested (hint: you'll need to find a way to cleverly simulate the passage of time by patching or mocking...)</li> </ul>"},{"location":"resources/exercises/ex01-api-design/#phase-2-cicd-in-production","title":"Phase 2: CI/CD in Production","text":"<p>Let's deploy your backend API to the UNC Kubernetes/OKD cluster! Then you can share snippets and redirects with your friends.</p> <p>The steps we follow will be very similar to the tutorial you worked through in class on Monday, February 17th. The general overview is:</p> <ol> <li>Setup Continuous Integration with a GitHub Action</li> <li>Setup a Cloud Deployment on OKD</li> <li>Setup Continuous Deployment from GitHub Action to OKD</li> </ol>"},{"location":"resources/exercises/ex01-api-design/#setting-up-continuous-integration-with-a-github-action","title":"Setting up Continuous Integration with a Github Action","text":"<p>You will want your GitHub Action established on your <code>main</code> branch as that is where the CI/CD pipeline will run. Only one team member should complete this sequence of steps, so coordinate as to who that will be to avoid conflicts. We recommend doing this together, if possible! This is valuable infrastructure to understand how to stand-up and what the implications are. If you do not do it together, and your team mate completes these steps, be sure to read through and check your understanding along the way. Switch to your <code>main</code> branch.</p> <p>GitHub actions run in containers and will need to have your project's dependencies installed, including <code>pytest</code>. Those dependencies are in <code>requirements.txt</code>, but you may not have added <code>pytest</code> to it yet. Be sure <code>pytest</code> is in your <code>requirements.txt</code> pinned to the current version (as of this writing is <code>8.3.4</code>).</p> <p>Add a file named <code>.github/workflows/cicd.yml</code> to your project with the following contents:</p> <pre><code>name: CI/CD Pipeline\n\non:\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n\njobs:\n  ci:\n    name: \"Continuous Integration\"\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Set up Python 3.13\n        uses: actions/setup-python@v3\n        with:\n          python-version: \"3.13\"\n\n      - name: Install Dependencies\n        run: |\n          python -m pip install --upgrade pip\n          pip install -r requirements.txt\n\n      - name: Validation - pytest\n        env:\n          PYTHONPATH: .\n        run: pytest\n</code></pre> <p>At this point, you are only defining the CI job. This file will be extended to perform the CD job soon.</p> <p>Go ahead and create a commit on <code>main</code> and push this to your repository. Open your repository on GitHub and go to your Actions tab to see that the job runs. If you have no tests merged into your <code>main</code> branch yet then the <code>pytest</code> job will fail, which is expected. You can continue on.</p>"},{"location":"resources/exercises/ex01-api-design/#creating-a-ruleset-for-continuous-integration","title":"Creating a Ruleset for Continuous Integration","text":"<p>Go to your repository's Settings tab &gt; Rules &gt; Rulesets &gt; New ruleset. Create a Ruleset with the following settings:</p> <ul> <li>Name: <code>main</code></li> <li>Enforcement status: Active</li> <li>Targets &gt; Add Target &gt; Include the Default Branch</li> <li>Checked Rules:<ul> <li>Restrict creations</li> <li>Restrict deletions</li> <li>Require a pull request before merging<ul> <li>Required approvals: 0</li> </ul> </li> <li>Require status checks to pass This is CI!<ul> <li>Require branches to be up to date before merging (check)</li> <li>Status checks that are required: Add checks<ul> <li>Search for \"Continuous Integration\" and check it. This is the job in the GitHub action you set up above! This is where your <code>pytest</code>s run. </li> </ul> </li> </ul> </li> <li>Block force pushes</li> </ul> </li> </ul> <p>Save changes. This is a slightly more sophisticated branch ruleset that you have seen prior. Namely, it will require us to use Pull Requests to merge into main. Additionally, before merging, your branches will need to successfully pass your automated tests. This is fundamentally important and characteristic of what continuous integration is.</p>"},{"location":"resources/exercises/ex01-api-design/#creating-a-pull-request","title":"Creating a Pull Request","text":"<p>Let's test this Ruleset by creating a Pull Request. In your GitHub Repository, navigate to the Pull Request tab and click New Pull Request. For the base, be sure your team's repository is targetted and select the <code>main</code> branch. For the compare branch, select your Phase II branch. You should see the commit history and changes between <code>main</code> and your Phase II branch here. Click Create Pull Request.</p> <p>For the title, add a descriptive title along the lines of \"Phase II Milestone: Implementation\" and a meaningful description that describes what you've done in Phase II in a few sentences. Additionally, mention the \"verification steps\" of additional tests added with <code>pytest</code>. Then click Create pull request. </p> <p>After creating the PR, you will see your history of commits and you should see a message indicating \"Some checks haven't completed yet\" with \"Continuous Integration\". Assuming your tests all pass <code>pytest</code>, you will now see a button to merge your branch into <code>main</code>. Wait to do so, for now. If you accidentally do merge, you will want to follow the steps below for what to do after successfully merging and let your team mate know they'll need to do the same.</p>"},{"location":"resources/exercises/ex01-api-design/#adding-okdkubernetes-oc-tool-to-the-dev-container","title":"Adding OKD/Kubernetes' <code>oc</code> Tool to the Dev Container","text":"<p>To setup and manage your Kubernetes/OKD cloud project from your dev container, we need to download and install the <code>oc</code> program onto your image. For the CI/CD Tutorial, this was automatically setup for you. In your project, one of you will need to add this additional configuration and push to your Phase 2 branch (or a new branch if you accidentally already merged).</p> <p>If only one of you completed the prior steps alone, our suggestion is to have the other complete these steps. Like before, both of you should understand what is happening in this sequence. Here we need some additional steps taken after our dev container is created. To add these steps, we'll create a bash shell script in the <code>.devcontainer</code> directory named <code>post-create.sh</code>. A shell script is just a sequence of commands like those you could type into a terminal.</p> .devcontainer/post-create.sh<pre><code># Install `oc` CLI tool\narch=\"$(arch)\"\ncase \"$arch\" in \n    x86_64) export TARGET='' ;; \n    aarch64) export TARGET='arm64-' ;; \nesac\nwget -O /tmp/oc.tgz \"https://github.com/okd-project/okd/releases/download/4.15.0-0.okd-2024-03-10-010116/openshift-client-linux-${TARGET}4.15.0-0.okd-2024-03-10-010116.tar.gz\"\npushd /tmp\ntar -xvzf oc.tgz\nsudo mv oc /usr/bin/oc\nrm kubectl oc.tgz README.md\npopd\n\n# Install Python Packages\npip install --upgrade pip\npip install -r requirements.txt\n</code></pre> <p>The first set of commands downloads the correct <code>oc</code> package (<code>x86_64</code> is for Intel/AMD-based CPUs and <code>aarch64</code> is for Mac M-family chips). The second set of commands installs your <code>python</code> packages.</p> <p>After creating this file, we need to replace the current <code>postCreateCommand</code> in <code>devcontainer.json</code> to run this script instead. Open up <code>.devcontainer/devcontainer.json</code> and change the <code>postCreateCommand</code>'s assigned string to be <code>\"bash .devcontainer/post-create.sh\"</code> (instead of the <code>pip</code> command). Save this file and if you are prompted to rebuild the dev container, accept. If you are not prompted, be sure you saved and then use the Code Command Palatte to run \"Rebuild Container.\"</p> <p>After rebuilding, you should be able to run <code>oc version</code> and see client version <code>4.15.0...</code>. Congrats, you have successfully added the <code>oc</code> tool to your dev container setup!</p>"},{"location":"resources/exercises/ex01-api-design/#adding-a-production-dockerfile","title":"Adding a production <code>Dockerfile</code>","text":"<p>When your project builds in production on OKD it will produce a Docker image. We will control the steps to produce this image using a <code>Dockerfile</code>, as explored earlier in the course. Add a new file to the root directory of your project named <code>Dockerfile</code> with the following contents:</p> Dockerfile<pre><code># Dockerfile for Production Build\n# Use the official Python 3.13 image as the base image.\nFROM python:3.13\n\n# Set the working directory in the container.\nWORKDIR /app\n\n# Copy requirements file to the container.\n# This file should list all Python dependencies.\nCOPY ./requirements.txt /app/requirements.txt\n\n# Install the Python dependencies.\nRUN pip install --upgrade pip &amp;&amp; \\\n    pip install -r requirements.txt\n\n# Copy the rest of the application code.\nCOPY . /app\n\n# Expose port 8080 which uvicorn will run on.\nEXPOSE 8080\n\n# Command to run FastAPI in production mode.\nCMD [\"fastapi\", \"run\", \"--host\", \"0.0.0.0\", \"--port\", \"8080\"]\n</code></pre> <p>This is a good point to add the configuration changes you just made to a new commit, push it to your Phase 2 branch, or another branch if you already merged.</p>"},{"location":"resources/exercises/ex01-api-design/#merging-your-prs-and-continuing-work","title":"Merging your PRs and Continuing Work","text":"<p>We are going to recommend using the Squash and Merge strategy of merging your PRs into <code>main</code> moving forward in this project. Pull up the PR for your Phase 2 changes and look for the green button. If it does not say \"Squash and Merge\", click the down triangle on the button and select Squash and merge. Go ahead and merge. Give the commit message line and extended description a meaningful message. Don't delete the branch after merging, leave it for posterity's sake in this project.</p> <p>Back in your dev container, and your team mates, you will want to switch to <code>main</code> and then pull the changes from your repo. If you use <code>git log -1</code> you should see the squashed and merged commit. Additionally, you should be able to run <code>pytest</code> and see your passing tests. Woo!</p> <p>Generally, when working with Pull Requests (PRs), this is your workflow:</p> <ol> <li>Create a branch locally, push the branch to GitHub</li> <li>Create a Pull Request (PR) on GitHub (select your team's repository's <code>main</code> branch as target)</li> <li>Once ready to merge, merge via Squash and Merge and Fill in Commit message/Message</li> <li>Click Confirm</li> <li>In you and your team mates' dev container: switch to <code>main</code> and pull.</li> </ol> <p>If you haven't followed these steps for your Phase 2 branch, now is a good time to go ahead and do so such that your tests and latest routes are on the <code>main</code> branch before we go to deploy.</p> <p>Additionally, if you make additional changes or fixes to your implementation following deployment, just create new branches, give them meaningful names, be sure your tests cover your changes, and continue on following this process.</p> <p>Soon we will see how Code Review plays into this process in engineering teams, but for now we can forego the code review process.</p>"},{"location":"resources/exercises/ex01-api-design/#manually-deploying-your-project-to-okdkubernetes","title":"Manually Deploying your Project to OKD/Kubernetes","text":"<p>Both members of the team will deploy the exercise to their respective OKD namespaces. This ensures both of you have additional experience setting up the pieces and seeing how they come together. You will want to be sure you and your partner have completed the steps above. Your local dev container should be on <code>main</code>, now with all of your Phase 2 changes merged, and your dev container rebuilt such that <code>oc version</code> succeeds.</p> <p>To work with UNC's OKD/Kubernetes cluster, you need to be on Eduroam or VPN'ed in.</p> <p>Login to OKD here: https://console.apps.unc.edu</p> <p>Get your <code>oc</code> login command by clicking your name in the top right and navigating to copy login command. Click display token and then copy the <code>oc login --token=...</code> line and paste it into your dev container's Terminal. Try running the <code>oc project</code> command to see your OKD/Kubernetes project selected (<code>comp590-140-25sp-&lt;your-onyen&gt;</code>).</p>"},{"location":"resources/exercises/ex01-api-design/#setup-a-fine-grained-personal-access-token","title":"Setup a Fine-grained Personal Access Token","text":"<p>In the CI/CD Tutorial we used a classic personal access token with wide ranging access to read your repositories on GitHub. For this project, let's use the newer style Fine-grained token that gives the token holder permission to read only your EX01 repository. The production setup will be given this token so it can access your code to build your project. To create a new one, on GitHub click your Profile &gt; Settings &gt; Developer settings &gt; Personal access tokens &gt; Fine-grained tokens &gt; Generate new token.</p> <ul> <li>Token Name: EX01 - OKD Access -  <li>Resource owner: comp423-25s</li> <li>Expiration: 30 Days is Fine</li> <li>Description: Giving access to OKD to clone/access the EX01 repo.</li> <li>Repository Access:<ul> <li>Only select repositories: Select your team's repository for ex01.</li> </ul> </li> <li>Permission:<ul> <li>Repository permissions:<ul> <li>Contents: Read-only</li> </ul> </li> </ul> </li> <p>After clicking Generate Token you will be brought to a screen where it shows you, very lightly, the access token created. Copy this token to your clipboard (click the copy icon button), you will need it in the next step!</p> <p>Register your EX01 GitHub Access token as an OKD secret. This secret will be used by your OKD BuildConfig to clone your repository into the build process. Run the following command and substitute your GitHub Username and the Access Token in the placeholders (replace the &lt; and &gt;'s!):</p> <pre><code>oc create secret generic ex01-pat \\\n    --from-literal=username=&lt;your-github-username&gt; \\\n    --from-literal=password=&lt;your-github-pat&gt;\n</code></pre> <p>Let's also label this secret as belonging to <code>app</code> named <code>ex01</code> so that we can easily manage it with other <code>ex01</code> related resources in the future (such as deleting everything when we move on to another project):</p> <pre><code>oc label secret ex01-pat app=ex01\n</code></pre>"},{"location":"resources/exercises/ex01-api-design/#set-up-the-app","title":"Set up the App","text":"<p>OKD's <code>oc</code>'s <code>new-app</code> subcommand is an all-in-one command to establish a <code>Deployment</code>, <code>BuildConfig</code>, <code>ImageStream</code>, and <code>Service</code> for an application based on some common conventions. The option flags we provide below tell it our app is <code>Docker</code>-based, gives it access to the personal access token secret setup above, and because we are running this command in our current working directory <code>.</code>, <code>oc</code> is clever and looks at your <code>git</code> repository's <code>remote</code> servers to know which repository it is hooked up to.</p> <pre><code>oc new-app . \\\n    --name=ex01 \\\n    --source-secret=ex01-pat \\\n    --strategy=docker \\\n    --labels=app=ex01\n</code></pre> <p>Once this command succeeds you can try the following command to follow along with the build of your app in production:</p> <pre><code>oc logs -f buildconfig/ex01\n</code></pre> <p>This command will \"follow\" (thanks to <code>-f</code>), also commonly called tail, the output of your build in production on OKD/Kubernetes. Once the build completes you will be returned back to the command prompt, but you can also stop tailing the log with <code>Ctrl+C</code>. You can observe it following the steps of the <code>Dockerfile</code> when building your image.</p> <p>Next you'll expose a secure \"edge\" route to your service:</p> <pre><code>oc create route \\\n    edge \\\n    --service=ex01 \\\n    --insecure-policy=Redirect\n</code></pre> <p>Finally, find your app's public URL on cloud apps with the following subcommand:</p> <pre><code>oc get route ex01\n</code></pre> <p>Copy the host and paste it into your browser. Try navigating to <code>/docs</code> on this host, as well. You should see your app running in production!</p> <p>If you wanted to manually initiate a new build for your app based on your <code>main</code> branch, you can now do so with the following command: <code>oc start-build ex01</code>. However, we'd really like to automate deployment following a successful CI verification run and merge into the <code>main</code> branch. So let's setup continuous deployment!</p>"},{"location":"resources/exercises/ex01-api-design/#setting-up-continuous-deployment","title":"Setting up Continuous Deployment","text":"<p>Now that your app is running in production, let's automate deployment on successful PR merges to <code>main</code>. You will update your GitHub Action to include a CD step.</p>"},{"location":"resources/exercises/ex01-api-design/#adding-a-repository-secret-with-the-url-of-your-okd-build-webhook","title":"Adding a Repository Secret with the URL of your OKD Build WebHook","text":"<p>What is a WebHook URL? It's just an API endpoint that one service (OKD/Kubernetes in our case) can expose to allow other services (GitHub) to notify them of something important. For us, we will find a secret URL OKD/Kubernetes exposes which, if we make an HTTP POST request to it, it will kick off a new build for our project in OKD/Kubernetes. We can try this from the terminal of your dev container:</p> <p>First, find the secret URL:</p> <pre><code>oc describe bc/ex01 | grep -C 1 generic\n</code></pre> <p>You should see a URL that looks something like: <code>https://api.apps.unc.edu:6443/apis/build.openshift.io/v1/namespaces/comp590-140-25sp-ONYEN/buildconfigs/ex01/webhooks/&lt;secret&gt;/generic</code></p> <p>Next, we need to find the secret to plug into the <code>&lt;secret&gt;</code> part of the path. This is found in the YAML configuration for the BuildConfig (<code>bc</code>). We can filter down to it using <code>grep</code> to search for <code>generic</code> with one line of context around the matching line:</p> <pre><code>oc get bc ex01 -o yaml | grep -C 1 generic\n</code></pre> <p>You should copy the secret and paste it in place of the <code>&lt;secret&gt;</code> place holder in your WebHook URL. Copy this whole URL to your clipboard, we'll use it in two places.</p> <p>First, let's test making a POST request to the WebHook from your dev container using the <code>curl</code> command-line utility. The <code>curl</code> program allows you to make HTTP requests from the command-line and is highly configurable:</p> <pre><code>curl -X POST &lt;paste your URL with secret here&gt;\n</code></pre> <p>This command will result in a message that says an invalid content-type was provided (we didn't provide any request body!) but that it is \"ignoring payload and continuing with build.\" Woo!</p> <p>You can once again follow the build you just kicked off with the command:</p> <pre><code>oc logs -f buildconfig/ex01\n</code></pre> <p>We didn't really want to start this build, we were just testing it, so you can cancel the build with the following:</p> <pre><code>oc get builds\noc cancel-build ex01-X\noc get builds\n</code></pre> <p>Replace the <code>X</code> with the number of the build you are attempting to cancel.</p> <p>Let's add this secret WebHook URL to your EX01 repository as a secret your GitHub Action will be able to use. Repository &gt; Settings &gt; Secrets and variables &gt; Actions &gt; New Repository Secret:</p> <ul> <li>Name: <code>CD_BUILD_WEBHOOK_&lt;ONYEN&gt;</code> (substitute your ONYEN)</li> <li>Secret: Paste your secret Webhook URL found above</li> </ul> <p>Save your repository secret. This will serve as a variable name in the next step.</p>"},{"location":"resources/exercises/ex01-api-design/#updating-github-action","title":"Updating GitHub Action","text":"<p>Since both you and your team mate will both kick-off the CD step from the same GitHub Action definition, you will want to coordinate who makes the initial changes and who adds to it second. This will help avoid merge conflicts.</p> <p>If you are the first to establish continuous deployment for your production environment, add the following to the end of your YAML file. If you are the second of your pair, just read this step to understand it, pull from <code>main</code> to get this going, and then continue to your instructions following.</p> <pre><code>  cd:\n    name: \"Continuous Deployment\"\n    needs: ci\n    if: ${{ github.event_name == 'push' }}\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: Notify OKD to Build and Deploy\n        run: |\n          curl -X POST ${{ secrets.CD_BUILD_WEBHOOK_&lt;ONYEN&gt; }}\n</code></pre> <p>Be sure to substitute the <code>&lt;ONYEN&gt;</code> with yours so that it matches the name of the secret you established above.</p> <p>The <code>cd</code> line should be at the same level of indentation as the <code>ci</code> entry which came in the section above. Both <code>ci</code> and <code>cd</code> are direct descendents of <code>jobs</code> based on indentation. Notice a few features of this <code>cd</code> definition:</p> <ul> <li><code>needs: ci</code> Indicates that this job is taking a dependency on the <code>ci</code> job being successful above.</li> <li><code>if: ${{ github.event_name == 'push' }}</code> this conditional differentiates a push (which a merge is treated as) from a pull request build. Thus, continuous deployment is skipped on Pull Requests until a PR is merged to <code>main</code> (and \"pushed\" to <code>main</code>). This makes sense because you do not want to deploy to production until you merge to <code>main</code>!</li> <li>Notice in the <code>steps</code> that the command <code>run</code> is the same one you ran from the terminal with <code>curl</code>. This will trigger the WebHook.</li> </ul> <p>Switch to a new branch, perhaps <code>cd-setup</code>, add these changes, make a commit, and push. Following the push, go create a Pull Request into your repository's <code>main</code> branch from the <code>cd-setup</code> branch you just pushed.</p> <p>After creating the PR, you should see that your tests will run as part of the CI step and that your CD steps will be skipped, correctly, because of the <code>if</code> condition added above. Go ahead and merge this change into <code>main</code> with Squash and Merge.</p> <p>After merging, go checkout your Actions tab. Take a look at how you now have a pipeline that runs: Continuous Integration followed by Continuous Deployment. These names were configured by the <code>name</code> fields in your <code>cicd.yaml</code> file in your project. You can click on either to see the process each moves through. Once the Continuous Deployment step succeeds, you should be able to check your builds to see a new build was initiated:</p> <pre><code>oc get builds\n</code></pre> <p>Once that build completes, it will deploy and you have setup a complete CI/CD workflow to a kubernetes cluster! This is something to be proud of! Now, as you make changes to your project, you will need to push to a branch, create a PR, pass all your tests, and then upon merging to <code>main</code> your work will be pushed to production automagically. This is a very real industry-grade software engineering workflow and pipeline.</p> <p>Back in your dev container, switch back to <code>main</code> and pull to incorporate your squashed and merged commit.</p> <p>For the second member of the team to setup continuous deployment. After adding your OKD project's webhook URL as a secret to your repository, your steps are as follows:</p> <p>Switch to <code>main</code> in your dev container and pull your partner's merged work. Open your <code>.github/workflows/cicd.yaml</code> file and you should see their <code>cd</code> step added above. Go ahead and create a new branch, perhaps named <code>cd-extension</code>. For your part, you're just going to add one more line to the \"Notify OKD to build and deploy\" step:</p> <pre><code>    steps:\n      - name: Notify OKD to Build and Deploy\n        run: |\n          curl -X POST ${{ secrets.CD_BUILD_WEBHOOK_&lt;FIRST_ONYEN&gt; }}\n          curl -X POST ${{ secrets.CD_BUILD_WEBHOOK_&lt;SECOND_ONYEN&gt; }}\n</code></pre> <p>You will add the second <code>curl</code> command with your ONYEN replacing the <code>&lt;SECOND_ONYEN&gt;</code> placeholder. This will cause <code>curl</code> to first trigger your partner's build and then yours immediately after.</p> <p>Go ahead and add this to a <code>git</code> commit on your <code>cd-extension</code> branch. Push it. Make a new PR to your repository's <code>main</code> branch. Your tests should all still pass in CI and then you should be able to squash and merge.</p> <p>Upon merge, your GitHub Actions page should reflect that another worflow has begun and you can see the pipeline progress. After it completes the Continuous Deployment step, you can check your OKD production builds:</p> <pre><code>oc get builds\n</code></pre> <p>You can also tail your build:</p> <pre><code>oc logs -f bc/ex01\n</code></pre> <p>Now your Continuous Deployment step initiates builds on both teammates' cloud projects! Congratulations, you have a working CI/CD pipeline.</p>"},{"location":"resources/exercises/ex01-api-design/#finishing-up-ex02","title":"Finishing up EX02","text":""},{"location":"resources/exercises/ex01-api-design/#frequently-asked-questions","title":"Frequently Asked Questions","text":""},{"location":"resources/exercises/ex01-api-design/#my-github-action-is-not-running-or-failing-why","title":"My Github Action is Not Running or Failing, Why?","text":"<p>If you do not see any attempts to build your Actions in the GitHub Actions tab of your repository, it is likely one of three reasons:</p> <ol> <li>You have not pushed the original action definition to <code>main</code></li> <li>You have not initiated a Pull Request with the action definition and targetted <code>main</code></li> <li>Your action file is improperly named. Be sure the file extension is <code>.yml</code></li> </ol> <p>If your build is failing, there are likely one of two reasons. Open up the Action and dig into its details to see exactly where it fails by drilling in.</p> <ol> <li>If the validation/pytest step fails because <code>pytest: command not found</code>, it is because you are missing the <code>pytest</code> dependency in <code>requirements.txt</code>. Be sure not to skip that step (search for it in the steps above!)</li> <li>Your tests are failing in GitHub Actions for some reason. Drill in in to investigate and keep pushing additional commits to your PR until your tests are passing.</li> </ol>"},{"location":"resources/exercises/ex01-api-design/#should-shortened-urls-redirect-to-the-url-or-just-display-the-url","title":"Should shortened URLs redirect to the URL or just display the URL?","text":"<p>For Cai's stories, you should be able to access the shortened URL directly in the web browser, not using <code>/docs</code> and be redirected to the URL that was shortened. You can search for FastAPI's <code>RedirectResponse</code> (and see the FAQ entry below about making sure this works in production). Note that the OpenAPI <code>/docs</code> UI will look like there is an error occuring on most redirects because it follows the redirect rather than shows you the redirect response. If you see a CORS error, you're probably doing it right, but to be sure you can try accessing your URL directly (e.g. <code>127.0.0.1:8000/short-url</code>) or looking in the network tab of your browser when using the <code>/docs</code> UI. Additionally, this is a place where you should have an integration test that can confirm a redirect response is correctly being returned.</p>"},{"location":"resources/exercises/ex01-api-design/#how-should-you-handle-hostname-differences-between-development-and-production","title":"How should you handle hostname differences between development and production?","text":"<p>In development your host name is likely your localhost IP address followed by a port: <code>localhost:8000</code>. In production, your hostname will be something like <code>ex01-comp590-140-25sp-ONYEN.apps.unc.edu</code>. If your Sue routes need to produce URLs for Cai to click on, you should not hard code <code>localhost</code>. Instead, you can use a dependency injection for FastAPI's <code>Request</code> object and inspect its host. Or, you can add the following helpful service to a new <code>url_service.py</code> file and inject it into a route instead. Here's the implementation:</p> url_service.py<pre><code>\"\"\"Service for creating URLs based on the current request's hostname.\"\"\"\n\nfrom fastapi import Request\n\n__author__ = \"Kris Jordan &lt;kris@cs.unc.edu&gt;\"\n\n\nclass URLService:\n    \"\"\"Service for creating URLs.\"\"\"\n\n    def __init__(self, request: Request):\n        \"\"\"Request is dependency injected by FastAPI.\"\"\"\n        self._request = request\n\n    def url_to_path(self, path: str) -&gt; str:\n        \"\"\"Create a URL with the same scheme and host as the request for a given path.\n        This is useful for avoiding hardcoding a host name or http/https prefix so that\n        the service can be used in both production and development environments.\n\n        In OKD, `x-forwarded-port` will be \"443\" for HTTPs and \"80\" for HTTP.\n\n        Args:\n            path: The path to create a URL for based on the current request.\n\n        Returns:\n            The created URL.\n        \"\"\"\n        port = self._request.headers.get(\"x-forwarded-port\") or self._request.url.port\n        scheme = \"https\" if port == \"443\" else \"http\"\n        host = self._request.headers.get(\n            \"x-forwarded-host\"\n        ) or self._request.headers.get(\"host\")\n        return f\"{scheme}://{host}/{path}\"\n</code></pre> <p>Then, from your <code>main.py</code>, you can import <code>URLService</code> and inject it into a route and use it as such:</p> <pre><code>@app.get(\"/demo\", ...)\ndef demo(url_svc: Annotated[URLService, Depends()]) -&gt; str:\n    return url_svc.url_to_path(\"abc123\")\n</code></pre> <p>The result of using this service's <code>url_to_path</code> as shown above is it would return <code>\"http://127.0.0.1:8000/abc123\"</code> if you are running in development. In production, it will return <code>\"https://ex01-comp590-140-25sp-ONYEN.apps.unc.edu/abc123\"</code>, instead. If you hardcoded a hostname anywhere, you will want to either come up with your own solution or use the service above.</p>"},{"location":"resources/exercises/ex02-ng-frontend/","title":"Angular Front-end for Link Sharing App","text":"<p>This exercise is a SOLO exercise. Everyone will establish their own repository and work to complete a simple front-end for their own API backend.</p> <p>In this exercise you will build a web front-end for your Link Sharing API of EX01. In the process you will gain experience with:</p> <ol> <li>High-level CORS (Cross-Origin Resource Sharing) Concerns</li> <li>TypeScript:<ul> <li>Interfaces</li> </ul> </li> <li>Angular:<ul> <li>Components</li> <li>Signals</li> <li>Services</li> <li>HttpClient</li> <li>Dependency Injection</li> <li>Routing</li> </ul> </li> </ol>"},{"location":"resources/exercises/ex02-ng-frontend/#enabling-cross-origin-resource-sharing-in-ex01","title":"Enabling Cross-Origin Resource Sharing in EX01","text":""},{"location":"resources/exercises/ex02-ng-frontend/#understanding-cors","title":"Understanding CORS","text":"<p>CORS (Cross-Origin Resource Sharing) is a security feature implemented by web browsers that restricts web pages from making requests to a different domain than the one that served the original page. This security measure exists to prevent malicious websites from making unauthorized requests to other domains using your credentials.</p> <p>When you build a web application with a separate frontend and backend (like we're doing with Angular and FastAPI), they typically run on different domains or ports during development. Without proper CORS configuration, your Angular application running on one port (e.g., localhost:4200) won't be able to make API requests to your FastAPI backend running on another port (e.g., localhost:8000).</p> <p>Additionally, for this exercise, we will deploy your front-end as a static web page on GitHub pages to further emphasize the separation between frontend and backend separation. Your EX02 frontend will run on GitHub Pages and (origin host: comp423-25s.github.io) and backend will run on your personal OKD project hostname. This also requires CORS for requests to succeed across origins.</p>"},{"location":"resources/exercises/ex02-ng-frontend/#using-middleware-in-fastapi","title":"Using Middleware in FastAPI","text":"<p>In web frameworks like FastAPI, middleware functions as a bridge between the server and your application code. Middleware intercepts requests and responses, allowing you to modify or process them before they reach your route handlers or before they're sent back to the client.</p> <p>The <code>CORSMiddleware</code> specifically manages HTTP headers related to CORS. When added to your application, it automatically handles setting the appropriate headers that tell browsers to permit cross-origin requests from your frontend application.</p> <p>In EX02, for simplicity's sake, we will enable very permissive CORS settings that are generally far more permissive than you would typically enable in a production application. In essence, we are disabling CORS protection of your API to make integration with our client in this application more straightforward. In true, industrial applications you will specify very specific hosts which you accept CORS API requests from.</p>"},{"location":"resources/exercises/ex02-ng-frontend/#enable-cors","title":"Enable CORS","text":"<p>You will need to add the following code to update your EX01 production deployment to enable CORS for working on EX02. Collaborate with your partner on EX01 to decide who will make this update, push the branch, and make the PR. </p> <p>First, import FastAPI's CORSMiddleware module in <code>main.py</code>'s imports section:</p> <pre><code>from fastapi.middleware.cors import CORSMiddleware\n</code></pre> <p>Then, register the middleware by adding the following snippet after you define your <code>app</code> in <code>main.py</code>:</p> <pre><code># Add CORS middleware to allow requests from any origin\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],  # Allows all origins\n    allow_credentials=True, \n    allow_methods=[\"*\"],  # Allows all methods\n    allow_headers=[\"*\"],  # Allows all headers\n)\n</code></pre> <p>Push this to a branch, make a PR, and ask your teammate to merge the PR so they can confirm the work you completed.</p>"},{"location":"resources/exercises/ex02-ng-frontend/#setting-up-the-ex02-dev-container","title":"Setting up the EX02 Dev Container","text":"<p>To get started on this project, you will need to accept and clone the EX02 starter repository here: https://classroom.github.com/a/ZInataQQ</p> <p>Once cloned, open the project in a dev container and wait for the post create build steps to complete. </p> <p>Start the development server with the following command:</p> <pre><code>ng serve --host=\"0.0.0.0\"\n</code></pre> <p>You may need to press enter to a prompted question about autocompletion rules. Just accept the default suggestion.</p> <p>The <code>host</code> flag instructs the Angular development server to listen on all IP addresses (0.0.0.0) for requests, which ensures Docker is able to route you through from your host to the dev container.</p> <p>Open http://localhost:4200 and you should be greeted with a simple user interface with some code to help get you started with this project.</p>"},{"location":"resources/exercises/ex02-ng-frontend/#starter-code-orientation","title":"Starter Code Orientation","text":""},{"location":"resources/exercises/ex02-ng-frontend/#core-files","title":"Core Files","text":"<ul> <li><code>src/main.ts</code> - Application entry point that bootstraps the Angular app</li> <li><code>src/app/app.component.ts</code> - Root component that serves as the application shell</li> <li><code>src/app/app.routes.ts</code> - Defines the application's routing configuration</li> </ul>"},{"location":"resources/exercises/ex02-ng-frontend/#components","title":"Components","text":"<ul> <li> <p>Share Component (<code>src/app/share/</code>):</p> <ul> <li><code>share.component.ts</code> - Form implementation using Angular Reactive Forms and Signals</li> <li><code>share.component.html</code> - Template with resource type selection and content input</li> </ul> </li> <li> <p>Navigation Component (<code>src/app/navigation/</code>):</p> <ul> <li><code>navigation.component.ts</code> - Simple navigation logic</li> <li><code>navigation.component.html</code> - Navigation links using Angular's router directives</li> </ul> </li> </ul>"},{"location":"resources/exercises/ex02-ng-frontend/#1-implement-sues-stories","title":"1. Implement Sue's Stories","text":"<p>Your task is to introduce an angular Service object that integrates with your API in order to complete the implementation of the <code>ShareComponent</code>, which will make use of the Service.</p> <p>The general strategy for making progess here is:</p> <ol> <li>Read and understand what is going on in the Share Component's TypeScript controller and HTML view template.</li> <li>Generate a Service (hint: use <code>ng generate service</code> subcommand).</li> <li>Define a method on the service for creating a link and/or snippet. It should take the appropriate parameters (which will be provided by the component) for creating a resource for your API (e.g. the type of resource and the content of the resource).<ul> <li>Assuming your API end point for Sue just returns a string, this method should return an <code>Observable&lt;string&gt;</code>, which will represent a shortened URL. If your API returns an object with properties, you will need to define an <code>interface</code> that has thoes properties and give it a name. Your method would return <code>Observable&lt;YourInterfaceName&gt;</code> instead.</li> <li>For now, you can implement a fake skeleton of the method by having it return <code>of(\"https://foo.bar\")</code> by importing the <code>of</code> function from <code>rxjs</code> (read more about <code>of</code> here: https://rxjs.dev/api/index/function/of). If your API returns an object, you can return an anonymous object with the expected fields, such as <code>of({\"url\":\"https://foo.bar\"})</code>;</li> </ul> </li> <li>Inject your service into the <code>ShareComponent</code>'s constructor as a private variable.</li> <li>Update the submission logic to call out to your service object's method(s) and subscribe to the result as you read about in the HttpClient reading: https://angular.dev/guide/http/making-requests#fetching-json-data. For more information on how to subscribe, see the official RxJS documentation: https://rxjs.dev/guide/observer.</li> <li>Ultimately, you will need to update the <code>ShareComponent</code>'s controller and HTML template upon success (or failure...) of the service method such that the template displays the resulting URL generated by your API. You should be able to click the URL and be taken to a new tab (make it an <code>a</code> tag and set the <code>target</code> attribute to <code>\"_blank\"</code>).</li> <li>Now it's time to actually implement integrating with your production API! You will need to inject <code>HttpClient</code> into your service, as is discussed in the <code>HttpClient</code> setup documentation https://angular.dev/guide/http/setup. Then, in your methods, replace the call to <code>of</code> with a call to your injected <code>httpClient</code>'s <code>post</code> method, like you read about in the \"Mutating server state\" of the Angular HttpClient Reading. You will need to provide a request body object which contains all necessary information for your API.</li> <li>Try it! One of two things will happen:<ul> <li>Nothing or an error. Open your Chrome Developer Tools and look in the console and the network tab for more diagnostics on what is going on behind the scenes. The network tab will be your best tool here. Investigate the tab. Not seeing your request? Be sure <code>Fetc/XHR</code> is shown. Still not seeing it? Did you save everything and <code>subscribe</code> to the result of your service method call from your component? Remember, the returned value from your service method is an <code>Observable</code> not an actual result! Seeing an error? Look at the HTTP response code to diagnose. If it's a CORS issue, return back to the CORS steps above and be sure you successfully deployed. If it's a 422, it means your request body did not fulfill the expectations of your API from EX01. Be sure you are sending all the data you need!</li> <li>Success: Woo! Sue will be so happy to use your new UI rather than the <code>/docs</code> UI!</li> </ul> </li> </ol>"},{"location":"resources/exercises/ex02-ng-frontend/#2-implement-resource-list-link","title":"2. Implement Resource List Link","text":"<p>For the second required portion of this exercise, you will introduce a new routable component for listing resources in your backend API for Amy. No filtering user interface is required. We'll make this functionality visible to all users, though, since this is just a demo application.</p> <p>Your goal here is to add a new item to the navigation for a resource list, add a component that you get routed to when viewing the resource list, and add additional service functionality and control templating for displaying all resources stored in your backend API.</p> <p>The general strategy here is to:</p> <ol> <li>Generate a new component (<code>ng g component</code>)</li> <li>Make the component routable via <code>app.routes.ts</code></li> <li>Add a link to <code>navigation/navigation.component.html</code> so that you can navigate to the component</li> <li>Inject your API service into your component (like you did in <code>ShareComponent</code>)</li> <li>Implement a skeleton of a method in your service for listing resources from your API. Is should return type <code>Observable&lt;YourAPIResponseType&gt;</code> where <code>YourAPIResponseType</code> is an interface you define to match your API's expectations. It may also be <code>YourAPIResponseType[]</code> if your API returns a list of the response and not an object.</li> <li>Implement the lifecycle interface <code>OnInit</code> that gets called when a component is loaded (in this case: routed to). This will subscribe to the service class' method. It should update one or more signal(s) you define in the class.</li> <li>The values of those signals should be read by the HTML template so that the resulting list of resources in your API are produced to the view layer of the system and you can see them in a table format.</li> </ol> <p>When deciding what and how to show the information on this screen the question you should ask yourself is, \"what would I want to see if I were Amy Admin?\"</p>"},{"location":"resources/exercises/ex02-ng-frontend/#publishing","title":"Publishing","text":"<p>The project comes predefined with a GitHub Action for publishing your web site. You will need to enable GitHub Pages for your project, though. To do so, go to your project's settings, go to Pages, and turn pages on from the <code>gh-pages</code> branch. It will take a couple minutes for this to take effect. You should be able to follow with the publishing process in the Actions tab. Once publishing is fully ready, you should see a link to your website if everything built correctly.</p>"},{"location":"resources/exercises/ex02-ng-frontend/#branch-expectations","title":"Branch Expectations","text":"<p>You are encouraged to experiment in branches while making progress on this exercise. However, your <code>git</code> workflow in this exercise is up to you. Ultimately, we expect your final product to be on <code>main</code> since that is what will be deployed live.</p>"},{"location":"resources/exercises/ex02-ng-frontend/#required-angular-conventions","title":"Required Angular Conventions","text":"<p>No credit will be given to projects which use old Angular style <code>ngIf</code> or <code>ngFor</code> tags, you should use the <code>@if</code> and <code>@for</code> functionality we read about. Additionally, all data that is shared between a <code>Component</code> typescript file and its HTML template should be done so via modern angular <code>signal</code>s, like you read about.</p>"},{"location":"resources/exercises/ex02-ng-frontend/#extra-credit","title":"Extra Credit","text":"<p>The following opportunities are available for extra credit, arranged by least to most challenging:</p> <ol> <li>1pt - Implement Vanity URLs in the Frontend</li> <li>1pt - Implement Expiration Dates when sharing a URL in the Frontend</li> <li>1pt - Implement Amy's Filtering Stories in the List Resources View</li> <li>2pt - Implement all of Amy's Stories (update, delete, view access counts)</li> </ol>"},{"location":"resources/exercises/sp00-api-spec/","title":"Sprint 1 - Week 1 - Interactive Prototypes &amp; API Scaffolding","text":"<p>Now that your initial feature design document and mid-fi wireframes are in place, your team will extend your work by developing interactive, clickable prototypes. These prototypes will enable your team to clearly demonstrate user interactions, providing peers with tangible insights into your feature\u2019s workflow. These clickable prototypes will be high fidelity and utilize the Material 3 design system of the CSXL. Additionally, you'll start scaffolding out the backend API routes and models necessary for your feature using FastAPI as the foundation.</p>"},{"location":"resources/exercises/sp00-api-spec/#assignment-details","title":"Assignment Details","text":""},{"location":"resources/exercises/sp00-api-spec/#1-clickable-prototypes","title":"1. Clickable Prototypes","text":"<ul> <li>Choose your primary user stories and their wireframes from last week to convert them a high fidelity wireframes using the CSXL Figma template.<ul> <li>Duplicate the CSXL Figma template into one of your team members' Figma spaces and add your team members to it.</li> <li>Add your story to the <code>Getting Started + YOUR DESIGN</code> page. Copy starter pages from CSXL Design page and material components from Components.</li> <li>We expect to see Material components and design principles followed throughout, unlike in the lo/mid-fi wireframes produced last week.</li> </ul> </li> <li>Turn your high-fidelity wireframes into a clickable Figma prototype as shown in class.</li> <li>Clearly illustrate the interactions from your top 3 critical user stories.</li> <li>Ensure each clickable prototype demonstrates:<ul> <li>The sequence of interactions.</li> <li>Where your feature will use the OpenAI LLM API.</li> <li>Key interactions or critical decision points clearly presented.</li> </ul> </li> <li>Link each clickable prototype clearly within your stories in your design document (Google Docs, Notion, etc.).</li> <li>Be prepared to present your top two story prototypes in a concise, 5-minute demonstration during class on Monday, March 31st. For each presented user story, include:<ul> <li>The associated REST API route(s) (next part).</li> <li>The model(s) it utilizes.</li> </ul> </li> </ul> <p>Prototype Presentation Advice</p> <ul> <li>Clearly narrate your user's journey through your prototype.</li> <li>Highlight the value your feature provides through specific interactions.</li> <li>Keep explanations clear and to-the-point to manage your time effectively.</li> </ul>"},{"location":"resources/exercises/sp00-api-spec/#2-rest-api-model-scaffolding","title":"2. REST API &amp; Model Scaffolding","text":"<p>Begin detailing your API in your design document by:</p> <ul> <li>Defining REST API routes that clearly support your critical user stories.</li> <li>Describing new models your feature's REST API will require. Refer to existing models located at <code>backend/models</code> in the CSXL repository to guide your designs.</li> <li>Clearly indicate if existing routes or models will need augmentation or modification.</li> </ul> <p>Your document should clearly communicate:</p> <ul> <li>Route HTTP methods (<code>GET</code>, <code>POST</code>, <code>PUT</code>, <code>DELETE</code>) and paths.</li> <li>The purpose of each route.</li> <li>Basic descriptions of the data each route will handle.</li> </ul>"},{"location":"resources/exercises/sp00-api-spec/#3-integration-analysis","title":"3. Integration Analysis","text":"<p>Answer the following critical integration questions in your design document:</p> <ul> <li>Existing Dependencies:<ul> <li>Identify specific files, classes, and methods your feature's starting point will directly depend upon, extend, or integrate with. Provide permalinks (including line numbers) from the CSXL codebase.</li> </ul> </li> <li>API &amp; Models:<ul> <li>Clearly cite where you plan to add routes (new files are acceptable, but provide their complete paths).</li> <li>Clearly cite where you plan to add or modify models.</li> </ul> </li> <li>Frontend Components:<ul> <li>Identify how you will organize your frontend component(s).</li> </ul> </li> <li>AI Prompts:<ul> <li>Behind the scenes your backend will need to make requests to the OpenAI API (think: ChatGPT). Start to brainstorm the prompts your backend routes will use with the AI, in other words: what would you put into the ChatGPT chat box and expect back. A common strategy is taking some user text and converting it into a structured JSON output you specify.</li> <li>Identify at least one prompt and the JSON model format you expect as a response from the OpenAI API. Give some sample input text or JSON data from user inputs, representative of what your backend would send to the OpenAI API, and provide concrete examples of expected responses.</li> </ul> </li> </ul> <p>Clearly identifying these dependencies and frontend needs early will streamline your future development and avoid surprises.</p>"},{"location":"resources/exercises/sp00-api-spec/#project-management-best-practices","title":"Project Management Best Practices","text":"<p>On Wednesday, we'll provide instructions for setting up your team's project board on GitHub. We'll dedicate class time on Friday to discussing GitHub issues and project board best practices. Keep the following in mind:</p> <ul> <li>Tasks should be clearly described, assigned to team members, and updated frequently.</li> <li>Link each project board card to relevant issues in your GitHub repository.</li> </ul> <p>Why Project Management Matters</p> <p>Using structured project management practices from the beginning will improve:</p> <ul> <li>Team coordination and productivity.</li> <li>Code quality through continuous peer review.</li> <li>Your shared understanding of the codebase and collaborative skills.</li> </ul>"},{"location":"resources/exercises/sp00-api-spec/#team-project-setup","title":"Team Project Setup","text":"<p>Your team will share a GitHub repository for collaboration. This repository is where you all will create pull requests, perform code review, and establish a continuous deployment pipeline (next sprint).</p> <ol> <li> <p>To get started, designate one member of your team to establish the repository. This member will create a new team named after your assigned team table, e.g. Team A1 if you are assigned table A1. See the teams sheet to verify your team table. Then, follow this link to establish your team and create a blank, starter repository. Once this is completed, other members of team should join the team and the repository.</p> </li> <li> <p>Another member of the team should be designated for the initial repository push. This team member should have already joined the team and should be able to see the blank repository accepting the assignment resulted in on GitHub (named after your team table). As part of RD26, you setup a local development environment for the CSXL. You should open that dev container and go ahead and pull from origin one more time to get the latest updates from the upstream CSXL repository. Go ahead and remove the remote repository named <code>origin</code> from your repository. Then, add a new remote repository named <code>origin</code> that is directed at the <code>https://github.com</code> URL of your final project. Go ahead and push <code>main</code> to <code>origin</code> and confirm that your team's repository now has the complete history of the CSXL repo in it. You will see a latest commit from your TA Andrew (<code>ItIsAndrewL</code>) as the most recent commit with ID prefix <code>a46bf64</code>.</p> </li> <li> <p>After completing step 2, all other members of the team should update their local CSXL development environment to remove the git <code>origin</code> remote and establish a new remote, named <code>origin</code>, that points to your team's GitHub repository (use the <code>https://github.com</code> URL). After doing so, you should be able to perform <code>git pull origin main</code> and it succeed. Additionally, you can verify correctness by running <code>git remote show origin</code> to see that it is pointed to your team's repository and not the official CSXL repository.</p> </li> <li> <p>Only after everyone has successfully completed step 3, a third member of your team should establish a project board for your team.</p> <ol> <li>Begin by opening you your team repo (<code>comp423-25s/csxl-team-XN</code> where <code>XN</code> is your table number, like <code>a1</code>). </li> <li>Be sure you do this from your team's repository page! From this page, click the <code>Projects</code> tab. Click <code>New Project</code>. </li> <li>From the modal with templates, select <code>Featured</code> and then select the <code>Kanban</code> template. </li> <li>Name the project \"Team XN Project Board\", where XN is your table. </li> <li>Finally, press the ellipses <code>...</code> in the top right corner, beneat your profile photo, and select Settings. </li> <li>Click Manage Access and under \"Invite Collaborators\", search for your team, select it, make the role Admin, and click Invite.</li> </ol> </li> <li> <p>After completing step 4, other members of the team should verify they are able to access the team project board by going to the repository on GitHub, clicking the Projects tab, seeing the project show up there and able to navigate to it.</p> </li> </ol> <p>We will discuss setting up your project board in class on Friday 3/28.</p>"},{"location":"resources/exercises/sp00-api-spec/#submission-demonstration","title":"Submission &amp; Demonstration","text":"<ul> <li>Continue updating your original design document.</li> <li>Ensure all clickable prototypes are clearly linked to from within your user stories. Test these links in an incognito window. You should be taken directly to the start of a story clickthrough.</li> <li>Be ready to demonstrate your clickable prototypes clearly and succinctly on March 31st, including clear references to routes and models associated with each story.</li> </ul> <p>This structured, design-forward approach will enhance both the quality and manageability of your feature, setting a strong foundation for the development cycles ahead.</p>"},{"location":"resources/exercises/sp00-cfp/","title":"Call for Proposals: Integrating AI into the CSXL Web Application","text":"<p>This semester in our software engineering course, you'll have the opportunity to enhance the CSXL web application by incorporating AI functionality using OpenAI's powerful language models (LLMs). Our goal is to make the XL app smarter, more user-friendly, and more engaging through thoughtful integration of AI.</p>"},{"location":"resources/exercises/sp00-cfp/#what-is-the-csxl-web-application","title":"What is the CSXL Web Application?","text":"<p>The CSXL web app, , currently helps you and other UNC CS students by: <ul> <li>Reserving coworking spaces (rooms and desks)</li> <li>Managing tickets for course office hours</li> <li>Providing a directory of student organizations</li> <li>Allowing applications to become an undergraduate teaching assistant (UTA)</li> </ul> <p>We are seeking proposals that creatively use AI to expand and enhance these existing functionalities\u2014or propose entirely new features!</p>"},{"location":"resources/exercises/sp00-cfp/#project-ideas","title":"Project Ideas","text":"<p>The following suggestions illustrate possible areas for AI integration, but feel free to expand upon them or propose something completely new! The three provided ideas are arranged in relative order of difficulty and scope. We believe the first is the most straightforward idea, followed by the second, and finally the third (study buddy) is the broadest in scope.</p>"},{"location":"resources/exercises/sp00-cfp/#1-ai-enhanced-room-and-desk-reservations","title":"1. AI-Enhanced Room and Desk Reservations","text":"<p>Imagine a conversational assistant integrated into the CSXL app that allows you to:</p> <ul> <li>Check room or desk availability using natural language (\"Are there pair programming rooms available tomorrow at noon?\")</li> <li>Manage or cancel reservations easily (\"Cancel my reservation for today at 3 PM.\")</li> <li>Query real-time usage information (\"Is my friend Joan at the XL right now?\" or \"How busy is it right now?\")</li> <li>Tracking of requests asked, along with success or failure in addressing the user's prompt, so that we can improve the feature over time.</li> </ul> <p>What other intelligent reservation features can you envision?</p>"},{"location":"resources/exercises/sp00-cfp/#2-smarter-office-hours-ticket-support","title":"2. Smarter Office Hours Ticket Support","text":"<p>AI could help students submit better, more detailed office-hour tickets by:</p> <ul> <li>Checking ticket submissions to ensure clarity and detail (\"Did the student provide enough information about their issue?\") and giving instructors the ability to set guidelines the AI enforces</li> <li>Automatically tagging or categorizing tickets for TAs to understand what is going on in the queue and improved data analysis</li> <li>Generating reports for instructors / TAs that summarizing common issues over a specified timespan to better anticipate and address frequent problems</li> </ul> <p>What other AI-driven improvements could help streamline office hours?</p>"},{"location":"resources/exercises/sp00-cfp/#3-ai-generated-practice-questions-and-study-buddies","title":"3. AI-Generated Practice Questions and Study Buddies","text":"<p>Create an AI-powered study helper that:</p> <ul> <li>Generates practice questions tailored to specific course topics and learning objectives defined by instructors or TAs as a part of their CSXL course site</li> <li>Allows students to rate or TAs to pre-screen questions, ensuring quality and relevance</li> <li>Tracks which questions students have seen or struggled with, ensuring variety and personalized learning experiences</li> </ul> <p>How else could AI facilitate collaborative learning or individual study?</p>"},{"location":"resources/exercises/sp00-cfp/#4-your-own-creative-ai-driven-feature","title":"4. Your Own Creative AI-Driven Feature","text":"<p>Don't feel limited! If you have an innovative idea on how AI could make the CSXL web app more useful, engaging, or intelligent, we encourage you to propose it. Feel free to think big and be creative, this is your chance to shape the future of the CSXL web application!</p>"},{"location":"resources/exercises/sp00-epic-stories/","title":"Sprint 0 - Week 0 - An Epic Tale of Short Stories","text":""},{"location":"resources/exercises/sp00-epic-stories/#agile-team-kickoff-feature-design-document","title":"Agile Team Kickoff: Feature Design Document","text":"<p>Your team will collaborate to create an initial design document outlining the epic of your feature. This task will guide your team through the planning of first Agile sprint and help you clearly define your project's scope, purpose, and value. Begin by creating a shared Google Doc for initial brainstorming and drafting. Ultimately, this document will be converted into a markdown file (<code>feature-design.md</code>) in your team's repository under the <code>docs</code> directory.</p> <p>For features, please see our Call for Projects this Spring 2025. We are integrating AI functionality into the CSXL web application! All features must utilize the OpenAI LLM API in some way that adds intelligence to . <p>Important Note on AI: Generative AI tools (e.g., ChatGPT, Bard) are strictly prohibited in crafting your design document. This exercise focuses on teamwork, critical thinking, communication, and a thorough understanding of the problem you aim to solve. Detection of generative AI writing in submissions risks a team score of 0% for this sprint.</p>"},{"location":"resources/exercises/sp00-epic-stories/#required-sections-of-your-document","title":"Required Sections of Your Document","text":""},{"location":"resources/exercises/sp00-epic-stories/#1-title-team","title":"1. Title &amp; Team","text":"<ul> <li>Create a descriptive, engaging title for your feature. You are encouraged to go beyond the original RFP title.</li> <li>Clearly list all team members with their full names and links to their GitHub repositories.</li> </ul>"},{"location":"resources/exercises/sp00-epic-stories/#2-overview","title":"2. Overview","text":"<ul> <li>Clearly restate the purpose, value, and context of your chosen feature.</li> <li>Include your own interpretation of the problem and explain the value your solution will provide to users.</li> <li>Keep this brief and impactful (1-2 concise paragraphs).</li> </ul>"},{"location":"resources/exercises/sp00-epic-stories/#3-key-personas","title":"3. Key Personas","text":"<ul> <li>Identify and briefly describe the 2-4 primary personas your feature targets.</li> <li>For each persona, clearly articulate:<ul> <li>Role: Who are they, generally?</li> <li>Goals: What do they aim to achieve using your feature?</li> <li>Pain Points: What specific problems does your feature help resolve for them?</li> </ul> </li> </ul>"},{"location":"resources/exercises/sp00-epic-stories/#4-user-stories","title":"4. User Stories","text":"<ul> <li>Write user stories following this template:</li> </ul> <pre><code>As a [persona], I want [to perform some action] \nso that [I can achieve some goal or benefit].\n\nAcceptance Criteria:\n- Clear, testable criteria describing what completing this story looks like.\n- Criteria 2\n- Criteria 3 (as necessary)\n</code></pre> <ul> <li>Organize user stories by persona and prioritize them by:<ul> <li>Necessity (Essential for minimum viable product? Nice-to-have?)</li> <li>Frequency of use (Daily, weekly, occasional?)</li> <li>Importance to user value</li> </ul> </li> <li>Clearly label and separate your stories by persona for clarity.</li> </ul>"},{"location":"resources/exercises/sp00-epic-stories/#5-wireframes-mockups-sample-interactions","title":"5. Wireframes / Mockups / Sample Interactions","text":"<ul> <li>For your top 3 critical user stories, create clear wireframes illustrating each step of the story.<ul> <li>If your feature involves content managed by instructors, CSXL staff, career services, etc., then one of your top stories should also include what the process looks like for this persona to add and edit this content.</li> </ul> </li> <li>Use Figma to produce mid-fidelity wireframes/prototypes to ensure consistency and a professional appearance. Export your Figma frames and add them to your epic design document.</li> <li>Include a brief but clear explanation beneath each wireframe:<ul> <li>What interaction is happening?</li> <li>What action(s) are users performing?</li> <li>What is the outcome or expected result?</li> </ul> </li> <li>For interactions where there is natural language or integration with the large-language model, provide two to threee different samples of what the user might prompt with and a reasonable response to expect (either language or UI) from the system.</li> </ul> <p>Collaboration Advice</p> <ul> <li>Discuss regularly as a team. Consensus early on saves rework later.</li> <li>Use simple language to clearly express ideas.</li> <li>Get frequent feedback from each other\u2014be direct, constructive, and supportive.</li> </ul> <p>Submission Requirements</p> <p>Your final document must:</p> <ul> <li>Be written in your own words\u2014no AI-generated content.</li> <li>Clearly demonstrate a thoughtful understanding of user needs, product vision, and realistic implementation.</li> <li>Be neatly organized, professionally formatted, and submitted as a PDF.</li> </ul>"},{"location":"resources/exercises/sp01-one-story-db/","title":"Sprint 1 - Week 1 - One Story End-to-End with DB","text":"<p>The goal of this sprint, which began last week, is to have the most valuable story of your project demonstratable end-to-end from front-end down to the database and OpenAI AI integration. On Monday, April 14th, your team will demo the story running on CloudApps.</p> <p>Requirements:</p> <ul> <li>Integration with OpenAI API</li> <li>Persistence in DB</li> <li>Project Management Standards</li> <li>Running on CloudApps</li> </ul>"},{"location":"resources/exercises/sp01-one-story-db/#integration-with-the-openai-api","title":"Integration with the OpenAI API","text":"<p>On Friday, April 4th, API keys for all teams were handed out. Each member has an individual API key for use in their own development environment which is tracked for appropriate, class-related purposes. Additionally, we showed the strategy and some helper functions for integrating with the API in your projects. See the recording for a more fullsome description, but in general here are some useful links:</p> <ul> <li>Backend OpenAI Service Helper</li> <li>Backend Service Using OpenAI Service</li> <li>Backend Model for OpenAI Response Example</li> <li>Backend API Route using the Service</li> </ul> <p>The path toward adding this sample code to your project shown in class involved adding the primary CSXL repository as a remote named <code>upstream</code> and using the <code>cherry-pick</code> subcommand to pull in the commit which added the above files. If you'd prefer to add these files manually to a branch, that's OK, too. The strategy shown in class was:</p> <pre><code>git remote add upstream https://github.com/unc-csxl/csxl.unc.edu.git\ngit remote fetch upstream\ngit switch stage\ngit switch -c add-openai-code\ngit cherry-pick 3c0822e\ngit push origin add-openai-code\n</code></pre> <p>Additionally, in your <code>backend/.env</code> file, you need to add an environment variable named <code>UNC_OPENAI_API_KEY</code> which is set to your personal key (no spaces) as handed out in class. This is a secret and should not be committed to your team's repository!</p> <p>Then, create a PR which targets your <code>stage</code> branch for integration and have a team member review and merge.</p> <p>Notably: You need to rebuild your devcontainer via the command palette in VSCode so that you get the updated <code>backend/requirements.txt</code> dependencies which includes <code>openai</code></p> <p>Requirement: If your Sprint 1 end-to-end story integrates with the AI; great! You should be able to show your own backend service that injects the <code>OpenAIService</code> and makes use of its <code>prompt</code> method with a Pydantic <code>response_model</code> parameter type of your team's design. If your Sprint 1 story does not have the AI integration in the user experience path, you should go ahead and write an additional backend API route and respective service that will integrate with the AI API and can be demonstrated via the <code>/docs</code> interface.</p>"},{"location":"resources/exercises/sp01-one-story-db/#persistence-in-db","title":"Persistence in DB","text":"<p>Your story should involve persisting new information to the database in some way; specifically, and technically, this means either augmenting an existing <code>Entity</code> or introducing one or more of your own <code>sqlalchemy</code> <code>Entity</code> classes.</p> <p>If your story (or feature!) does not necessarily directly involve new data in the database, then for this requirement, your team should introduce some sort of \"AI Audit Log\" entity that persists the user prompt and JSON-encoded text response from the AI. You do not need to surface this to an API/UI for this Sprint, but the successful recording of data should be visible via the Postgres Explorer plugin shown in class on Monday, April, 7th.</p> <p>Database persistence integration should only occur in the backend services layer, not directly from the HTTP API layer.</p> <p>If your demo / feature depends on data being prepopulated in your database, then you should add it such that running <code>python3 -m backend.script.reset_demo</code> repopulates your database correctly for demo purposes. When TAs are grading, they will run this script on your</p>"},{"location":"resources/exercises/sp01-one-story-db/#project-management-standards","title":"Project Management Standards","text":"<p>Continue utilizing the expected tools and workflow of the course:</p> <ol> <li>Maintain your Project Board with cards linked to issues, assigned to team member(s), with descriptive titles for all cards/issues</li> <li>Perform work on branches off of <code>stage</code></li> <li>Perform pull requests with well written titles and messages and request code reviews from team members</li> <li>Make effortful and helpful code reviews for your team mates, helpfully maintaining high standards of code</li> <li>Squash and merge approved PRs into <code>stage</code></li> </ol>"},{"location":"resources/exercises/sp01-one-story-db/#running-on-cloudapps","title":"Running on CloudApps","text":"<ul> <li>Instructions for CloudApps deployment will post on Wednesday, April 9th.</li> </ul>"},{"location":"resources/exercises/sp01-one-story/","title":"Sprint 1 - Week 1 - One Story End-to-End","text":"<p>The goal of this sprint is to have your primary story working end-to-end in the CSXL code base. Additionally, your team will get into the flow of performing Pull Requests and Code Reviews for one another and keeping your project board updated to reflect the status of ongoing work.</p> <p>In the first week of this Sprint, your feature's backend services layer is permitted, and generally expected, to fake responses from the database and AI integration.</p>"},{"location":"resources/exercises/sp01-one-story/#expectations","title":"Expectations","text":"<ul> <li>One story end-to-end</li> <li>Project Management Standards</li> <li>PR/CR Workflow Enforced from Stage</li> </ul>"},{"location":"resources/exercises/sp01-one-story/#your-primary-story","title":"Your Primary Story","text":"<p>Focus on your team's most valuable user story that incorporates an AI integration. Your goal is to have this working and interactive from the front-end all the way to the back-end. In this first week, your focus is orienting yourself with existing code and finding where your team's work will fit into it. For now, your aim is to implement from the front-end down to the back-end services, but those back-end services will be faked. Next week, we can worry about the AI integration and data persistence concerns. Since this is a large code base, you can likely find examples of most everything you are trying to accomplish by looking around at other areas of the application and seeing how they were achieved there.</p>"},{"location":"resources/exercises/sp01-one-story/#back-end-api-and-data-models","title":"Back-end API and Data Models","text":"<p>Your team should start with establishing your back-end Pydantic models and routes. The main entrypoint of the backend API is <code>backend/main.py</code>. You will see it imports its routes from FastAPI router files in the <code>backend/api</code> directory.</p> <p>For now, we recommend establishing your team's own separate router file in an appropriate <code>backend/api</code> subdirectory (e.g. room/desk reservation logic is in <code>coworking</code>, courses is in <code>academics</code>, office hours queue is in <code>office_hours</code>). Start with a single test route to be sure you can get it working and showing up in the <code>localhost:1560/docs</code> OpenAPI interface. After defining a router and adding a route to it, be sure to register it in <code>backend/main.py</code> as a <code>feature_api</code>. Before continuing further, be sure you see your route appear in <code>/docs</code>.</p> <p>Helpful hints:</p> <ul> <li>To run the development CSXL server, from the DevContainer, use <code>honcho start</code> and navigate to <code>localhost:1560</code></li> <li>When in doubt, reset your database following the steps in <code>docs/database.md</code></li> <li>Be sure to name your <code>APIRouter</code> instance in your backend router module <code>api</code></li> </ul> <p>Once you have a \"hello world\" route that you can successfully use from <code>/docs</code>, you are ready to start fully defining the routes you will need for this story. For now, we recommend focusing only on the routes you need for your initial story and no more. These routes will also need Pydantic models, or changes to existing models. You should make those changes in the <code>backend/models</code> directory. New models should be added to new files whose file structure is informed by where you chose to define your routes. If you need to \"modify\" an existing model, we recommend the approach you take for now is to use inheritance to define a new model just for your feature which extends the existing model and adds any additional fields needed. For an example of inheritance, see <code>backend/models/user_details.py</code> where <code>UserDetails</code> extends <code>User</code> and adds some additional fields to <code>User</code>.</p> <p>The FastAPI routes you define and need for this story should follow the conventions we learned about annotating route parameters this semester. The conventions we have learned are newer (and better!) than the more dated style you are seeing in the CSXL code base. (We hope to update them this summer!) You should also include documentation for your route definitions like we expected during the FastAPI exercise earlier this semester.</p>"},{"location":"resources/exercises/sp01-one-story/#back-end-services","title":"Back-end Services","text":"<p>Your routes should handle HTTP-level concerns, but ultimately should delegate the business logic to a service with necessary inputs coming from the request. You should define a new service similar to how other services are implemented in <code>backend/services</code>, also appropriately organized in the file structure, with the service methods your routes will depend on. For now, you can fake return values from these service methods in order to make progress on this project with your team. In doing so, the front-end work will be able to progress independently of the back-end and the API contract will be the shared agreement between layers of the stack.</p>"},{"location":"resources/exercises/sp01-one-story/#front-end","title":"Front-end","text":"<p>How your team's front-end is organized will be highly dependent upon your feature and story. You should find your way to the components and widgets you are likely to integrate with. If you need an entirely new front-end route, take a look at how other features work in the codebase and find relevant examples to work off of. You should utilize Material UI widgets in your feature. If you're looking for how to utilize a specific widget, look for relevant examples.</p> <p>While there may be a tendency to reach for GPT or Co-pilot on the front-end, please note it's likely to create a bigger headache and mess than you think if you lack confidence in the front-end. You are much better off trying to make slow, steady progress pair programming and having a sense of everything you are changing.</p> <p>If you arrive in office hours with code for your feature which you cannot explain, the TAs are instructed to help you revert back to <code>stage</code> and ask you to go work on it more intently, to try again.</p>"},{"location":"resources/exercises/sp01-one-story/#team-project-management","title":"Team Project Management","text":"<p>Continue utilizing the expected tools and workflow of the course:</p> <ol> <li>Maintain your Project Board with cards linked to issues, assigned to team member(s), with descriptive titles for all cards/issues</li> <li>Perform work on branches off of <code>stage</code></li> <li>Perform pull requests with well written titles and messages and request code reviews from team members</li> <li>Make effortful and helpful code reviews for your team mates, helpfully maintaining high standards of code</li> <li>Squash and merge approved PRs into <code>stage</code></li> </ol>"},{"location":"resources/exercises/sp01-one-story/#prcr-settings","title":"PR/CR Settings","text":"<p>Let's setup your GitHub repository so that your team is able to work from a branch named <code>stage</code> as your primary branch. We will reserve the <code>main</code> brach to reflect production's <code>main</code> branch.</p> <p>One member of your team should create a branch in the project named <code>stage</code> and push it to your team's repository. Other members of the team should <code>fetch</code> and switch to <code>stage</code>.</p> <p>A member of the team should setup the branch protection rules for <code>main</code> and <code>stage</code> in your team repository. In your team's final project repository, navigate to:</p> <ol> <li>Settings</li> <li>General &gt; Default Branch &gt; Change Branch to <code>stage</code><ul> <li>Press the Swap Button (not the Pencil!) and select <code>stage</code></li> <li>If you do not see <code>stage</code>, be sure you completed all the steps in \"Initialize Team Repository\", then refresh this page and try again.</li> <li>Press Update and accept the change</li> </ul> </li> <li>Change to the Branches tab in the sidebar<ol> <li>Add Branch Ruleset</li> <li>Ruleset Name: <code>main</code></li> <li>Enforcement status: <code>Active</code></li> <li>Targets, Add Target, Include by Pattern: <code>main</code></li> <li>(Check) Restrict creations</li> <li>(Check) Restrict updates</li> <li>(Check) Block force pushes</li> <li>Save Changes with <code>Create</code> Button</li> </ol> </li> <li>Add another Ruleset (Go back to Rulesets tab)<ol> <li>New Branch Ruleset</li> <li>Ruleset name: <code>stage</code></li> <li>Enforcement status: <code>Active</code></li> <li>Targets, Add Target, select Include default branch</li> <li>(Check) Restrict deletions</li> <li>(Check) Require linear history</li> <li>(Check) Require a pull request before merging<ol> <li>(Check) Require approvals: 1 required</li> <li>(Check) Dismiss stale pull request approvals when new commits are pushed</li> <li>(Check) Require approval of the most recent reviewable push</li> <li>(Check) Require conversation resolution before merging</li> </ol> </li> <li>Save Changes with <code>Create</code></li> </ol> </li> </ol> <p>Your team repository now protects <code>main</code> from modifications and requires Pull Requests and Code Reviews on <code>stage</code>. This workflow is representative of many industrial workflow settings.</p>"},{"location":"resources/exercises/sp02-deployment/","title":"Staging Server Environment (DevOps)","text":"<p>Your team should setup the staging environment on one team member's namespace. Choose one members' OKD CloudApps course namespace to setup the production staging environment. The other team member(s) will be added to this namespace as collaborator(s) so everyone has access.</p> <p>In establishing the staging environment on our cloud infrastructure, we will work from the bottom up. We will start with the database server, then add secrets needed to build and run the application, then add the application, and finally add the route to expose the application to the internet.</p>"},{"location":"resources/exercises/sp02-deployment/#accessing-cloud-infrastructure","title":"Accessing Cloud Infrastructure","text":"<p>Warning: If you are not on-campus when working with the cloud infrastructure, it will have the appearance of being \"down\". This is due to a firewall preventing off-campus access without a virtual private network VPN connection. If you try to load Cloud Apps at any point this semester and see a non-responsive or blank web page, it is likely because you are not connected via Eduroam nor the VPN.</p> <p>If you are off-campus, you will need to establish a VPN connection in to make use of Carolina CloudApps: https://ccinfo.unc.edu/start-here/secure-access-on-and-off-campus/</p> <p>Access the OKD CloudApps console here: https://console.apps.unc.edu/</p> <p>Under the okd logo, you should see \"Developer\" in a drop down and to the right \"Project: \" followed by <code>comp590-140-25sp-ONYEN</code> where ONYEN is your UNC ONYEN.</p>"},{"location":"resources/exercises/sp02-deployment/#using-the-oc-command-line-tool-to-administer-okd","title":"Using the <code>oc</code> Command-line Tool to Administer OKD","text":"<p>The <code>oc</code> tool is included in the <code>csxl</code> developer container. As long as you are successfully running Docker locally and connected to a campus network or VPN, you will be able to use <code>oc</code> from your container. However, if you are making use of CodeSpaces, you will need to follow these instructions for installing <code>oc</code> onto your host machine so that you can access the OKD cluster from VPN/campus rather than the cloud container.</p>"},{"location":"resources/exercises/sp02-deployment/#logging-into-the-okd-container","title":"Logging into the OKD Container","text":"<p>Our course projects will continue to be hosted on the OKD cluster of CloudApps, found here: https://console.apps.unc.edu/</p> <p>Go ahead and log-in. Remember: off-campus access requires VPN as described in the above section!</p> <p>Next, you will need to log-in to OKD from the Command-Line Utility in your DevContainer. The login command is found in the OKD Console. Look in the top right for your name, click the drop down, and select \"Copy Login Command\". From here select \"Display Token\". Here, look for the line \"Log in with this token\" and copy the complete command beginning with <code>oc login</code> to your clipboard.</p> <p>Paste this command into a terminal in your DevContainer (or, if you are on CloudSpaces, your host machine's terminal). You should be correctly logged in and see a message of success.</p>"},{"location":"resources/exercises/sp02-deployment/#giving-team-members-access-to-your-project","title":"Giving Team Members Access to Your Project","text":"<p>One member of each team should be designated the project host. From this member's OKD CloudApps account, you will need to add other team members as follows:</p> <ol> <li>Add team members to your course workspace</li> <li>Navigate to the Administrator sidebar (Default is Developer)</li> <li>Select: User Management &gt; Role Bindings</li> <li>For each team member, with their <code>onyen</code>:<ol> <li>Create binding</li> <li>Name: <code>admin-ONYEN</code> (replace <code>ONYEN</code> with teammate's ONYEN)</li> <li>Be sure the project you are in in CloudApps is <code>comp590-140-25sp-ONYEN</code></li> <li><code>ONYEN</code> should be your UNC ONYEN</li> <li>Role name: <code>admin</code></li> <li>Subject:</li> <li>User</li> <li>Name: your teammate's ONYEN</li> </ol> </li> </ol> <p>Add all of your team members and have them confirm that they have access.</p>"},{"location":"resources/exercises/sp02-deployment/#creating-the-database-server","title":"Creating the Database Server","text":"<p>The first step in establishing the cloud deployment is to establish the backend database pod.</p> <ol> <li>Add a PostgreSQL database to your project:<ol> <li>Developer View Sidebar</li> <li>Add (from the Sidebar)</li> <li>Database</li> <li>PostgreSQL Provided by Red Hat</li> <li>Instantiate Template</li> <li>Change only the following settings:<ol> <li>Database Service Name: <code>db</code></li> <li>PostgreSQL Database Name: <code>csxl</code></li> <li>Version of PostgreSQL Image: <code>latest</code></li> </ol> </li> <li>Create</li> <li>Navigate to the secrets page as described in the next paragraph</li> </ol> </li> </ol> <p>Once the database is created, go to the Secrets page found in the left-hand sidebar and view the generated credentials for the database under <code>db</code> (this is the name we gave it above). If you select \"Reveal Values\" you can see the name, username, and password for the database. These secrets will be used as environment variables in your application in the next step.</p>"},{"location":"resources/exercises/sp02-deployment/#creating-secrets-for-your-application","title":"Creating Secrets for your Application","text":"<p>Let's create a secret for your application to use. This will be used to store the database credentials, and will ultimately be mounted as environment variables in your application.</p> <p>Leave open the tab with these secrets, which you navigated to in Step 8 above. Additionally, you will need to generate a random string for the <code>JWT_SECRET</code> environment variable. This will be used to sign the JWT tokens that your application will use to authenticate users. You can generate a random string using the following command in your Dev Container:</p> <pre><code>openssl rand -hex 32\n</code></pre> <p>From your DevContainer's terminal, in a shell prompt run the following command to create the secret on OpenShift BE CAREFUL TO AVOID TYPOS.</p> <p>You can copy this command and edit it, replacing the placeholders, in an empty text file before running the command in your DevContainer terminal.</p> <pre><code>oc create secret generic final-project-environment \\\n    --from-literal=POSTGRES_HOST=db \\\n    --from-literal=POSTGRES_PORT=5432 \\\n    --from-literal=POSTGRES_DATABASE=csxl \\\n    --from-literal=POSTGRES_USER=&lt;from-secret-above&gt; \\\n    --from-literal=POSTGRES_PASSWORD=&lt;from-secret-above&gt; \\\n    --from-literal=JWT_SECRET=&lt;generate-random-string&gt; \\\n    --from-literal=UNC_OPENAI_API_KEY=&lt;your-teams-deployment-api-key&gt;\n</code></pre> <p>For the final secret, be sure to use the team's UNC OpenAI API key you were provided on the print out. It's the last key on the sheet. If this is not accessible, you can also use your own deployment key.</p> <p>Changing Secrets Later</p> <p>If you realize you need to change a secret, you can do so via the OKD web console by navigating to</p> <p>Developer &gt; Secrets &gt; <code>final-project-environment</code> &gt; Actions &gt; Edit Secret.</p> <p>From the OpenShift web console, you can verify that the secret was created by navigating to the Secrets page and selecting the <code>final-project-environment</code> secret.</p>"},{"location":"resources/exercises/sp02-deployment/#deploy-key-secrets","title":"Deploy Key Secrets","text":"<p>Before OpenShift's builder process is able to clone your repository from GitHub, we need to establish a means for OpenShift to authenticate itself to gain access to your team's private repository. This will closely resemble how you authenticate yourself with GitHub, but with the key difference it's the builder process running on Carolina Cloud app's machines-- not yours!-- that needs to gain access to your GitHub repository.</p> <p>It is worth pausing to reflect on how sensitive this step is in real world applications: you are setting up a means to directly access your code in a private repository. At organizations you may find yourself employed by, or founding, the code in your private repositories are some of it's most valuable assets and their secure handling is very important to maintaining their secrecy and protecting customers from hacks.</p> <p>It is for these reasons that you want to be very careful to never commit secrets to a <code>git</code> repository. The keys we are about to setup are considered secrets! (If you find yourself at an organization that breaks this rule: run.)</p> <p>To avoid accidentally commiting secrets to a project, one strategy is to be sure the filenames containing the secrets are added to the project's <code>.gitignore</code>. This file lists patterns that will not be included by default. Go ahead confirm the following rule is in the project's <code>.gitignore</code> file:</p> <p><code>deploy_key*</code></p> <p>Go ahead and make a commit with this change to <code>.gitignore</code> included in the commit.</p> <p>DEVCONTAINER: In your DevContainer's terminal, not your host's, generate an SSH key:</p> <pre><code>ssh-keygen -t ed25519 -C \"GitHub Deploy Key\" -f ./deploy_key\n</code></pre> <p>Note: Do NOT set a passphrase for the ssh key, just press enter at the prompt without typing anything when asked.</p> <p>You should now see the files <code>deploy_key</code>, which is the private/secret key, and <code>deploy_key.pub</code> which is the public key.</p> <p>Add the public key to your project repository's settings on GitHub:</p> <ol> <li>Navigate to your repository's settings</li> <li>Select Deploy Keys</li> <li>Add Deploy Key</li> <li>Title: <code>CloudApps Deploy Key</code></li> <li>Key: Copy the contents of <code>deploy_key.pub</code> into the key field</li> <li>Check the box to allow write access</li> <li>Click Add Key</li> </ol> <p>Now run the following command to add the private key as a secret to your Cloud Apps account:</p> <pre><code>$ oc create secret generic comp590-final-project-deploykey \\\n    --from-file=ssh-privatekey=./deploy_key \\\n    --type=kubernetes.io/ssh-auth\n</code></pre> <p>To verify the secret was correctly created, run the following command:</p> <pre><code>oc get secret comp590-final-project-deploykey\n</code></pre> <p>Finally, you need to link the secret to the \"builder\" process of OpenShift. This will allow OpenShift to use the secret when it pulls your code from GitHub and builds your project.</p> <pre><code>oc secrets link builder comp590-final-project-deploykey\n</code></pre> <p>This command will succeed silently.</p>"},{"location":"resources/exercises/sp02-deployment/#create-the-openshift-application","title":"Create the OpenShift Application","text":"<p>IMPORTANT: Be sure you substitute your team's information in TWO places below! First: the repository URL, second the HOST variable should not be <code>csxl-team-XX</code>, but should instead be your team zone + number. This is your team's table. Using lowercase is encouraged.</p> <p>IMPORTANT: Be sure you are currently on your stage branch. If you are not, go ahead and stash and/or commit changes on your current branch, and switch to stage.</p> <pre><code>oc new-app python:3.11~git@github.com:comp423-25s/&lt;your-final_repo_name&gt;.git#stage \\\n  --source-secret=comp590-final-project-deploykey \\\n  --name=final-project \\\n  --strategy=docker \\\n  --env=MODE=development \\\n  --env=HOST=csxl-team-&lt;TEAM NUMBER&gt;-comp423-25s.apps.unc.edu\n</code></pre> <p>Notice the <code>#stage</code> at the end of the repository URL. This is the branch name that OpenShift will pull from. When setting up the final project, you created a branch named <code>stage</code> and established it as the primary branch for your repository. This notion of a staging branch is a common practice in DevOps, and is a good way to keep your production code separate (live at csxl.unc.edu) from your development code (which you are establishing right now).</p> <p>While the project is building, link the secrets you created as the environment variables of the deployment and verify their existence with <code>list</code>:</p> <pre><code>oc set env deployment/final-project --from=secret/final-project-environment\noc set env deployment/final-project --list\n</code></pre>"},{"location":"resources/exercises/sp02-deployment/#exposing-the-application","title":"Exposing the Application","text":"<p>Once your application builds, it will be running on a pod that is not exposed to the internet. To establish a public route, first we need to expose it as a service, run the following command:</p> <pre><code>oc expose deployment final-project \\\n  --port=80 \\\n  --target-port=8080\n</code></pre> <p>Next, we can create a route to the service with a specifically chosen hostname. Please replace <code>XX</code> with your team's number  and table number.</p> <pre><code>oc create route edge \\\n  --service=final-project \\\n  --hostname=csxl-team-&lt;TEAM NUMBER&gt;-comp423-25s.apps.unc.edu\n</code></pre> <p>You can now visit the hostname for your team and access it in the browser. If you see a message from OpenShift that says \"Application is not available\", it means that the application is still building. Once your build completes, you should see the application running, but there is still one more important step: resetting the database.</p> <p>Crash-loop Back-off and 'OOM Killed' (Out of Memory)</p> <p>If your pod keeps crashing, with a message like \"Killed by OOM Manager\", it's because the Python/FastAPI server process requires more memory than your deployment is configured to provide by default. Our deployment platform, Kubernetes/OKD, monitors resource usage so that its resources are shared fairly among us. It takes a very conservative default, which can lead to your process being crashed when it needs more memory than the default. To ask for more memory, but still a modest amount for 2025 standards, take the following steps in the <code>oc</code> tool: </p> <pre><code>oc set resources deployment/final-project --requests=memory=256Mi --limits=memory=1Gi\noc rollout restart deployment/final-project\n</code></pre> <p>The first command requests a higher memory limit for the deployment and the second restarts the pod in the deployment so that it uses the new settings.</p>"},{"location":"resources/exercises/sp02-deployment/#resetting-the-database","title":"Resetting the Database","text":"<p>The database that you created in the previous step is empty. You will need to reset the database to the state that it was in when you submitted your final project. To do this, you will need to run the <code>reset_demo.py</code> script that is included in your final project repository.</p> <p>This script needs to be run from within your pod, so in this section you will learn how to connect to your pod and run commands from within it.</p> <p>First, you will need to find the name of your pod. Run the following command to get a list of pods running in your project:</p> <pre><code>oc get pods --selector deployment=final-project\n</code></pre> <p>You should see a single pod with a name like <code>final-project-648fdff8d5-rr4fs</code>. The letters and numbers at the end of the name are a unique identifier for the pod. This identifier changes every time a new build of your pod is deployed, environment variables change, the pod gets restarted, and in other instances. Copy the name of your running pod and run the following command to connect to it:</p> <pre><code>oc rsh final-project-YOUR-POD-IDENTIFIER\n</code></pre> <p>The <code>rsh</code> stands for \"remote shell\".  You are now connected to your pod running in the cloud via a secure shell (ssh)! The commands you run are not running on your host machine, but on the CloudApps infrastructure. If you <code>ls</code> you will see you are in your project's built directory. Not everything is there, importantly not the frontend because it was compiled into the <code>static</code> directory as part of the build process.</p> <p>To confirm you are logged into your pod, you can assure yourself with the following command:</p> <pre><code>hostname\n</code></pre> <p>You can now run the <code>reset_demo</code> script to reset the database. Run the following command to do so:</p> <pre><code>python3 -m backend.script.reset_demo\n</code></pre> <p>You should see the SQLAlchemy log messages creating tables, inserting dev data, etc. Your staging database is now reset!</p> <p>Important: As you deploy new versions, add new entities, add new dev data, etc., this process of resetting the database in staging is one you and your team members will both need to be comfortable doing and remember to do.</p>"},{"location":"resources/exercises/sp02-deployment/#setting-up-push-to-deploy-webhooks","title":"Setting up Push-to-Deploy Webhooks","text":"<p>GitHub repositories can be configured with webhooks, which are URLs that get called when events occur in order to notify another service of the event. In our case, we want to set up a webhook so that when we merge pull requests to the <code>stage</code> branch, OpenShift's build configuration for our project will receive a webhook notification and kick off a new build and deploy pipeline.</p> <p>To find the URL for the web hook, open up your project in OpenShift and navigate to the Admin sidebar, followed by Builds &gt; BuildConfigs. Select <code>final-project</code> and look for the webhooks section at the bottom. Click the Copy URL with Secrets button for the GitHub webhook. This copies the URL to your clipboard.</p> <p>Next, open your project's settings in GitHub and navigate to Webhooks. Click Add Webhook and paste the URL into the Payload URL field. Be sure to set the content type to <code>application/json</code> and leave the secret field empty. Click Add Webhook.</p> <p>From the \"Webhooks\" page you're brought back to, click your webhook. Then go to the Recent Deliveries tab. You should see a successful delivery. Congratulations, your project is now set up to automatically build and deploy every time your team merges PRs into the <code>stage</code> branch! As a reminder, if your data entities change, you will need to reset the database in staging after the build and deploy completes.</p>"},{"location":"resources/exercises/sp02-deployment/#youre-in-stagingproduction","title":"You're in Staging/Production!","text":"<p>This setup mirrors our production setup of <code>csxl.unc.edu</code> and is running the same code base. Congratulations on setting up what is, in essence, a production cloud environment for a small, modern web application!</p> <p>We call this \"Staging\" in a nod to how many organizations think of \"Staging\" environments. It's an area where your team can work on a feature, see it deployed publicly on the internet, and test it without having any impact on our production deployment.</p>"},{"location":"resources/exercises/sp02-second-story/","title":"Sprint 2","text":""},{"location":"resources/exercises/sp02-second-story/#sprint-2-expectations","title":"Sprint 2 Expectations","text":"<p>This sprint is about arriving at a well implemented, tested, and thoughtful production-quality feature.</p>"},{"location":"resources/exercises/sp02-second-story/#expectation-0-complete-2nd-end-user-story-end-to-end","title":"Expectation 0: Complete 2nd End-user Story End-to-End","text":"<p>In addition to the first story from SP01, we expect a 2nd end-user story working end-to-end. This story may not depend upon the AI integration (and likely will not!). If your feature significantly involves two different personas, try choosing the most important story from your second persona.</p>"},{"location":"resources/exercises/sp02-second-story/#expectation-1-polish-for-end-user-stories","title":"Expectation 1: Polish for End-user Stories","text":"<p>The interactions designed for your primary persona should be smooth and polished. This includes user-friendly interactions and form design, friendly error messages (or, even better, designing away the ability for there to even be errors!), and thoughtful user experience considerations such as clear user instructions and being sure everything visible works. If there are features you added user interface elements for that are not yet implemented, you should remove them by the end of this sprint. Everything visible should be functional.</p> <p>Additionally, polish should be added to the implementation wherever possible. You are encouraged to move through each story of your feature from end-to-end, including docs and tests, and improve your implementation wherever possible.</p>"},{"location":"resources/exercises/sp02-second-story/#expectation-2-document-your-implementation-for-future-developers","title":"Expectation 2: Document Your Implementation for Future Developers","text":"<p>Your initial design document from SP00 set you out in a direction to head with respect to design and routes. It is highly likely that while your team moved in that direction, the hopes and dreams of the design document were met with the realities of time constraints and technical challenges that required some iteration and deviation from the original plan. This is both typical and why overplanning without any implementation experimentation is rarely wise.</p> <p>For this expectation, draft a markdown document in the <code>docs/</code> directory of your project repository that is based on the realities of the feature work your team is doing and has implemented. It should be written for another developer to read and to understand how your feature is implemented. Structure it in such a way as to document how your feature works at each layer of the stack, from frontend to backend, database implications, and AI integration. Especially for the API, document the key routes and data models that exist in your code base. These should be visible and readable, fully formatted, on GitHub after you push your branches.</p> <p>You should avoid language such as, \"we would direct new developers to X and give them...\". Your documentation is written directly addressing a developer, not the course staff. If it helps, imagine you are writing for a future COMP423 student working to understand and extend your feature. Include screen grabs of the primary components and/or widgets of the frontend and look for other docs files on how to organize and include screenshots in your markdown.</p> <p>Choose plain language where possible.</p> <p>Ensure the formatting of your document is easy to read and understand. Make appropriate use of paragraph text, versus merely bulleted lists, where needed. Choose heading text that is appropriate for your feature and the audience. If information would better be represented with a table, use a table instead of a list. This list is not exhaustive. Use your best judgement to make your documentation a great artifact you can be proud of and share with future employers.</p> <p>Finally, include screenshots of your feature from the end user persona's perspective with narrative of what is being shown. To add an image to your project, place it in the <code>docs/images</code> directory.</p> <p>Include an authors section toward the top of the document listing the names of everyone in the group with links to their GitHub profiles.</p> <p>This document should be written by your four group members as first authors. LLMs usage is only appropriate for copyediting and feedback on how your documentation could be improved.</p>"},{"location":"resources/exercises/sp02-second-story/#expectation-3-project-management-standards","title":"Expectation 3: Project Management &amp; Standards","text":"<p>These remain the same as in the previous sprint.</p> <p>Issues are kept up-to-date on project boards and closed out when completed. Changes are merged into stage exclusively via pull requests with meaningful code reviews. Commits merged into stage are descriptive following best practices of commit messages.</p> <p>Angular Material components are used anywhere there are inputs, tables, tabs, etc. If there is an Angular Material component that achieves what your user interfaces need, you should use it in the frontend rather than standard, or bespoke, native HTML controls.</p> <p>Backend service classes should be tested using Pytest with mock data. Backend service classes and methods should be documented using docstrings following the Google Python Style Guide. Your final backend service code files must maintain 100% passing test coverage on stage. Your feature can and should mock the OpenAIService with a fixture similar to how similar services are mocked (See <code>backend/test/services/fixtures.py</code> for an example of how <code>permission_svc</code> is mocked, for example. You will see just after how <code>user_svc</code> is mocked to depend upon this. Then see <code>backend/test/services/user_service.py</code>'s <code>test_list_enforces_permission</code> for an example of how the mock is used.)</p> <p>Careful attention to permissions and access control should be paid to adhere to the principle of least privilege. Users should only be able to perform the necessary actions on the permitted resources for their legitimate purpose.</p> <p>Stories merged in to <code>stage</code> should be of usable, production quality.</p>"},{"location":"resources/exercises/sp02-second-story/#expectation-4-running-in-production-on-cloudapps","title":"Expectation 4. Running in Production on CloudApps","text":"<p>Find deployment instructions here.</p>"},{"location":"resources/exercises/sp02-second-story/#extra-credit-1-point-catch-your-stage-branch-up-with-csxluncedu-production","title":"Extra-Credit (1 point) - Catch Your <code>stage</code> Branch up with csxl.unc.edu Production","text":"<p>The TAs are not permitted to assist with this extra credit opportunity in or outside of Office Hours.</p> <p>Some PRs have landed in production at <code>csxl.unc.edu</code> since you began Sprint 2: https://github.com/unc-csxl/csxl.unc.edu/commits/main</p> <p>To earn this point of extra credit, you should catch your stage branch up to <code>upstream/main</code> such that you have commit <code>cef9639</code>, or later, in your <code>stage</code> branch. You may need to resolve conflicts. When creating a PR for this catch-up branch, rather than squashing and merging into your <code>stage</code> in this instance you should use the \"Create a Merge Commit\" strategy. This strategy will retain the history from production's main branch.</p> <p>This is good practice, and easier to achieve, if it's done semi-regularly. Additionally, this serves as a prerequisite to being considered for merging your team's features into production after the semester ends.</p>"},{"location":"resources/frontend/1-tools/","title":"JavaScript and the the Rise of the Web Client Platform","text":""},{"location":"resources/frontend/1-tools/#introduction-and-motivation","title":"Introduction and Motivation","text":"<p>Welcome to the front-end side of software engineering! Until now, you've gained experience with Python-based backends\u2014building REST APIs with FastAPI, configuring containerized environments, and even touching on production considerations like Kubernetes. You've seen how static type annotations can improve clarity in Python, and you've embraced unit testing to maintain software quality.</p> <p>Now, we\u2019re shifting toward web client applications. These are dynamic, interactive applications that run efficiently in the browser, providing smooth user experiences comparable to native apps. To build these, we need a strong foundation in modern JavaScript development tools and practices.</p>"},{"location":"resources/frontend/1-tools/#a-brief-history-of-javascript-and-the-web","title":"A Brief History of JavaScript and the Web","text":""},{"location":"resources/frontend/1-tools/#from-static-pages-to-dynamic-experiences","title":"From Static Pages to Dynamic Experiences","text":"<p>In the early days of the web (1990s), pages were built solely with hypertext markup language (HTML) for structure and cascading style sheets (CSS) for styling. Interactivity was minimal\u2014typically limited to simple tricks like swapping images on hover.</p> <p>Enter JavaScript in 1995. Created by Netscape, JavaScript allowed developers to write program scripts to add dynamic behavior to web pages, such as validating forms without requiring a full-page reload. It quickly became the standard client-side programming language since it was supported by all major browsers.</p>"},{"location":"resources/frontend/1-tools/#the-evolution-of-javascript-and-ecmascript","title":"The Evolution of JavaScript and ECMAScript","text":"<p>As web applications became more complex, JavaScript had to adapt. However, due to its rapid adoption and browser inconsistencies, the language needed standardization. This led to ECMAScript (ES), the official specification that defines JavaScript\u2019s behavior. JavaScript and ECMAScript are colloquially used interchangeably.</p> <p>Key milestones in JavaScript\u2019s evolution:</p> <ul> <li>ES5 (2009): Introduced JSON support, <code>strict mode</code>, and array methods like <code>map</code> and <code>forEach</code>.</li> <li>ES6 (2015): Major upgrade with modern syntax including <code>let</code> and <code>const</code>, arrow functions, template literals, classes, and modules. This release was a very big deal and significantly changed the experience of writing web client applications!</li> <li>ES7 and Beyond: Continuous yearly updates adding features like async/await, optional chaining, and improved performance optimizations.</li> </ul>"},{"location":"resources/frontend/1-tools/#key-characteristics-of-javascript","title":"Key Characteristics of JavaScript","text":"<p>JavaScript has several defining characteristics that influence how it operates:</p> <ul> <li>Interpreted: Unlike compiled languages like C++, JavaScript is executed line-by-line at runtime. This is akin to Python, which is also an interpreted language.</li> <li>Dynamically Typed: Variables do not have fixed types, allowing flexibility but also potential runtime errors. Again, like Python, this is more common in interpreted languages.</li> <li>Single-Threaded &amp; Event-Driven: JavaScript runs on a single execution thread but uses an event loop to handle asynchronous operations efficiently. You will learn more about this soon as it is an important runtime model to understand the nuances of for modern web development.</li> <li>Prototype-Based: Unlike traditional class-based languages, JavaScript is prototype-based, allowing objects to inherit directly from other objects. We will not dig into this and write TypeScript that feels more like the traditional OOP that you have learned thus far, but it's worth a mention that if you dig deeper there are differences here.</li> <li>Runs in the Browser &amp; Beyond: Originally designed for web browsers, JavaScript can now run on servers and desktops via environments like Node.js. We will use Node.js to write JavaScript/TypeScript programs that run at the commandline.</li> </ul> <p>As JavaScript grew, so did its complexity. Large applications needed better structure, maintainability, and developer tooling\u2014which led to the creation of TypeScript.</p>"},{"location":"resources/frontend/1-tools/#what-is-nodejs","title":"What is Node.js?","text":"<p>At its core, Node.js is a runtime environment that allows JavaScript to run outside of a web browser. When JavaScript was originally designed, it was intended to be executed only within browsers to make web pages interactive. However, as web applications became more complex, developers needed a way to run JavaScript on servers and in development tools. This is where Node.js comes in.</p> <p>Node.js is built on Chrome\u2019s V8 engine, which is the same high-performance JavaScript engine used in Google Chrome to process JavaScript code efficiently. By using this engine outside of the browser, Node.js enables JavaScript to be used for a variety of applications beyond just web pages. With Node.js, developers can build server-side applications, command-line tools, and development scripts, effectively making JavaScript a full-stack programming language.</p> <p>One of Node.js\u2019s major advantages is its non-blocking, event-driven architecture, which makes it well-suited for handling real-time applications and high-performance web services. Unlike traditional languages like Python and Java, which use a thread-based model where each task or request waits for the previous one to complete, Node.js operates differently. Instead of waiting for one operation to finish before moving on to the next, Node.js continues executing other tasks while waiting for asynchronous operations to complete.</p>"},{"location":"resources/frontend/1-tools/#understanding-non-blocking-event-driven-architecture","title":"Understanding Non-Blocking, Event-Driven Architecture","text":"<p>Consider a scenario in Python where you need to make an HTTP request to an external API and process its response. A typical synchronous implementation might look like this:</p> <pre><code>import requests\n\nresponse = requests.get('https://api.example.com/data')\ndata = response.json()\nprint(\"Data fetched successfully\")\nprint(data)\n</code></pre> <p>In this example, Python blocks execution while waiting for the HTTP request to complete. The program cannot continue to the next task until the request finishes.</p> <p>Now, let's compare this to a Node.js equivalent using an asynchronous approach:</p> <pre><code>const https = require('https');\n\nhttps.get('https://api.example.com/data', (res) =&gt; {\n    let data = '';\n    res.on('data', chunk =&gt; data += chunk);\n    res.on('end', () =&gt; {\n        console.log(\"Data fetched successfully\");\n        console.log(data);\n    });\n});\n\nconsole.log(\"Fetching data...\");\n</code></pre> <p>Here, instead of blocking execution, Node.js continues running the next line (<code>console.log(\"Fetching data...\");</code>) while the HTTP request happens in the background. Once the request completes and data is received, the provided callback function executes. This is what makes Node.js non-blocking\u2014it does not pause the execution of other tasks while waiting for an I/O operation to complete.</p> <p>We will spend significantly more time and effort digging into the implications and approaches to working with asynchronous, event-driven programming.</p>"},{"location":"resources/frontend/1-tools/#the-challenges-of-writing-large-scale-javascript-applications","title":"The Challenges of Writing Large-Scale JavaScript Applications","text":"<p>While JavaScript is a powerful and flexible language, it comes with several challenges when developing and maintaining large applications, particularly in team settings. Here are some key limitations:</p> <ol> <li>Lack of Static Typing: JavaScript is dynamically typed, meaning type errors can go undetected until runtime, leading to unpredictable behavior and increased debugging time.</li> <li>Poor Readability and Maintainability: Without enforced types and clear function signatures, large codebases become harder to read and maintain, especially for new team members.</li> <li>Inconsistent Code Quality: JavaScript allows multiple ways to achieve the same outcome, making it difficult to enforce consistent coding standards across a team. Just because you can do something in JavaScript in a shortcut way, doesn't mean an engineering team should and the lack of enforcement against these concerns leads to unruly codebases.</li> <li>Limited IDE Support and Refactoring Tools: JavaScript\u2019s flexibility limits the effectiveness of modern development tools like autocompletion and refactoring assistance.</li> </ol> <p>These limitations have led to the growing adoption of TypeScript, a superset of JavaScript that adds static typing and improved tooling. TypeScript is an open source programming language created by Microsoft's Developer Division, the same group that makes VSCode! In fact, VSCode is implemented in TypeScript! In the next section, we\u2019ll explore how TypeScript helps address these challenges and why it has become a preferred choice for scalable web development.</p>"},{"location":"resources/frontend/2-typescript/","title":"TypeScript For the COMP 301 Java Developer","text":"<p>Written by Ajay Gandecha and Kris Jordan for the CSXL Web Application and for COMP 423: Foundations of Software Engineering.</p>"},{"location":"resources/frontend/2-typescript/#preface","title":"Preface","text":"<p>During your career at UNC, you likely started out in COMP 110 learning the Python programming language. In COMP 210, you transitioned to Java and learned how to organize your code using classes and common data structures. In COMP 301, you built off of this idea and learned more about useful language features to help you gain a toolbox of design patterns and strategies for approaching software architecture challenges.</p> <p>Since this course's semester project is currently focused on web applications, you need to gain familiarity with the programming languages and tools needed to build high quality web apps. As you just read, JavaScript is the leading programming language that powers the web and web applications. According to the 2023 StackOverflow Developer Survey, developers ranked JavaScript as their most commonly-used programming language - an eleven-year long streak and counting!</p> <p>In this course, we will use TypeScript to build out the frontend of our web applications. TypeScript is a superset of JavaScript - it adds static typing with optional type annotations to JavaScript. It transpiles to JavaScript.</p> <p>Static typing is practiced in COMP110 with Python's modern type annotations, which were actually inpsired by TypeScript's success, and has its roots in industrial languages like Java and C. The word \"static\", in this context, refers to at development time which is, importantly, not at runtime. You can think of static as \"code at rest\" when it is in your editor or being analyzed by a compiler, not code that is actually running on a machine. Specifying static types allows the TypeScript IDE (e.g., VSCode) and compiler to verify that your code's expressions and statements are type safe. An example of a type safety check would be ensuring that if your code contains a call to a method named <code>bar</code> on an object of type <code>Foo</code>, that in the <code>Foo</code> class definition there actually exists a method named <code>bar</code> with the correct parameters corresponding to the arguments provided. Without type safety, or static type annotations, you increase your risk of writing code that breaks when your users are using it, after release, rather than at development time, before release. Static type specification also serves as a form of built-in documentation for other developers on your team to know how to properly use each other's code more reliably and confidently. Static type checking represents an important theme of Software Engineering as a discipline, and this course: time invested in detailed specification and documentation allows teams to collaborate more successfully and unlocks opportunities to verify correctness with tools during development.</p> <p>TypeScript shares some similarities to Java - both are high-level languages, both support object-oriented programming. However, there are many key differences (including their purpose, how they are compiled, etc). You will learn more about these features throughout the course. </p> <p>This document is designed to help you become familiar with the syntax and features of TypeScript from the context of the Java experience you all have had in COMP 301. It compares the syntax between Java and TypeScript in various situations and should serve as a guide going into the first few weeks of the semester.</p>"},{"location":"resources/frontend/2-typescript/#syntax","title":"Syntax","text":"<p>The syntax for TypeScript is pretty succint and less verbose than Java! In this section, you will learn the syntax of TypeScript code with the context of the Java syntax you have worked in throughout COMP 210 and COMP 301.</p>"},{"location":"resources/frontend/2-typescript/#typing","title":"Typing","text":"<p>The first major distinction between Java and TypeScript exists with its typing system. Recall the following:</p> <ul> <li>Primitive types are a set of basic data types in a programming language. All other data types and classes can be constructed from these primitive types. Using standard programming conventions, primitive types are often denoted with an all-lowercase name and usually do not need to be imported.</li> <li>Reference types, on the other hand, are all of the other types in a language. Reference types are defined as structures that contain or build upon the basic primitive types. Reference types are often defined by interfaces, classes, and enumerations. Reference types, like the name of all clases, often start with a capital letter (For example, <code>Dog</code> or <code>Cat</code>).</li> </ul> <p>In Java, we have the following primitive types: * <code>int</code>: Represents a number with no decimal places. * <code>double</code>: Represents a number that can store fractions (decimal places). * <code>boolean</code>: Represents a state that can either be <code>true</code> or <code>false</code>.</p> <p>In TypeScript, on the otherhand, we have different primitive types. TypeScript defines the following: * <code>number</code>: Represents a number that can store fractions (decimal places). * <code>boolean</code>: Represents a state that can either be <code>true</code> or <code>false</code>. * <code>string</code>: Represents a sequence of characters.</p> <p>Notice there is not a type distinction between integers and floats / doubles. We use <code>number</code> in TypeScript for both. This is helpful because it effectively allows us to work with double-floating point, 64-bit, values for all numerical computations.</p> <p>Second, notice that <code>string</code> is not capitalized in TypeScript. Technically, the string values we use wind up being references and realizations of the immutable <code>String</code> class in TypeScript/JavaScript, with its expected methods, but its type is specified with lowercase letters as a built-in.</p>"},{"location":"resources/frontend/2-typescript/#variable-and-constant-declarations","title":"Variable and Constant Declarations","text":"<p>Now that you know a bit about the basic data types in TypeScript, let's take a look at how to define variables.</p> <p>Let's compare a number declaration in Java and TypeScript, then compare more generally.</p> JavaTypeScript <pre><code>// Declaring a Number\nint myNumber = 88;\n\n// General Formula\ntype name = value;\n</code></pre> <pre><code>// Declaring a Number\nlet myNumber: number = 88;\n\n// General Formula\nlet name: type = value;\n</code></pre> <p>As you can see, there are a few differences. First, in Java, we specify the data type first. In TypeScript, we provide a type annotation after the name of the variable. We also provide the <code>let</code> keyword before variable name.</p> <p>You can also notice the difference in types. In Java, we use the <code>int</code> primitive type. In TypeScript, we use <code>number</code> instead. Lastly, you can note that both Java and TypeScript use semicolons at the end of their lines.</p> <p>What if we wanted to make these values constants instead of variables (so that we cannot change their value later)?</p> JavaTypeScript <pre><code>// Declaring a Constant\nfinal int myNumber = 88;\n\n// General Formula\nfinal type name = value;\n</code></pre> <pre><code>// Declaring a Constant\nconst myNumber: number = 88;\n\n// General Formula\nconst name: type = value;\n</code></pre> <p>As you can see, in Java, we use the <code>final</code> keyword to turn a variable into a constant. The keyword is appended to the front. In TypeScript however, we just use the <code>const</code> keyword instead of the <code>let</code> keyword!</p>"},{"location":"resources/frontend/2-typescript/#arrays","title":"Arrays","text":"<p>The way that arrays work in Java and TypeScript are a bit different, and so is the syntax to create them.</p> <p>In Java, you probably remember that the length of an array cannot be changed once it is set - and that using <code>ArrayList&lt;&gt;</code> or any other subtype of <code>List</code> (imported from <code>java.utils.*</code>) provides this functionality!</p> <p>TypeScript arrays are more similar to the Java <code>List</code> than to the Java array. Creating arrays in TypeScript is also very similar to creating lists in Python. To declare an array in TypeScript, we can simply add <code>[]</code> to the end of a variable's type annotation, and use brackets to add initial values. Compare the following:</p> TypeScriptPythonJava <pre><code>// Initialize\nlet names: string[] = [\"Aziz\", \"Andrew\"]\n// Add values\nnames.push(\"Jordan\");\n// Replace a value\nnames[2] = \"Kris\";\n// Remove a value\nnames.splice(names.indexOf(\"Kris\"), 1); // Removes by value\nnames.splice(1, 1); // Removes by index\n// Access a value \nlet aziz: string = names[0];\n</code></pre> <pre><code># Initialize\nnames: list[str] = [\"Aziz\", \"Andrew\"]\n# Add values\nnames.append(\"Jordan\")\n# Replace a value\nnames[2] = \"Kris\"\n# Remove a value\nnames.remove(\"Kris\") # Removes by value\nnames.remove(1) # Removes by index\n# Access a value\naziz = names[0]\n</code></pre> <pre><code>// Initialize\nList&lt;String&gt; names = new ArrayList&lt;&gt;();\nnames.add(\"Aziz\");\nnames.add(\"Andrew\");\n// Add values\nnames.add(\"Jordan\");\n// Replace a value\nnames.set(\"Kris\", 2);\n// Remove a value\nnames.remove(\"Kris\"); // Removes by value\nnames.remove(1); // Removes by index\n// Access a value\nString aziz = names.get(0);\n</code></pre> <p>Just like in Python lists and traditional Java arrays (but unlike Java's <code>List</code>), we can index values of TypeScript arrays using the subscription <code>[]</code> syntax.</p> <p>As shown in the code above, TypeScript does not have a built-in delete method - but, it does have <code>.splice(i, n)</code>, which removes <code>n</code> number of elements starting at index <code>i</code>. So, we can combine this with <code>.indexOf()</code> to delete our value.</p> <p>TypeScript's arrays also have a <code>.pop()</code> method that removes the last item of an array. </p> <p>To access the length of a TypeScript array, you can use the array's <code>length</code> field. For example, given an array <code>a</code>, the length of this array would be accessed using <code>a.length</code>.</p>"},{"location":"resources/frontend/2-typescript/#conditionals","title":"Conditionals","text":"<p>Java and TypeScript have similar syntax for creating conditional statements and if-statements. </p> <p>TypeScript uses the same boolean operators that Java does. This means that <code>&amp;&amp;</code> represents AND, <code>||</code> represents OR, and <code>!</code> represents NOT. TypeScript and Java both use the lowercased <code>true</code> and <code>false</code> for boolean values.</p> <p>Additionally, following in the C-family heritage, the <code>&amp;&amp;</code> and <code>||</code> operators are short-circuiting. If the left-hand expression of an <code>&amp;&amp;</code> operator is <code>false</code>, the right-hand expression will not be evaluated. Conversely, if the left-hand expression of an <code>||</code> operator is <code>true</code>, then the right-hand expression will not be evaluated. This matters when the right-hand expression contains a function or method call that mutates state.</p> <p>Coming from Java, one surprising feature of JavaScript and TypeScript is the notion of truthiness. You can learn more about truthy values on MDN, a great documentation resource for front-end web concerns. Many values besides the boolean value <code>true</code> are treated as <code>true</code>/\"truthy\" in boolean contexts in JavaScript. For example, any non-empty strings and any non-zero numbers are considered \"truthy\" in boolean contexts. This means you can write a valid, type safe expression like <code>\"foo\" || \"\"</code>. Surprisingly, the <code>||</code> operator evaluates to its first truthy value, so <code>\"foo\" || \"\"</code>, <code>\"\" || \"foo\"</code>, and <code>\"foo\" || \"bar\"</code> all evaluate to <code>\"foo\"</code>, not <code>true</code>. This is handy and commonly used in variable initialization statements, such as <code>let initialValue: string = userInput || \"Default Value\";</code></p> <p>If-statements have the same syntax and usage as they do in Java!</p> JavaTypeScript <pre><code>if (conditionA || conditionB) {\n // Some code here!\n}\nelse {\n // Some code here.\n}\n</code></pre> <pre><code>if (conditionA || conditionB) {\n // Some code here!\n}\nelse {\n // Some code here.\n}\n</code></pre> <p>NOTE: Both Java and TypeScript require the use of parenthesis <code>( )</code> around the conditional statements in if-statements.</p>"},{"location":"resources/frontend/2-typescript/#loops","title":"Loops","text":""},{"location":"resources/frontend/2-typescript/#the-while-loop","title":"The <code>while</code> Loop","text":"<p>Just like with if-statements, both Java and TypeScript use the same syntax for while loops! We use parenthesis around the conditional in both languages. </p> JavaTypeScript <pre><code>while (conditionA) {\n // Some code here!\n}\n</code></pre> <pre><code>while (conditionA) {\n // Some code here!\n}\n</code></pre>"},{"location":"resources/frontend/2-typescript/#the-for-loop","title":"The <code>for</code> Loop","text":"<p>In both Java and TypeScript, there are two types of loops that both serve distinct purposes.</p> <p>The first type of loop contains a counter variable that is modified each time the the loop iterates - and, iteration stops when some provided condition evaluates to false. This type of loop exists in both Java and TypeScript. The code is nearly identical, but notice that in the TypeScript version, we need to use our new method of creating variables. We do not say <code>int i = 0;</code>, instead we say <code>let i = 0;</code>. We can see this here:</p> JavaTypeScript <pre><code>for(int i = 0; i &lt; 10; i++) {\n // Loop body here...\n}\n</code></pre> <pre><code>for(let i = 0; i &lt; 10; i++) {\n // Loop body here...\n}\n</code></pre> <p>NOTE: In this example, notice how we do not include the type annotation on the conditional variable. In general, type annotations on variables in TypeScript are not necessary by default. TypeScript infers types of variables when there is no explicit type annotation provided. However, including them is strongly encouraged. In this case, for conciseness in the for loop header body and the the fact that the variable's type is guaranteed to be <code>number</code>, it can be omitted here.</p> <p>The second type of loop in Java allows you to iterate over a collection, where a variable is updated with a value corresponding to the current iteration. This is often the most widely-used loop. There are syntactical differences here between Java and TypeScript, both in the keywords used and the variable creation convention.</p> JavaTypeScript <pre><code>for(String name : names) {\n // Loop body here...\n}\n</code></pre> <pre><code>for(let name of names) {\n // Loop body here...\n}\n</code></pre> <p>As you can see, like in previous examples, TypeScript uses the <code>let</code> keyword. In addition, Java uses <code>:</code>, while TypeScript uses <code>of</code>.</p>"},{"location":"resources/frontend/2-typescript/#defining-functions","title":"Defining Functions","text":"<p>Functions are the most fundamental abstraction technique we use in software engineering. It is important to note that in Java, we create methods, which are functions that are members of a class. In TypeScript, we also mainly work in the context of classes, but we are not necessarily required to. So, if you are hearing the term \"functions\" and \"methods\" passed around, it is useful to remember this distinction: methods are called on an object (e.g. <code>object.method()</code>) whereas functions are generally called standalone <code>function()</code>. This distinction has some nuance in more advanced uses of TypeScript/JavaScript, but is generally how you should approach it.</p> <p>There are many fundamental differences in the syntax for creating functions in Java and TypeScript. Let's take a look at an example of a function that takes in a user's name and returns a string that greets the user.</p> JavaTypeScript <pre><code>String greet(String name) {\n return \"Welcome, \" + name + \"!\";\n}\n</code></pre> <pre><code>function greet(name: string): string {\n return \"Welcome, \" + name + \"!\";\n}\n</code></pre> <p>There are a few noticeable differences. First, TypeScript uses the <code>function</code> keyword at the front rather than specifying a return type first. Also, the type annotation is at the end of the function header (and before the body). The placement of type annotations for the function parameters also changes here.</p> <p>In the case that a function returns nothing, note that in Java, we specify the return type to be <code>void</code>. We can do this in TypeScript too, however it is optional. Both including <code>: void</code> or not is valid. For example:</p> JavaTypeScript <pre><code>void doSomething() {\n // Implementation Not Shown\n}\n</code></pre> <pre><code>function doSomething() {\n // Implementation Not Shown\n}\n\n// OR\n\nfunction doSomething(): void {\n // Implementation Not Shown\n}\n</code></pre>"},{"location":"resources/frontend/2-typescript/#arrow-functions","title":"Arrow Functions","text":"<p>TypeScript also has a tremendously useful feature called arrow functions. Arrow functions are a more compact and concise method of defining traditional functions. Let's take a look at a function from above as a traditional function and one as an arrow function.</p> TypeScript - Traditional FunctionTypeScript - Arrow Function <pre><code>function greet(name: string): string {\n return \"Welcome, \" + name + \"!\";\n}\n</code></pre> <pre><code>let greet = (name: string): string =&gt; {\n return \"Welcome, \" + name + \"!\";\n}\n</code></pre> <p>There are a few things to unpack here. First, it looks like we are ultimately assigning \"something\" to a variable. We use the <code>let</code> keyword and we provide a variable name! On the right, we have a weird structure that would go in the value spot of our variable formula.</p> <p>In fact, this is exactly what we are doing! We are saving a function to a variable and giving it a name that we can use to call it. In the <code>( )</code>, we provide the parameters to the function. We provide a return type in the type annotation as well. Then, we use <code>=&gt;</code> to connect these parameters to a function body.</p> <p>We can then call our function in the same way we would normally, like so: <pre><code>greet(\"Jade\");\n</code></pre></p> <p>While this seems like just a syntactic change, the implications of this are massive and opens the door to an entire new world of programming called functional programming, as we can pass around functions as values. This is something that we will be covering extensively throughout this course, however it is super important to become familiar with the arrow function syntax now so it is less suprising later!</p> <p>To conclude this section, provide two important caveats must be emphasized: * Arrow functions don't have their own <code>this</code> bindings and therefore should not be used when defining methods of a class. * Arrow functions cannot be used as constructors. Calling them with <code>new</code> throws a <code>TypeError</code>.</p> <p>These caveats are important to note because traditional functions and arrow functions are not exactly the same, and there are some semantic differences.</p>"},{"location":"resources/frontend/2-typescript/#class-and-interface-construction","title":"Class and Interface Construction","text":"<p>Classes define data types and are the foundation of object-oriented programming. It will be critical for you to be comfortable working within TypeScript classes throughout your time in COMP 423! While there are many syntax differences between classes in Java and TypeScript, the core idea and motivation for using them remains the same. Below is an example of a full class in both Java and TypeScript. I recommend that you read this in its entirely and try to compare line by line! From there, we will go through each section.</p> TypeScriptJava <pre><code>/** Represents a UNC Student. */\npublic class Student {\n\n    /* Fields\n    * NOTE: In COMP 301, you learned about using the\n    * `private` keyword on fields to control access\n    * via getter and setter methods. For this example,\n    * I am making some fields public and others private.\n    */\n\n    /** Represents the name of the student */\n    public name: string;\n    /** Represents the year of the student*/\n    public year: number;\n    /** Represents the address of the student */\n    private address: string;\n\n    /* Constructor */\n    constructor(name: string, year: number, adr: string) {\n        this.name = name;\n        this.year = year;\n        this.address = adr;\n        this.welcome();\n    }\n\n    /* Methods */\n\n    /** Prints a welcome message to the console. */\n    public welcome() {\n        console.log(\"Hello, \" + this.name + \"!\");\n    }\n\n    /** Converts a year number to a description. */\n    public static yearToString(year: number): string {\n        if(year == 1) {\n            return \"Freshman\";\n        } else if(year == 2) {\n            return \"Sophomore\";\n        } else if(year == 3) {\n            return \"Junior\";\n        } else if(year == 4) {\n            return \"Senior\";\n        }\n\n        return \"Oops...\";\n    }\n}\n</code></pre> <pre><code>/** Represents a UNC Student. */\npublic class Student {\n\n    /* Fields\n    * NOTE: In COMP 301, you learned about using the\n    * `private` keyword on fields to control access\n    * via getter and setter methods. For this example,\n    * I am making some fields public and others private.\n    */\n\n    /** Represents the name of the student */\n    public String name;\n    /** Represents the year of the student*/\n    public int year;\n    /** Represents the address of the student */\n    private String address;\n\n    /* Constructor */\n    public Student(String name, int year, String adr) {\n        this.name = name;\n        this.year = year;\n        this.address = adr;\n        this.welcome();\n    }\n\n    /* Methods */\n\n    /** Prints a welcome message to the console. */\n    public void welcome() {\n        System.out.println(\"Hello, \" + this.name + \"!\");\n    }\n\n    /** Converts a year number to a description. */\n    public static String yearToString(int year) {\n        if(year == 1) {\n            return \"Freshman\";\n        } else if(year == 2) {\n            return \"Sophomore\";\n        } else if(year == 3) {\n            return \"Junior\";\n        } else if(year == 4) {\n            return \"Senior\";\n        }\n\n        return \"Oops...\";\n    }\n}\n</code></pre> <p> </p> <p>As you can see, there are a few similarities between classes in Java and TypeScript! First, we can look at access modifiers. The <code>public</code>, <code>private</code>, and <code>protected</code> keywords are the same in both Java and TypeScript.</p> <p>Notice that the fields are the same conventions as well! Note however that the <code>let</code> keyword is not used when defining fields - it is only needed when defining regular variables.</p> <p>The constructor also differs a bit. In TypeScript, the <code>constructor</code> keyword replaces <code>public ClassName</code> from Java! The type annotations in the parameters also follow the normal conventions of TypeScript functions.</p> <p>Lastly, like fields, methods in TypeScript also do not use their respective keyword (<code>function</code>) to be defined. Instead, we can just provide an access modifier.</p> <p>We use the <code>static</code> keyword to denote class methods the same way in both Java and TypeScript. Learn more about class fields and methods here.</p> <p>Within a function, we also have access to the <code>this</code> keyword that references the current object.</p> <p>Now, how do we instantiate objects?</p> <p>We actually use the same syntax as in Java:</p> JavaTypeScript <pre><code>Student noah = new Student(\"Noah\", 3, \"Columbia St\");\n</code></pre> <pre><code>noah: Student = new Student(\"Noah\", 3, \"Columbia St\");\n</code></pre> <p>We can also define interfaces in TypeScript like we do in Java. Take a look at the following:</p> JavaTypeScript <pre><code>public interface Person {\n String name;\n}\n\npublic class Student implements Person { /* ... */ }\n</code></pre> <pre><code>public interface Person {\n name: string;\n}\n\npublic class Student implements Person { /* ... */ }\n</code></pre> <p>As you can see, the keywords remain the same between both languages with <code>interface</code> and <code>implements</code>! The only difference between the two languages are with variable creation and type annotation conventions.</p> <p>There is also another interesting feature of TypeScript worth mentioning here.</p> <p>TypeScript employs structural type checking. This means that TypeScript views objects as equivalent types if they share the same structure, NOT just the same name! On the otherhand, Java is a nominally type language, which means it views objects as equivalent types if they share the same name ONLY (or if there is an inheritence relationship).</p> <p>So, we can technically directly create a value of type <code>Person</code> in TypeScript! This is not something you can directly do in Java without creating a subclass. The syntax would look like so:</p> TypeScript <pre><code>let person: Person = {\n name: \"Charles\"\n};\n</code></pre> <p>In this example, we use JSON (JavaScript object notation) to create an object of data that contains the same properties that a <code>Person</code> objct should have. Surprisingly enough, due to TypeScript being a structural language, this is a valid way to instantiate an object, technically of type object, that can used anywhere an object of type <code>Person</code> is expected without explicitly implementing the <code>Person</code> interface!</p> <p>This feature is often called \"duck typing\", thanks to the addage \"if it looks like a duck, swims like a duck, and quacks like a duck, then it probably is a duck.\" TypeScript and structural typing take it further: \"if it's a goose that looks like a duck, then it's a duck.\" In programming, structural type checking like TypeScript's, relaxes the strictness of nominal typing like Java's, by embracing the idea that if an object has all the same fields and methods needed as some other type, then it's probably OK to treat it as that other type.</p>"},{"location":"resources/frontend/2-typescript/#extra-typescript-features","title":"Extra TypeScript Features","text":""},{"location":"resources/frontend/2-typescript/#comments","title":"Comments","text":"<p>The examples throughout this document have already used many comments, however we create comments in Java and TypeScript in the exact same way! This is shown below:</p> JavaTypeScript <pre><code>// This is a single-line comment.\n\n/*\nThis is an example of a\nmulti-line comment!\n*/\n</code></pre> <pre><code>// This is a single-line comment.\n\n/*\nThis is an example of a\nmulti-line comment!\n*/\n</code></pre>"},{"location":"resources/frontend/2-typescript/#printing-values","title":"Printing Values","text":"<p>In Java and TypeScript, we have statements to print out values! In TypeScript, values are printed to the console. We use the following convention to print values:</p> JavaTypeScript <pre><code>String taName = \"Jean\";\nSystem.out.println(taName);\n// Output:\n// &gt;&gt; Jean\n</code></pre> <pre><code>let taName: string = \"Jean\";\nconsole.log(taName);\n// Console:\n// &gt;&gt; Jean\n</code></pre> <p>As you can see, we use <code>console.log()</code> to print out values to the console in TypeScript. To see values printed to <code>console.log()</code> in a browser, you will need to open your browser's developer tools and view its console tabl.</p>"},{"location":"resources/frontend/2-typescript/#enums","title":"Enums","text":"<p>Enums (enumerators) are an extremely useful language feature in many programming languages! Enums allow you to define custom, related values or states. Think of enums as implementing a multiple-choice question, where there are many options! Let's look at an example:</p> JavaTypeScript <pre><code>enum Direction {\n  UP,\n  DOWN,\n  LEFT,\n  RIGHT,\n}\n</code></pre> <pre><code>enum Direction {\n  Up,\n  Down,\n  Left,\n  Right,\n}\n</code></pre> <p>As you might notice, creating enums in TypeScript is nearly equivalent to its Java counterpart that you saw in COMP 301! The main difference is that it is convention for Java enum options to be entirely  capitalized, while TypeScript enum options only have their first letter capitalized.</p> <p>Let's look at the <code>Direction</code> enum applied in a TypeScript function:</p> TypeScript <pre><code>function directionToText(direction: Direction): string {\n if(direction == Direction.Up || direction == Direction.Down) {\n  return \"Let's go vertically!\"\n }\n else if (direction == Direction.Left || direction == Direction.Right) {\n  return \"Let's go horizontally!\"\n }\n}\n</code></pre> <p>Enumerations will be extremely useful in your final projects to model data.</p>"},{"location":"resources/frontend/2-typescript/#type-aliases","title":"Type Aliases","text":"<p>There is a nifty feature in TypeScript called the type alias, which essentially allows you to create another label by which you can refer to a type. This can be useful to make types more concise, or to make it more readable for your feature. Look at the following example:</p> TypeScript <pre><code>type Rating = number;\n\nlet csxlRating: Rating = 10;\n</code></pre> <p>Using the <code>type</code> keyword, we give <code>number</code> an alias as <code>Rating</code>. Now, we can use <code>number</code> and <code>Rating</code> interchangeably. Next, we create a variable called <code>csxlRating</code> of type <code>Rating</code> (which is really just type <code>number</code>), and then assign a number to it.</p>"},{"location":"resources/frontend/2-typescript/#ternary-operator","title":"Ternary Operator","text":"<p>The last super useful feature of TypeScript to feature in this document is the ternary operator. The ternary operator allows you to write a conditional expression. Unlike the <code>if</code>/<code>else</code> syntax in TypeScript and Java, which are statements, the ternary operator results in an expression. This means that if a condition is <code>true</code>, the expression can evaluate to one value and if it's <code>false</code>, another.</p> <p>The ternary operator uses the following syntax: <code>condition ? expr_if_true : expr_if_false</code></p> <p>Let's look at an example relating to the CSXL site:</p> TypeScript <pre><code>// Stores the hour which the CSXL opens.\n// For sake of example, say the CSXL opens at 10am on weekdays and 12pm on weekends:\nlet csxlOpeningHour: number = isWeekday ? 10 : 12;\n\nconsole.log(csxlOpeningHour);\n\n// Output IF isWeekday = true:\n// &gt;&gt; 10\n// Output IF isWeekday = false:\n// &gt;&gt; 12\n\n// Since the ternary operator produces an expression, it can\n// also be used like:\nconsole.log(isWeekday ? \"Weekday\" : \"Weekend\")\n</code></pre> <p>This is the same syntax that is used in Java! Ternary operators are extremely useful and are used numerous times throughout the CSXL application. I highly recommend checking out the codebase and searching for <code>?</code> / <code>:</code> to see more relevant examples!</p>"},{"location":"resources/frontend/2-typescript/#generic-types","title":"Generic Types","text":"<p>Generic types are a powerful convention in Java that allows you to pass types as a parameter into objects. This makes objects support multiple data types.</p> <p>For example, take a <code>LinkedList</code> implementation in Java. Linked lists are data structures that can store many different types of values. For example, look at the following in Java:</p> Java <pre><code>// Create a linked list that stores strings.\nLinkedList&lt;String&gt; myStringList = new LinkedList&lt;&gt;();\n// Create a linked list that stores students.\nLinkedList&lt;Student&gt; myRoster = new LinkedList&lt;&gt;(); \n</code></pre> <p>The above Java syntax likely looks vaguely familiar! Here, we are creating two linked lists - one of <code>String</code> objects and the other of <code>Student</code> objects. We pass the data type of the object we want to store into the <code>&lt; &gt;</code> part of the type annotation.</p> <p>TypeScript also supports generic types! This is a feature that will be used a lot throughout this course. First, let's compare the syntax for creating the hypothetical lists shown above:</p> JavaTypeScript <pre><code>// Create a linked list that stores strings.\nLinkedList&lt;String&gt; myStringList = new LinkedList&lt;&gt;();\n// Create a linked list that stores students.\nLinkedList&lt;Student&gt; myRoster = new LinkedList&lt;&gt;(); \n</code></pre> <pre><code>// Create a linked list that stores strings.\nlet myStringList: LinkedList&lt;string&gt; = new LinkedList&lt;&gt;();\n// Create a linked list that stores students.\nlet myRoster: LinkedList&lt;Student&gt; = new LinkedList&lt;&gt;(); \n</code></pre> <p>As you can see, the only thing different between both code snippets are how we declare the variable! The usage of <code>&lt; &gt;</code> remains the same.</p> <p>Now, how would we actually implement the <code>LinkedList&lt;T&gt;</code> class? Let's compare two rudimentary implmentations in both Java and TypeScript:</p> JavaTypeScript <pre><code>/** Represents a linked list node. */\npublic class LinkedList&lt;T&gt; {\n\n /** Value for the node. */\n private T value;\n /** Next node, if it exists. */\n private LinkedList&lt;T&gt; next;\n\n /** Constructor */\n public LinkedList(T value) {\n  this.value = value;\n }\n\n /** Returns the value of the node. */\n public T getValue() {\n  return this.value;\n }\n\n/* Modifies the value of the node. */\n public void setValue(T value) {\n  this.value = value;\n }\n\n /* Other methods not shown */\n}\n</code></pre> <pre><code>/** Represents a linked list node. */\npublic class LinkedList&lt;T&gt; {\n\n /** Value for the node. */\n private value: T;\n /** Next node, if it exists. */\n private next: LinkedList&lt;T&gt;;\n\n /** Constructor */\n constructor(value: T) {\n  this.value = value;\n }\n\n /** Returns the value of the node. */\n public getValue(): T {\n  return this.value;\n }\n\n/* Modifies the value of the node. */\n public setValue(value: T) {\n  this.value = value;\n }\n\n /* Other methods not shown */\n}\n</code></pre> <p>In the header of the class, we put <code>&lt;T&gt;</code>, which specifies that we are adding a type parameter! Whenever this is then provided, like in <code>LinkedList&lt;string&gt;</code> or <code>LinkedList&lt;Student&gt;</code>, the <code>T</code> used throughout the class is then replaced by the type that is provided! So in the <code>LinkedList&lt;string&gt;</code> example, the field <code>value</code> becomes of type <code>string</code>. In the <code>LinkedList&lt;Student&gt;</code> example, the field <code>value</code> becomes of type <code>Student</code>.</p> <p>If this concept is unfamiliar, we highly recommend to practice using generic types in classes, as well as experimenting on your own! Generic types are an invaluable tool to make code extendable to multiple use-cases, and is used in many of the packages we are going to use throughout the course.</p>"},{"location":"resources/frontend/2-typescript/#conclusion","title":"Conclusion","text":"<p>Congratulations! \ud83c\udf89 TypeScript is an extremely powerful and useful language, and we you will have the chance to work with TypeScript code this entire semester. If you are having trouble remembering TypeScript syntax, feel free to return to this document at any time. In addition, for practice, we highly recommend you go to the official TypeScript playground or open a new Repl.it ! The TypeScript playground, as well as opening a <code>.ts</code> TypeScript file in Visual Studio Code and playing around with it, are some of the best ways to get more familiar and accustomed to using the language. As you have seen throughout your computer science careers so far, sometimes the best way to learn is to dive right in!</p> <p>In addition, below are some additional resources that you may find useful as your work through learning TypeScript.</p>"},{"location":"resources/frontend/2-typescript/#extra-resources","title":"Extra Resources","text":"<ul> <li>Official TypeScript Cheat Sheets</li> <li>Official Docs - TypeScript for the Java Programmer</li> </ul>"},{"location":"resources/frontend/3-event-driven/","title":"Introduction to Event-Driven Programming in TypeScript","text":""},{"location":"resources/frontend/3-event-driven/#function-definitions-and-arrow-functions","title":"Function Definitions and Arrow Functions","text":"<p>As a refresher from the previous reading, in TypeScript, functions are first-class citizens, meaning they can be assigned to variables, passed as arguments, and returned from other functions. One of the most common ways to define functions concisely is using arrow functions.</p> <p>Here\u2019s a simple example:</p> <pre><code>const square = (x: number): number =&gt; {\n    return x * x;\n};\n</code></pre> <ul> <li>The function takes a parameter <code>x</code> of type <code>number</code>.</li> <li>It returns a <code>number</code>.</li> <li>The function itself is stored in a variable <code>square</code>, which holds a reference to the function definition.</li> </ul>"},{"location":"resources/frontend/3-event-driven/#short-hand-arrow-function-syntax","title":"Short-Hand Arrow Function Syntax","text":"<p>For functions whose bodies consist of a single return statement, like the <code>square</code> function, JavaScript and TypeScript provide a shorthand syntax:</p> <pre><code>const square = (x: number): number =&gt; x * x;\n</code></pre> <p>This is still a full function definition! It simply omits the curly braces and <code>return</code> keyword to make the code more concise. This form is often used in functional programming and for inline callbacks.</p>"},{"location":"resources/frontend/3-event-driven/#functional-interfaces","title":"Functional Interfaces","text":"<p>In TypeScript, we can define an interface that represents a function type. This makes our code more structured and provides strong type-checking. Unlike an object-oriented interface, a functional interface does not name the methods it supports; it simply defines a function signature that any matching function can satisfy.</p> <pre><code>interface UnaryFunction {\n    (x: number): number;\n}\n\nconst squareFunction: UnaryFunction = (x) =&gt; x * x;\n</code></pre>"},{"location":"resources/frontend/3-event-driven/#why-is-this-a-functional-interface","title":"Why is this a Functional Interface?","text":"<p>The key distinction between a functional interface and a traditional object-oriented interface is that a functional interface does not define named methods; instead, it only specifies a function signature. This means that any function conforming to the parameter and return types can be assigned to a variable of this type.</p>"},{"location":"resources/frontend/3-event-driven/#understanding-function-types","title":"Understanding Function Types","text":"<p>A function\u2019s type is determined by the combination of its parameter types and return type. This is intuitive because if two functions agree on these types, they can be used interchangeably in function call expressions without breaking type safety.</p> <p>For example, consider:</p> <pre><code>const double: UnaryFunction = (x) =&gt; x * 2;\nconst negate: UnaryFunction = (x) =&gt; -x;\n</code></pre> <p>Since <code>double</code> and <code>negate</code> both conform to the <code>UnaryFunction</code> signature, we can substitute one for the other in any context where a <code>UnaryFunction</code> is expected, and TypeScript will still type-check correctly.</p> <p>This principle of substitutability ensures that TypeScript maintains strong type safety while allowing flexibility in function-based programming paradigms.</p>"},{"location":"resources/frontend/3-event-driven/#type-inference","title":"Type Inference","text":"<p>A modern feature of TypeScript is type inference, which allows the compiler to automatically determine types based on context. Since the type of function variables like <code>double</code> and <code>negate</code> is explicitly defined, TypeScript can infer and enforce the correct parameter and return types without needing additional annotations.</p> <p>This provides the best of both worlds: full type safety while reducing the effort required to redundantly specify types that can be inferred.</p>"},{"location":"resources/frontend/3-event-driven/#higher-order-functions","title":"Higher-Order Functions","text":"<p>A higher-order function is a function that takes another function as an argument or returns a function. This allows us to write more flexible and reusable code by parameterizing behavior.</p>"},{"location":"resources/frontend/3-event-driven/#higher-order-function-example-map","title":"Higher-order Function Example: <code>map</code>","text":"<p>Before diving into the code, let\u2019s break down <code>map</code> in English. Imagine you have a list of numbers, and you want to apply a specific operation\u2014like squaring each number\u2014to every element. One way to do this is with a loop, applying the operation to each item manually. But what if you want to apply different operations, such as doubling or taking the absolute value? Instead of writing separate loops for each case, we can use <code>map</code> to generalize the process.</p> <p>The <code>map</code> function takes an array and a function as arguments. It applies the function to each element of the array and returns a new array with the transformed values. This lets us reuse <code>map</code> with any function we choose, making our code more modular and expressive.</p>"},{"location":"resources/frontend/3-event-driven/#implementing-a-custom-map-function","title":"Implementing a Custom <code>map</code> Function","text":"<p>Here's an example of how we might implement <code>map</code> from scratch in TypeScript:</p> <pre><code>const map = (arr: number[], func: (num: number) =&gt; number): number[] =&gt; {\n    const result: number[] = [];\n    for (const num of arr) {\n        result.push(func(num));\n    }\n    return result;\n};\n\nconst square = (x: number) =&gt; x * x;\n\nconst numbers = [1, 2, 3, 4];\nconst squaredNumbers = map(numbers, square);\nconsole.log(squaredNumbers); // [1, 4, 9, 16]\n</code></pre>"},{"location":"resources/frontend/3-event-driven/#why-pass-functions-around","title":"Why Pass Functions Around?","text":"<p>The ability to pass functions as arguments gives us powerful ways to structure our code. Instead of defining heavyweight classes or duplicating logic, we can simply pass different behaviors into a function like <code>map</code> to get the desired result. This keeps our code cleaner and more flexible.</p> <p>For example, we can easily swap out the function to apply different transformations:</p> <pre><code>const double = (x: number) =&gt; x * 2;\nconsole.log(map(numbers, double)); // [2, 4, 6, 8]\n\nconst absolute = (x: number) =&gt; Math.abs(x);\nconsole.log(map([-1, -2, 3, -4], absolute)); // [1, 2, 3, 4]\n</code></pre> <p>By using higher-order functions, we reduce redundancy and make our programs more expressive, letting us focus on the what rather than the how. This approach is at the core of functional programming and leads to more readable and maintainable code.</p>"},{"location":"resources/frontend/3-event-driven/#introduction-to-event-driven-asynchrony","title":"Introduction to Event-Driven Asynchrony","text":"<p>Most modern web applications rely on event-driven programming to handle user interactions and network requests efficiently. Imagine clicking a button in a web app that triggers a network request to fetch data. If JavaScript were to process this request in a blocking manner, the entire page would become unresponsive until the request finished. This would be a terrible experience\u2014no scrolling, no typing, no animations\u2014just a frozen screen until the network responded. Instead, JavaScript uses an event loop and an asynchronous model to ensure that while waiting for a task to complete, the rest of the application can continue running smoothly.</p>"},{"location":"resources/frontend/3-event-driven/#why-asynchrony","title":"Why Asynchrony?","text":"<p>Web applications frequently make requests to APIs across the internet. These requests can take time to complete due to network latency, slow servers, or large amounts of data being transferred. If the UI were to block while waiting for each request, users would experience frustrating lags. Instead, JavaScript offloads such tasks to the event loop, which allows the browser to continue processing other user interactions while waiting for the network request to finish.</p> <p>Here\u2019s how the event loop works:</p> <pre><code>sequenceDiagram\n    participant User\n    participant JavaScript\n    participant WebAPI\n    participant CallbackQueue\n\n    User-&gt;&gt;JavaScript: Clicks a button\n    JavaScript-&gt;&gt;WebAPI: Sends API request (non-blocking)\n    JavaScript-&gt;&gt;User: UI remains interactive\n    WebAPI--&gt;&gt;CallbackQueue: Response arrives\n    CallbackQueue-&gt;&gt;JavaScript: Executes callback (updates UI)</code></pre> <p>The event loop continuously checks the callback queue for pending tasks and runs them only when the main execution stack is empty. This ensures smooth execution without blocking.</p>"},{"location":"resources/frontend/3-event-driven/#promises-and-fetch-api","title":"Promises and Fetch API","text":"<p>A Promise represents a value that might be available now, or in the future, or never. JavaScript provides a built-in <code>Promise</code> class, which is a powerful tool for handling asynchronous operations. Instead of writing nested callbacks (which can become unreadable), Promises provide methods that allow us to register behavior for when an operation completes or fails.</p> <p>A <code>Promise</code> has two key methods:</p> <ul> <li><code>.then(callback)</code> \u2013 Runs the callback function when the Promise resolves successfully.</li> <li><code>.catch(callback)</code> \u2013 Runs the callback function when the Promise is rejected due to an error.</li> </ul> <p>The <code>fetch</code> API in JavaScript returns a Promise when making HTTP requests. Here\u2019s an example:</p> <pre><code>const fetchData = (): Promise&lt;void&gt; =&gt; {\n    return fetch(\"https://jsonplaceholder.typicode.com/todos/1\")\n        .then(response =&gt; response.json()) // First promise\n        .then(data =&gt; console.log(data))   // Second promise\n        .catch(error =&gt; console.error(\"Error fetching data:\", error));\n};\n\nfetchData();\n</code></pre>"},{"location":"resources/frontend/3-event-driven/#understanding-chained-methods-and-fluent-apis","title":"Understanding Chained Methods and Fluent APIs","text":"<p>At first glance, this code might feel overwhelming, especially if you haven\u2019t encountered method chaining or fluent APIs before. Let\u2019s break it down step by step.</p> <ol> <li>Fetching Data: The <code>fetch</code> function initiates an HTTP request to retrieve data from the given URL. It immediately returns a <code>Promise</code> that will resolve when the response arrives.</li> <li>Processing the Response: Since <code>fetch</code> doesn\u2019t directly return the data but a <code>Response</code> object, we need to call <code>.json()</code> on it. This method also returns a Promise, which resolves when the response body has been parsed.</li> <li>Handling the Data: The next <code>.then()</code> receives the parsed JSON and logs it to the console.</li> <li>Error Handling: If anything goes wrong (e.g., network failure or an invalid response), the <code>.catch()</code> method ensures we handle errors gracefully.</li> </ol> <p>Each <code>.then()</code> method processes the result of the previous step, allowing us to chain operations in a clean and readable way. This avoids deeply nested callbacks (a problem known as \"callback hell\").</p>"},{"location":"resources/frontend/3-event-driven/#flow-explanation","title":"Flow Explanation:","text":"<ol> <li><code>fetch</code> returns a Promise resolving to a <code>Response</code> object.</li> <li>We call <code>.json()</code> on the <code>Response</code>, which returns another Promise.</li> <li>The second <code>.then()</code> handles the parsed JSON data.</li> <li>If anything goes wrong, <code>.catch()</code> captures errors.</li> </ol>"},{"location":"resources/frontend/3-event-driven/#understanding-the-promise-state-machine","title":"Understanding the Promise State Machine","text":"<p>A Promise in JavaScript follows a specific lifecycle, transitioning through different states:</p> <pre><code>graph TD;\n    A[Pending] --&gt;|Operation succeeds| B[Fulfilled]\n    A --&gt;|Operation fails| C[Rejected]</code></pre> <ul> <li>Pending: The initial state, where the Promise is waiting for the asynchronous operation to complete.</li> <li>Fulfilled: The operation completed successfully, and the <code>then()</code> handler is called.</li> <li>Rejected: The operation encountered an error, and the <code>catch()</code> handler is called.</li> </ul> <p>Each state transition happens exactly once. Once a Promise is either fulfilled or rejected, it cannot change state again.</p> <p>By understanding how Promises work and integrating them into event-driven programming, we gain fine control over asynchronous workflows. This ensures that applications remain responsive and efficient, leading to a better user experience.</p>"},{"location":"resources/frontend/3-event-driven/#asyncawait","title":"Async/Await","text":"<p>The <code>async/await</code> syntax is a modern way to write asynchronous code in JavaScript that builds directly on top of Promises. It makes asynchronous operations easier to read and reason about by allowing developers to write code that looks synchronous while retaining all the benefits of non-blocking execution.</p> <p>Under the hood, an <code>async</code> function always returns a Promise. The <code>await</code> keyword pauses execution inside the function until the awaited Promise resolves. This approach avoids deeply nested <code>.then()</code> chains and allows for more natural error handling with <code>try/catch</code> blocks.</p> <p>Using <code>async/await</code>, we can rewrite the previous Promise-based example in a more readable way:</p> <pre><code>const fetchDataAsync = async (): Promise&lt;void&gt; =&gt; {\n    try {\n        const response = await fetch(\"https://jsonplaceholder.typicode.com/todos/1\");\n        const data = await response.json();\n        console.log(data);\n    } catch (error) {\n        console.error(\"Error fetching data:\", error);\n    }\n};\n\nfetchDataAsync();\n</code></pre>"},{"location":"resources/frontend/3-event-driven/#why-use-asyncawait","title":"Why Use Async/Await?","text":"<ul> <li>Improves readability: Makes asynchronous code look and behave more like synchronous code, reducing cognitive load.</li> <li>Avoids callback hell: Eliminates the need for deeply nested <code>.then()</code> chains, improving maintainability.</li> <li>Intuitive error handling: Uses <code>try/catch</code> instead of <code>.catch()</code>, making it more consistent with synchronous code.</li> </ul>"},{"location":"resources/frontend/3-event-driven/#understanding-the-connection-to-promises","title":"Understanding the Connection to Promises","text":"<p>The <code>async/await</code> syntax does not introduce a new asynchronous mechanism; rather, it is a syntactic transformation of Promise-based code. The JavaScript engine internally rewrites <code>async</code> functions into standard Promise chains.</p> <p>For example, the above <code>async/await</code> function is equivalent to the following Promise-based implementation written before.</p> <p>This transformation has been formally studied in continuation-passing style (CPS) transformation research, proving that <code>async/await</code> retains the same computational expressiveness as Promises while improving code clarity. The ability to represent asynchronous workflows more naturally makes <code>async/await</code> the preferred approach in modern JavaScript development.</p>"},{"location":"resources/git/ch0-introduction/","title":"Ch. 0 What is Source Code Management and <code>git</code>?","text":"<p>Imagine you're working on a group project, writing code with your friends or classmates. Things start small and simple, but as the project grows, chaos sneaks in. Who has the latest version of the code? What if two people edit the same file? What if you need to undo something from last week?</p>"},{"location":"resources/git/ch0-introduction/#source-code-management-scm","title":"Source Code Management (SCM)","text":"<p>Software development is messy. Code evolves over time, bugs are fixed, new features are added, and experiments come and go. Without a system to track these changes, you can easily lose your way or overwrite someone else\u2019s work. Source Code Management tools offer a tried and true solution.</p>"},{"location":"resources/git/ch0-introduction/#a-brief-history-of-scm-tools","title":"A Brief History of SCM Tools","text":"<p>Managing project versions on a team has been a challenge since the early days of stored programs. SCM tools have been around for over 50 years that helped developers manage their projects:</p> <ul> <li>SCSS (Source Code Control System, 1973): One of the earliest systems, it introduced basic source code tracking but lacked collaborative features.</li> <li>RCS (Revision Control System, 1982): Inspired by SCSS, a set of UNIX commands for multiple users to work on single files and track changes with diffs.</li> <li>CVS (Concurrent Versions System, 1990): Introduced the concept of a central repository but struggled with merging changes from multiple developers.</li> <li>Subversion (SVN, 2000): Improved on CVS by offering atomic commits and better branching, but still relied on a central server.</li> <li>Distributed Systems (e.g., BitKeeper, 2000): Allowed for more flexible workflows, without a centralized server, but was closed-source, paid software. It was a primary basis of inspiration for <code>git</code>.</li> <li><code>git</code> (2005): Today's leading open source SCM was designed to handle large projects with speed, reliability, and a distributed architecture. Created by Linus Torvalds to become the Linux operating system's SCM, <code>git</code> has an interesting origin story, if you're into computing history. </li> </ul>"},{"location":"resources/git/ch0-introduction/#what-is-git","title":"What is <code>git</code>?","text":"<p><code>git</code> is a command-line tool for managing version control in projects. It allows developers to track changes in a codebase, collaborate with others, and maintain a history of project development. Unlike some tools that rely on a central server, <code>git</code> is distributed, so every user has a full copy of the project\u2019s history on their local machine.</p>"},{"location":"resources/git/ch0-introduction/#what-is-a-git-repository","title":"What is a <code>git</code> Repository?","text":"<p>A <code>git</code> repository (often shortened to \"repo\") is a project's organized history. It stores all the information about a project, including its versions, files, branches, and more. Repositories exist locally on you and your teammates' machines, but can also be synchronized with remote repositories on the internet, via services such as GitHub.</p>"},{"location":"resources/git/ch0-introduction/#what-is-github","title":"What is GitHub?","text":"<p>It\u2019s common to hear <code>git</code> and GitHub mentioned together, often confused with one another, but it is important to recognize they\u2019re not at all the same.</p> <p>GitHub is a cloud-based platform built on top of <code>git</code>. It provides a space to host <code>git</code> repositories online, making it easier to collaborate with others by sharing your code. GitHub adds extra features for software engineering teams you will learn all about in COMP423.</p> <p>While GitHub is one of the most popular platforms, it\u2019s not the only one. Alternatives like GitLab, Bitbucket, and others offer similar functionality.</p>"},{"location":"resources/git/ch0-introduction/#why-engineers-still-choose-git-20-years-later","title":"Why Engineers Still Choose <code>git</code> 20+ Years Later","text":"<p><code>git</code> is the most popular SCM today for many reasons:</p> <ol> <li>Distributed Workflow: Every team member gets their own complete copy of the project's history. This means you can work offline, experiment freely, and share your work when you're ready without blocking your team mates.</li> <li>Fast and Lightweight: <code>git</code> is designed to handle projects of any size efficiently, from small hobby projects to large-scale codebases. Its commands complete shockingly past compared to historical SCMs.</li> <li>Powerful Collaboration: <code>git</code> enables safe collaboration with the ability review a team mate's work and incorporate thier changes when it's ready, without risking loss of your own work.</li> <li>Safety Net: By keeping a history of snapshots of your project, <code>git</code> enables you to undo mistakes or recover something you deleted and later realized you needed.</li> <li>Open Source and Available: <code>git</code> is free, open-source, and widely supported across different platforms.</li> </ol>"},{"location":"resources/git/ch0-introduction/#installing-git-and-checking-its-version","title":"Installing <code>git</code> and Checking its Version","text":"<p>Let's be sure <code>git</code> is installed on your machine! You can check by opening a Terminal, preferably a <code>bash</code> terminal on Windows over PowerShell, and running the command <code>git --version</code>. If a reasonably modern version prints out, you're good to go! If not, continue below.</p>"},{"location":"resources/git/ch0-introduction/#windows","title":"Windows","text":"<ol> <li>Download the <code>git</code> installer from git-scm.com.</li> <li>Run the installer.</li> <li>During setup, use the default options unless you know what you're doing. Key things to confirm:</li> <li>Adjusting your PATH environment: Choose \"Use <code>git</code> from the command line and also from 3rd-party software.\"</li> <li>Default editor: Select Visual Studio Code.</li> <li>After installation, open the Command Prompt and run:    <pre><code>git --version\n</code></pre>    This command checks your <code>git</code> installation by displaying the installed version number. If you see the version number, you're good to go!</li> </ol> <p>Sample output:    <pre><code>git version 2.39.5\n</code></pre>    This confirms that <code>git</code> is properly installed and ready to use. It's okay if your version is different! <code>git</code> takes pride in being highly backwards compatible, so most commands will work the same way regardless of your version.</p>"},{"location":"resources/git/ch0-introduction/#macos","title":"macOS","text":"<ol> <li>Open your terminal.</li> <li>Run the following command:    <pre><code>git --version\n</code></pre>    If <code>git</code> isn\u2019t installed, your Mac will prompt you to install the Command Line Developer Tools. Confirm the installation and follow the prompts.</li> <li>Once installed, verify it works by running:    <pre><code>git --version\n</code></pre>    Sample output:    <pre><code>git version 2.39.5\n</code></pre>    This indicates that <code>git</code> is successfully installed on your macOS system. It's okay if your version is different! <code>git</code> takes pride in being highly backwards compatible, so most commands will work the same way regardless of your version.</li> </ol>"},{"location":"resources/git/ch0-introduction/#what-to-expect-next","title":"What to Expect Next","text":"<p>Now that you know why <code>git</code> is such a valuable tool, it\u2019s time to learn how to use it. In the next chapter we\u2019ll start using its basic commands.</p>"},{"location":"resources/git/ch1-git-structure/","title":"Ch. 1 Core Concepts of a <code>git</code> Repository","text":"<p><code>git</code> becomes much easier to learn and operate with a high-level understanding of its organization and data structure design.</p>"},{"location":"resources/git/ch1-git-structure/#snapshots-not-diffs","title":"Snapshots, Not Diffs","text":"<p><code>git</code> doesn\u2019t store the history of differences (diffs) between versions. Instead, it captures a history of snapshots of your project. Each snapshot is like a photograph of your entire project's contents at the moment you decide to commit to the snapshot.</p> <p>The technical design decisions behind <code>git</code>'s data structures are brilliant. We'll learn more about them in time. For now, let's just appreciate the features its design enables:</p> <ul> <li>Local History: Your entire project history is stored locally on your machine. This means you can explore or revert changes without needing an internet connection or accessing a central server.</li> <li>Quick Navigation: Since snapshots contain the full project state, Git can near instantly move to any commit without recalculating the state from diffs.</li> <li>Efficient Storage: Git only stores files that change between snapshots. Identical files are saved just once and linked back to in later snapshots, which saves space while maintaining integrity.</li> <li>Efficient Comparisons: Git uses hashing to compare files and directories. This allows it to quickly identify changes without scanning the entire file contents.</li> </ul>"},{"location":"resources/git/ch1-git-structure/#what-is-a-commit","title":"What is a Commit?","text":"<p>Building on the concept of snapshots and data integrity, a commit is a saved snapshot of your project at a specific point in time. It contains:</p> <ol> <li>File Contents: The exact state of the files that were committed.</li> <li>Metadata:<ul> <li>Who made the commit (name and email).</li> <li>When the commit was made (timestamp).</li> <li>A message describing the changes.</li> </ul> </li> <li>Parent Pointer(s): Each commit records a reference to one or more parent commits. Most commits have a single parent, but merge commits can have multiple parents.</li> <li>Commit ID Hash: Every commit is assigned a unique cryptographic hash, which acts as its identity. This hash is generated based on the commit\u2019s contents, metadata, and parent pointers. It ensures the integrity of the commit, making it impossible to alter the commit without detection. If even a single byte changes, the hash changes too, signaling that the commit has been tampered with. This immutability is central to Git's reliability.</li> </ol> <p>Here\u2019s an example of what a commit\u2019s metadata might look like:</p> <pre><code>commit 5d41402abc4b2a76b9719d911017c592\nParent: e38ad214bd57c8c7f69a1d8f6326b3d1f3e6a2ef\nAuthor: Your Name &lt;your.email@example.com&gt;\nDate:   Tue Jan 1 12:00:00 2025 +0000\n\n    Add README file\n</code></pre> <p>The hash (<code>5d41402abc4b2a76b9719d911017c592</code>) uniquely identifies the commit and protects its contents from tampering.</p>"},{"location":"resources/git/ch1-git-structure/#commit-history","title":"Commit History","text":"<p>A repository is essentially a timeline of snapshots, with each commit representing a specific state of the project. These snapshots are linked together because each commit holds a reference to its \"parent\" commit's hash ID, forming a chain. </p> <p>In a linear history, this structure is equivalent to a singly linked list. However, as you start working with other team members or experimenting with your own ideas in branches, histories begin to diverge. A diverging history occurs when more than one commit shares the same parent. Merge commits, on the other hand, have multiple parents when branches are combined.</p> <p>These relationships create a directed acyclic graph (DAG)\u2014a concept you\u2019ve seen in COMP210: Data Structures. Here, the DAG ensures that commits are immutable and history is consistent and reliable. Since commits can only reference existing ones and cannot be altered, your entire history remains tamper-proof.</p>"},{"location":"resources/git/ch1-git-structure/#navigating-and-understanding-history","title":"Navigating and Understanding History","text":"<ul> <li>The Commit Log: Think of the commit log as a journal of everything that has happened in your project. Commands like <code>git log</code> let you view this history, showing each commit\u2019s hash, author, date, and message.</li> <li>Revisiting Changes: Each commit is like a bookmark in your project. You can move back and forth in history, inspecting past states or even restoring them.</li> <li>Collaboration Made Easy: Since every commit includes a message and is linked to its parent, your teammates can see not just what changed but why. This transparency makes it easier to review and integrate work.</li> </ul>"},{"location":"resources/git/ch1-git-structure/#the-working-areas-of-a-git-repository","title":"The Working Areas of a <code>git</code> Repository","text":"<p>In addition to the committed history, a <code>git</code> repository organizes files and changes into two additional areas where you will spend most of your time:</p> <ol> <li>Working Directory: This is where you directly interact with your project's files. It reflects your local version of the project, where you edit, create, and delete files.</li> <li>Staging Area: Also called the index, this is a middle ground where you prepare changes from your working directory before committing them to the repository\u2019s history. Think of it as framing your next snapshot, letting you carefully curate and organize the changes you want to commit to your project\u2019s history. </li> </ol>"},{"location":"resources/git/ch1-git-structure/#flow-between-conceptual-areas","title":"Flow Between Conceptual Areas","text":"<p>Here\u2019s a high-level view of how files move through these areas during a typical workflow:</p> <pre><code>sequenceDiagram\n    participant WD as Working Directory\n    participant SA as Staging Area\n    participant CH as Committed History\n\n    WD-&gt;&gt;SA: git add (stage changes)\n    SA-&gt;&gt;CH: git commit (save snapshot)</code></pre> <p>This flow illustrates how the work you do in your version makes its way into your project's local history. You start by editing files in the Working Directory, select specific changes to stage in the Staging Area, and then finalize those changes into the Committed History with a commit.</p> <p>In the next chapter, you will learn all the fundamental <code>git</code> operations necessary to start a new <code>git</code> repository, perform some work, and form a commit history.</p>"},{"location":"resources/git/ch2-git-fundamental-subcommands/","title":"Ch. 2 Fundamental <code>git</code> Subcommands","text":"<p>This is a hands-on tutorial! Follow along by running all the commands as we go. By the end, you\u2019ll have a solid foundation of the most fundamental <code>git</code> operations.</p> <p>By the end of this chapter, you\u2019ll know what a subcommand is and have worked with several essential <code>git</code> subcommands:</p> <ul> <li><code>git config</code>: Setting up your identity for commits and other configurations.</li> <li><code>git init</code>: Initialize a folder as a new, empty <code>git</code> repository.</li> <li><code>git add</code>: Staging files for your next commit.</li> <li><code>git commit</code>: Creating a commit to record a snapshot of your project.</li> <li><code>git status</code>: Checking the current state of your repository.</li> <li><code>git log</code>: Viewing your project\u2019s history.</li> <li><code>git restore</code>: Reverting changes when something goes awry.</li> <li><code>git checkout</code>: Pulling files, and more, from a project's history of commits.</li> </ul> <p>These subcommands will form the foundation of your <code>git</code> expertise, enabling you to start every project on the right foot and build confidence as you explore deeper features. Let\u2019s jump right in!</p>"},{"location":"resources/git/ch2-git-fundamental-subcommands/#understanding-git-subcommands","title":"Understanding <code>git</code> Subcommands","text":"<p><code>git</code> is a command-line program that relies on a subcommand convention to perform specific actions to manage your repository. A subcommand is the first string argument following <code>git</code>. Each subcommand has its own purpose, many you will begin to learn in this chapter: initializing a repository (<code>git init</code>), checking the state of your repo (<code>git status</code>), or committing changes (<code>git commit</code>).</p> <p>As you get familiar with <code>git</code>, you\u2019ll find yourself using sequences of subcommands to accomplish tasks. The beauty of <code>git</code> lies in its flexibility, but that can also make it overwhelming at first. Don\u2019t worry\u2014<code>git</code> includes a built-in help system for you.</p>"},{"location":"resources/git/ch2-git-fundamental-subcommands/#getting-help-with-subcommands","title":"Getting Help with Subcommands","text":"<p>If you\u2019re ever unsure about how to use a subcommand or what options it supports, you can ask <code>git</code> for help directly from the command line. For example:</p> <pre><code>git help commit\n</code></pre> <p>This will open a manual page describing what the <code>commit</code> subcommand does, its syntax, and the available options. For example, you\u2019ll see some descriptive, helpful text like this:</p> <pre><code>NAME\n       git-commit - Record changes to the repository\n\nSYNOPSIS\n       git commit [-m &lt;msg&gt;]\n\nDESCRIPTION\n       Create a new commit containing the current contents of the index and\n       the given log message describing the changes.\n</code></pre> <p>You can also use shorthand to view help inline by adding <code>--help</code> after the subcommand, like so:</p> <pre><code>git commit --help\n</code></pre> <p>This approach works for any subcommand. It\u2019s a great way to learn as you go and explore new tools in the <code>git</code> toolbox.</p>"},{"location":"resources/git/ch2-git-fundamental-subcommands/#consulting-with-an-llm","title":"Consulting with an LLM","text":"<p>If you find yourself struggling to remember the exact subcommand or short flag to achieve your goal with <code>git</code>, or how to do something complex, a great use of an LLM like ChatGPT is asking it how to achieve your specific task. Describe what you want to do, ask for the <code>git</code> command(s) you need, and ask it to explain each step to you. Ultimately, you need to know what <code>git</code> can do and how to think in terms of its underlying data structures and conceptual model. That's why we are putting a significant emphasis on mastering <code>git</code> in COMP423!</p>"},{"location":"resources/git/ch2-git-fundamental-subcommands/#configure-your-name-and-email","title":"Configure your name and email","text":"<p>Before you start using <code>git</code>, set your name and email. This information will be attached to your commits.</p> <p>Run these commands in your terminal, replacing the placeholders with your details:</p> <pre><code>git config --global user.name \"Your Name\"\ngit config --global user.email \"your.email@example.com\"\n</code></pre> <p>These commands tell <code>git</code> who you are. The <code>--global</code> flag ensures this configuration applies to all your projects.</p> <p>You can check your configuration anytime with:</p> <pre><code>git config --list\n</code></pre> <p>Sample output:</p> <pre><code>user.name=Your Name\nuser.email=your.email@example.com\n</code></pre> <p>This confirms your details are correctly configured. You can also see additional configuration settings. We will not worry ourselves with the depths of <code>git</code> configurability in this course.</p>"},{"location":"resources/git/ch2-git-fundamental-subcommands/#initializing-your-first-repository","title":"Initializing Your First Repository","text":""},{"location":"resources/git/ch2-git-fundamental-subcommands/#step-1-create-a-directory","title":"Step 1: Create a Directory","text":"<p>Let\u2019s create a new directory for your project:</p> <pre><code>mkdir git-for-423\ncd git-for-423\n</code></pre> <p>Here\u2019s what these commands do:</p> <ul> <li><code>mkdir git-for-423</code>: Creates a new directory called <code>git-for-423</code>.</li> <li><code>cd git-for-423</code>: Changes into that directory so you can work inside it.</li> </ul>"},{"location":"resources/git/ch2-git-fundamental-subcommands/#step-2-initialize-git","title":"Step 2: Initialize <code>git</code>","text":"<p>Turn this directory into a <code>git</code> repository by running:</p> <pre><code>git init\n</code></pre> <p>This creates a hidden <code>.git</code> directory, which is where all the magic happens. The <code>.git</code> directory contains:</p> <ul> <li>Your entire project history, including every commit.</li> <li>Metadata about your repository.</li> <li>Configuration files and references to other states in your project.</li> </ul> <p>It\u2019s incredible that even for massive projects with thousands of files and decades of history, this one hidden directory contains everything <code>git</code> needs to manage the project.</p> <p>You can peek at it:</p> <pre><code>ls -a\n</code></pre> <p>Sample output:</p> <pre><code>.  ..  .git\n</code></pre> <p>This shows the <code>.git</code> directory alongside the regular and parent directory entries. The <code>.git</code> directory is what transforms a regular directory into a powerful <code>git</code> repository. If you peek further inside, with <code>ls .git</code>, you will see that there are more files and directories in it. The details of this structure are below the layer of abstraction we are focused on in learning <code>git</code>. However, note that your whole repo's history will be right there and there's no magic to it, just data structures and algorithms!</p>"},{"location":"resources/git/ch2-git-fundamental-subcommands/#making-your-first-commit","title":"Making Your First Commit","text":""},{"location":"resources/git/ch2-git-fundamental-subcommands/#step-1-create-a-file","title":"Step 1: Create a File","text":"<p>Let\u2019s start by adding a README file:</p> <pre><code>echo '# Welcome to COMP423!\\n' &gt; README.md\n</code></pre> <p>This command creates a file named <code>README.md</code> with the text `# Welcome to COMP423!` as its content. The <code>&gt;</code> operator redirects the text into the file. You learned about output redirection in COMP211: Systems Fundamentals.</p>"},{"location":"resources/git/ch2-git-fundamental-subcommands/#step-2-check-the-repository-status","title":"Step 2: Check the Repository Status","text":"<p>Use <code>git status</code> to see what\u2019s happening in your repo:</p> <pre><code>git status\n</code></pre> <p>Sample output:</p> <pre><code>On branch main\n\nNo commits yet\n\nUntracked files:\n  (use \"git add &lt;file&gt;...\" to include in what will be committed)\n    README.md\n\nnothing added to commit but untracked files present (use \"git add\" to track)\n</code></pre> <p>This tells you that <code>README.md</code> is untracked, meaning it isn\u2019t part of version control yet.</p>"},{"location":"resources/git/ch2-git-fundamental-subcommands/#step-3-stage-the-file","title":"Step 3: Stage the File","text":"<p>To tell <code>git</code> you want to include <code>README.md</code> in your next snapshot, stage it:</p> <pre><code>git add README.md\n</code></pre> <p>Sample output:</p> <pre><code>Changes to be committed:\n  (use \"git restore --staged &lt;file&gt;...\" to unstage)\n    new file:   README.md\n</code></pre> <p>This confirms that <code>README.md</code> is staged and ready to commit.</p>"},{"location":"resources/git/ch2-git-fundamental-subcommands/#step-4-commit-your-changes","title":"Step 4: Commit Your Changes","text":"<p>Create your first commit:</p> <pre><code>git commit -m \"Add README file\"\n</code></pre> <p>The <code>-m</code> flag specifies a commit message directly in the command.</p> <p>Sample output:</p> <pre><code>[main (root-commit) abc1234] Add README file\n 1 file changed, 1 insertion(+)\n create mode 100644 README.md\n</code></pre> <p>This shows:</p> <ul> <li>The branch name (<code>main</code>) and that it's the <code>root-commit</code> where root is the first \"node\" in a repository.</li> <li>The unique commit hash (<code>abc1234</code>). Your hash will be different!</li> <li>A summary of changes: 1 file added with 1 line of content.</li> </ul> <p>Congratulations! You\u2019ve just recorded your first piece of project history.</p>"},{"location":"resources/git/ch2-git-fundamental-subcommands/#adding-another-commit","title":"Adding Another Commit","text":"<p>Modify <code>README.md</code>:</p> <pre><code>echo \"This repository is for learning git.\" &gt;&gt; README.md\n</code></pre> <p>This appends the text to <code>README.md</code>. The <code>&gt;&gt;</code> operator adds text to the file without overwriting it. You may recall learning about this in COMP211: Systems Fundamentals.</p> <p>Check the status:</p> <pre><code>git status\n</code></pre> <p>Sample output:</p> <pre><code>On branch main\n\nChanges not staged for commit:\n  (use \"git add &lt;file&gt;...\" to update what will be committed)\n  (use \"git restore &lt;file&gt;...\" to discard changes in working directory)\n    modified:   README.md\n</code></pre> <p>This shows that <code>README.md</code> has been modified but not yet staged.</p> <p>Stage the changes:</p> <pre><code>git add README.md\n</code></pre> <p>Commit them:</p> <pre><code>git commit -m \"Update README with project purpose\"\n</code></pre> <p>Sample output:</p> <pre><code>[main abc5678] Update README with project purpose\n 1 file changed, 1 insertion(+)\n</code></pre> <p>Now your repository has two commits. Use <code>git log</code> to view them:</p> <pre><code>git log\n</code></pre> <p>Sample output:</p> <pre><code>commit abc5678\nAuthor: Your Name &lt;your.email@example.com&gt;\nDate:   Tue Jan 1 12:05:00 2025 +0000\n\n    Update README with project purpose\n\ncommit abc1234\nAuthor: Your Name &lt;your.email@example.com&gt;\nDate:   Tue Jan 1 12:00:00 2025 +0000\n\n    Add README file\n</code></pre> <p>Each commit references its parent(s), forming the DAG of your project history.</p>"},{"location":"resources/git/ch2-git-fundamental-subcommands/#how-git-tracks-file-and-repo-state","title":"How <code>git</code> Tracks File and Repo State","text":"<p>Here\u2019s a diagram of how <code>git</code> tracks files:</p> <pre><code>sequenceDiagram\n    participant WorkingDir as Working Directory&lt;br&gt;(Unchanged)\n    participant Changed as Working Directory&lt;br&gt;(Changed)\n    participant Staged as Staged&lt;br&gt;(Index)\n    participant Committed as Commit&lt;br&gt;(Committed History)\n\n    WorkingDir -&gt;&gt; Changed: Modify File\n    Changed -&gt;&gt; Staged: git add\n    Staged -&gt;&gt; Committed: git commit\n    Changed -&gt;&gt; WorkingDir: git restore &lt;file&gt;\n    Staged -&gt;&gt; Changed: git restore --staged &lt;file&gt;\n    Committed -&gt;&gt; WorkingDir: git checkout &lt;commit&gt; &lt;file&gt;</code></pre> <p>Use <code>git status</code> often to see where your files are in this flow.</p>"},{"location":"resources/git/ch2-git-fundamental-subcommands/#experimenting-with-commits-and-changes","title":"Experimenting with Commits and Changes","text":"<p>Now that you\u2019ve made a few commits, let\u2019s dive deeper into how <code>git</code> helps you manage and explore your project\u2019s history. Follow these steps to get hands-on experience:</p>"},{"location":"resources/git/ch2-git-fundamental-subcommands/#1-view-your-projects-history","title":"1. View Your Project\u2019s History","text":"<p>Use the <code>git log</code> command to see all your commits:</p> <pre><code>git log\n</code></pre> <p>For a compact summary, try the <code>--oneline</code> option:</p> <pre><code>git log --oneline\n</code></pre> <p>This shows each commit\u2019s hash and its message in a single line, making it easier to navigate.</p> <p>Shortened Hashes in <code>git</code></p> <p>In <code>git</code>, you can refer to commits by shortened versions of their hashes. For example, instead of using the full SHA-1 hash like <code>abc5678abc5678abc5678abc5678abc5678abc5</code>, you can simply use the first few characters, like <code>abc5678</code>. This works as long as the prefix uniquely identifies a commit in the repository.</p> <p>Remember from COMP210 how hash tables rely on unique keys and the odds of collision depend on the hash function and key space? <code>git</code>'s SHA-1 hashes are 160 bits long, providing \\(2^{160}\\) possible values\u2014an astronomically large number. Even with millions of commits, the probability of two full hashes colliding is practically zero.</p> <p>However, when using shortened hashes, you only need enough characters to uniquely identify a commit. For instance, using 5 hexadecimal characters gives \\(16^5 = 1,048,576\\) possible values. In a project like ours with only two commits so far, the chance of ambiguity is nonexistent. As your project grows, <code>git</code> will warn you if a prefix becomes ambiguous and requires more characters to ensure uniqueness.</p> <p>Challenge</p> <p>Look for the hash of your first commit. You\u2019ll use it in the next step!</p>"},{"location":"resources/git/ch2-git-fundamental-subcommands/#2-revisit-a-previous-commit","title":"2. Revisit a Previous Commit","text":"<p>Imagine you want to see what your project looked like at the time of your first commit.</p> <ol> <li> <p>Use the <code>git checkout</code> command to switch to that specific commit:    <pre><code>git checkout &lt;commit-hash&gt;\n</code></pre>    Replace <code>&lt;commit-hash&gt;</code> with the hash of your first commit (e.g., <code>abc1234</code>).</p> </li> <li> <p>Inspect the file\u2019s contents:    <pre><code>cat README.md\n</code></pre></p> </li> </ol> <p>Notice how the content matches the snapshot from your first commit.</p> <ol> <li>Return to the latest version of your project:    <pre><code>git checkout main\n</code></pre></li> </ol> <p>Tip</p> <p>Always return to a branch (like <code>main</code>) when you\u2019re done exploring past commits to avoid confusion.</p>"},{"location":"resources/git/ch2-git-fundamental-subcommands/#3-undo-a-file-change","title":"3. Undo a File Change","text":"<p>Let\u2019s say you accidentally modify a file and want to undo the changes. For example:</p> <ol> <li> <p>Modify the <code>README.md</code> file:    <pre><code>echo \"Oops, made a mistake!\" &gt;&gt; README.md\n</code></pre></p> </li> <li> <p>Use <code>git restore</code> to revert the file to its previous state:    <pre><code>git restore README.md\n</code></pre></p> </li> <li> <p>Verify the file is back to its original form:    <pre><code>cat README.md\n</code></pre></p> </li> </ol>"},{"location":"resources/git/ch2-git-fundamental-subcommands/#4-unstage-changes","title":"4. Unstage Changes","text":"<p>Suppose you\u2019ve staged a file but then change your mind. Here\u2019s how to unstage it:</p> <ol> <li> <p>Modify and stage the file:    <pre><code>echo \"Temporary change\" &gt;&gt; README.md\ngit add README.md\n</code></pre></p> </li> <li> <p>Unstage the file:    <pre><code>git restore --staged README.md\n</code></pre></p> </li> </ol> <p>Run <code>git status</code> to confirm the file is no longer staged but still modified.</p>"},{"location":"resources/git/ch2-git-fundamental-subcommands/#5-challenge-explore-and-restore","title":"5. Challenge: Explore and Restore","text":"<p>Use what you\u2019ve learned to experiment:</p> <ul> <li>Inspect specific file versions from past commits using <code>git checkout</code>.</li> <li>Revert untracked or staged changes using <code>git restore</code>.</li> <li>Play around with <code>git log</code> to navigate your project history.</li> </ul> <p>By combining these commands, you can confidently manage and explore your repository\u2019s state at any point in its timeline.</p>"},{"location":"resources/git/ch3-git-branch-merge/","title":"Ch. 3 Branching and Merging","text":"<p>Imagine this: you're working on a project like a collaborative web app, and you want to test out a bold new feature\u2014maybe integrating a third-party login system\u2014without disrupting the stable version already in use by other team members. In software teams, branching allows experimentation like this without risk. Or maybe you're part of a team, and multiple people are working on different features at the same time. How do you keep everything organized and avoid stepping on each other's toes? That\u2019s where branching and merging come in\u2014two of Git\u2019s most powerful features.</p>"},{"location":"resources/git/ch3-git-branch-merge/#what-is-a-branch","title":"What is a Branch?","text":"<p>In Git, a branch has very simple, beautiful implementation: a branch is just a named pointer to a commit with the special behavior that when you create a new commit while working on a branch, the branch pointer automatically updates to reference the new commit. No other branch pointers are updated. This implementation idea gives rise to a powerful conceptual abstraction: branches conceptually represent multiple parallel version histories in a repository. </p> <p>When you first create a new branch, no change in your project's history occurs; instead, a new pointer to the last commit on your current branch is created. This means the two branches start off identical, both pointing to the same commit, sharing the same history. As two individual branches have additional commits added to them independently their histories will\u00a0diverge, reflecting the different paths of development taken. When you decide it is time to incorporate work on one branch back into another branch, one branch's changes can be merged\u00a0into another branch.</p>"},{"location":"resources/git/ch3-git-branch-merge/#why-use-branches","title":"Why Use Branches?","text":"<p>Branches are incredibly useful for:</p> <ul> <li>Experimentation: Try out new ideas without impacting the stable version of your project.</li> <li>Parallel Development: Multiple team members can work on different features or fixes at the same time.</li> <li>Code Review: Branches allow you to submit changes for review before merging them into the main codebase.</li> </ul> <p>By isolating work on separate branches, you reduce the risk of overwriting someone else\u2019s changes or introducing bugs into your <code>main</code> branch.</p>"},{"location":"resources/git/ch3-git-branch-merge/#branch-early-and-often","title":"Branch Early and Often","text":"<p>One of the best things about Git branches is how lightweight and fast they are. Think about why their implementation makes them lightweight and fast. This speed allows developers to create and switch between branches almost instantaneously, which is especially beneficial in modern workflows. For example, developers can branch off to work on features or fixes, test their changes in isolation, and merge them back quickly without delaying others\u2019 progress. There\u2019s virtually no cost to having as many branches as you need. This makes branches an essential tool for developers.</p> <p>Key idiom: Branch early and often! Instead of making all your changes directly on <code>main</code> or a long-lived branch, create a branch for each new feature, bug fix, or experiment. This approach keeps your work isolated, makes it easier to collaborate, and allows for smoother integration later. Don\u2019t hesitate\u2014branches are free, use them liberally!</p>"},{"location":"resources/git/ch3-git-branch-merge/#what-is-head-gits-current-working-branch","title":"What is <code>HEAD</code>? Git's Current Working Branch","text":"<p><code>HEAD</code> is a special pointer in Git that tells you where you are currently working in your project\u2019s history. When <code>HEAD</code> is \"attached\" to a branch, you can think of <code>HEAD</code> as your current working branch. This is analogous to how your shell maintains your current working directory (CWD) such that shell commands you run are relative to your CWD. Git commands are relative to <code>HEAD</code>. </p> <p>Understanding <code>HEAD</code> helps you anticipate how Git commands behave:</p> <ul> <li><code>git commit</code>: Creates a new commit whose parent is the commit <code>HEAD</code> currently refers to. The branch <code>HEAD</code> is attached to is updated to refer to the freshly minted commit. This is how branches stay current with their latest commit.</li> <li><code>git log</code>: By default, displays commit history starting from <code>HEAD</code>.</li> <li><code>git restore</code>: Reverts files to the state they were in at the commit <code>HEAD</code> resolves to, allowing you to discard unwanted changes.</li> <li><code>git switch</code>: Causes <code>HEAD</code> to attach to a different branch and updates your working directory's contents to match the snapshot of that branch\u2019s latest commit. If you have modified files that haven\u2019t been staged, <code>git switch</code> will fail with a message letting you know you have uncommitted changes that are at risk of being overwritten.</li> </ul> <p>Sometimes <code>HEAD</code> is not attached to a branch.</p> <p>You will learn more about a detached <code>HEAD</code> state soon. It sounds spookier than it is. It just means <code>HEAD</code> points to a specific commit rather than to a branch. As soon as you create a new branch, which you will learn how to do next, you will no longer be in a detached <code>HEAD</code> state. This is useful when you want to go back to check out a commit that no branch currently points to, but nothing to concern ourselves with now.</p>"},{"location":"resources/git/ch3-git-branch-merge/#working-with-branches","title":"Working with Branches","text":"<p>To work with branches in Git, the recommended modern commands are <code>git branch</code> and <code>git switch</code>. While <code>git checkout</code> is still available and widely used, it has a broader scope, which can make it less intuitive for branch-specific tasks. Let\u2019s dive into best practices:</p>"},{"location":"resources/git/ch3-git-branch-merge/#creating-a-branch","title":"Creating a Branch","text":"<p>To create a new branch, use the following command:</p> <pre><code>git branch cool-feature\n</code></pre> <p>This creates the branch but doesn\u2019t switch you to it. This command only creates a new pointer to the current commit that the <code>HEAD</code> branch is on. No history has changed, and no parallel history exists yet. At this point, the two branches are exactly equivalent to each other and both point to the exact same commit.</p> <p>To start working on the new branch immediately, use:</p> <pre><code>git switch cool-feature\n</code></pre> <p>Once you understand these two steps independently, you can combine them with one command:</p> <pre><code>git switch --create cool-feature\n</code></pre> <p>The <code>--create</code> flag, whose short variant is <code>-c</code>, combines creating a branch and switching to it in one command. Now, <code>HEAD</code> is pointing to <code>cool-feature</code>, and you\u2019re ready to make changes.</p>"},{"location":"resources/git/ch3-git-branch-merge/#viewing-branches","title":"Viewing Branches","text":"<p>To see all the branches in your project and which one <code>HEAD</code> is pointing to:</p> <pre><code>git branch\n</code></pre> <p>For example, if you have two branches (<code>main</code> and <code>cool-feature</code>), and you are currently on the <code>cool-feature</code> branch, the output will look like this:</p> <pre><code>* cool-feature\n  main\n</code></pre> <p>The asterisk (<code>*</code>) indicates the branch that <code>HEAD</code> is currently pointing to. Again, think of <code>HEAD</code> as your current working branch.</p>"},{"location":"resources/git/ch3-git-branch-merge/#adding-a-new-commit-to-a-branch","title":"Adding a New Commit to a Branch","text":"<p>Once you\u2019re on the <code>cool-feature</code> branch and ready to make changes, you can add a new commit as follows:</p> <p>(1) Modify a file in your project, for example, editing <code>README.md</code> to include some additional content.</p> <pre><code># Welcome to COMP423!\nThis repository is for learning git.\nBranching and merging is powerful!\n</code></pre> <p>(2) Stage the changes using <code>git add</code>, review your staged work with <code>git status</code>:</p> <pre><code>git add README.md\ngit status\n</code></pre> <p>(3) Commit the changes with a descriptive message:</p> <pre><code>git commit -m \"Add a note about branching and merging\"\n</code></pre> <p>After committing, Git will output something like:</p> <pre><code>[cool-feature abc1234] Add a note about branching and merging\n 1 file changed, 7 insertions(+)\n</code></pre> <p>(4) Inspect the commit history using <code>git log</code> to see how the branch\u2019s <code>HEAD</code> has moved forward:</p> <pre><code>git log --oneline\n</code></pre> <p>Example output:</p> <pre><code>abc1234 (HEAD -&gt; cool-feature) Add a note about branching and merging\n</code></pre> <p>Here, you can see that <code>HEAD</code> has advanced to the new commit <code>abc1234</code> (your commit ID will be different) on the <code>cool-feature</code> branch.</p>"},{"location":"resources/git/ch3-git-branch-merge/#how-head-and-branch-updates-work","title":"How <code>HEAD</code> and Branch Updates Work","text":"<p>When you create a commit, Git uses <code>HEAD</code> to determine the parent of the new commit. The new commit will have the commit that <code>HEAD</code> was previously pointing to as its parent. After the commit is created, Git updates the branch that <code>HEAD</code> is attached to so that it points to the new commit. This is why the branch you\u2019re working on moves forward with each commit you make. Yes, this is the second or third time this tutorial has repeated this and for good reason: once your mental model fully internalizes this concept you will find working with branches much, much easier to understand!</p>"},{"location":"resources/git/ch3-git-branch-merge/#switching-between-branches","title":"Switching Between Branches","text":"<p>To move between branches, whose histories are now different, use <code>switch</code> again:</p> <pre><code>git switch main\n</code></pre> <p>In practical terms, switching branches allows you to work on completely different features or bug fixes without overwriting or disrupting your current progress. For example, your <code>cool-feature</code> branch included some new text in <code>README.md</code>, switching back to <code>main</code> will revert the working directory, and therefore <code>README.md</code>, to reflect the last commit made in the <code>main</code> branch. You can then easily switch back to <code>cool-feature</code> and be back on its timeline. This separation ensures that changes in progress do not accidentally affect production or stable environments.</p>"},{"location":"resources/git/ch3-git-branch-merge/#handling-in-progress-changes-when-switching-branches","title":"Handling In-Progress Changes When Switching Branches","text":"<p>Sometimes, you\u2019ll need to switch branches while you have in-progress changes in your working directory or staging. For example, you might need to review a colleague\u2019s work or fix a bug on another branch. </p> <p>In such cases, you have three main strategies to proceed with:</p>"},{"location":"resources/git/ch3-git-branch-merge/#1-commit-your-changes-to-your-branch","title":"1. Commit Your Changes to Your Branch","text":"<p>If your current changes are in a good state, you can commit them to the current branch before switching:</p> <pre><code>git add .\ngit commit -m \"WIP: Save progress on feature\"\n</code></pre> <p>This ensures your work is saved and associated with the current branch. Once committed, you can switch branches without any issues:</p> <pre><code>git switch branch-name\n</code></pre> <p>WIP is Work in Progress</p> <p>WIP is a common acronym in the softare engineering world. It is an abbreviation for Work in Progress. We are all WIPs.</p>"},{"location":"resources/git/ch3-git-branch-merge/#2-stash-your-changes-away-temporarily","title":"2. Stash your Changes away Temporarily","text":"<p>If your changes are not ready to be committed, you can temporarily set them aside using the stash:</p> <pre><code>git stash\n</code></pre> <p>This stores your changes in a separate stash area and reverts your working directory to match the last commit. You can then switch branches:</p> <pre><code>git switch branch-name\n</code></pre> <p>When you return to your original branch, you can restore the stashed changes by \"popping\" them from your stash stack:</p> <pre><code>git stash pop\n</code></pre>"},{"location":"resources/git/ch3-git-branch-merge/#3-discard-your-changes","title":"3. Discard Your Changes","text":"<p>If the changes you\u2019ve made aren\u2019t needed, you can discard them using previously learned commands:</p> <pre><code>git restore --staged .\ngit restore .\n</code></pre> <p>These commands resets your working directory and clear your staging index to match the last commit on the branch, effectively throwing away any modifications. Once reset, you\u2019re free to switch branches:</p> <pre><code>git switch branch-name\n</code></pre>"},{"location":"resources/git/ch3-git-branch-merge/#merging-branches","title":"Merging Branches","text":"<p>Once your work on a branch is complete, you\u2019ll want to combine it with another branch (usually <code>main</code>). Merging into <code>main</code> is a best practice because it keeps the central branch stable and reflects the latest working version of your project. This aligns with workflows like trunk-based development, where small, frequent merges into a shared branch help reduce integration problems and ensure that everyone is working from a reliable codebase. This process is called merging.</p>"},{"location":"resources/git/ch3-git-branch-merge/#fast-forward-merge-vs-merge-commit","title":"Fast-Forward Merge vs. Merge Commit","text":"<p>When merging, Git uses two main strategies:</p>"},{"location":"resources/git/ch3-git-branch-merge/#fast-forward-merge","title":"Fast-Forward Merge","text":"<p>If the branch being merged hasn\u2019t diverged from the target branch (e.g., no new commits were made on <code>main</code> since <code>cool-feature</code> started), Git can simply move the pointer of the target branch forward to the latest commit of the merged branch. This is called a fast-forward merge.</p> <p>For instance, imagine a developer creates a branch for fixing a small bug and completes the fix without any changes occurring on <code>main</code> in the meantime. A fast-forward merge is efficient and keeps the history clean:</p> <pre><code>git merge cool-feature\n</code></pre> <p>After the merge, the history will look like a single line of commits, as if all the work was done directly on the target branch <code>main</code>.</p>"},{"location":"resources/git/ch3-git-branch-merge/#merge-commit","title":"Merge Commit","text":"<p>If the branches have diverged (e.g., both <code>main</code> and <code>cool-feature</code> have new commits), Git creates a merge commit to combine their histories. A merge commit has two parent commits, representing the tips of the branches being merged.</p> <p>This strategy is particularly useful in larger projects where multiple developers are contributing. For example, if one developer has added a new feature while another has updated documentation on <code>main</code>, a merge commit preserves the distinct contributions:</p> <pre><code>git merge cool-feature\n</code></pre> <p>Here\u2019s how the history looks with a merge commit:</p> <pre><code>*   Merge branch 'cool-feature'\n|\\\n| * Commit on cool-feature\n* | Commit on main\n|/\n</code></pre> <p>To inspect a merge commit and see its parents:</p> <pre><code>git log --graph --oneline\n</code></pre> <p>Merge commits make it easier to trace where specific changes originated, which can be critical for debugging or auditing code.</p>"},{"location":"resources/git/ch3-git-branch-merge/#step-1-switch-to-the-target-branch","title":"Step 1: Switch to the Target Branch","text":"<p>First, switch to the branch you want to merge into (e.g., <code>main</code>):</p> <pre><code>git checkout main\n</code></pre> <p>This step is crucial because Git applies merge operations to the branch that <code>HEAD</code> is currently pointing to. If you accidentally target the wrong branch, you might unintentionally merge unfinished or experimental changes into a stable branch like <code>main</code>, potentially introducing bugs or breaking the build. For example, imagine merging an in-progress feature branch into <code>main</code> during a product release\u2014this could disrupt the deployment process and create significant headaches for the team.</p>"},{"location":"resources/git/ch3-git-branch-merge/#step-2-merge-your-feature-branch","title":"Step 2: Merge Your Feature Branch","text":"<p>Next, run the merge command:</p> <pre><code>git merge cool-feature\n</code></pre> <p>If there are no conflicts, Git will combine the changes, and you\u2019re done! \ud83c\udf89</p>"},{"location":"resources/git/ch3-git-branch-merge/#handling-merge-conflicts","title":"Handling Merge Conflicts","text":"<p>Sometimes, two branches modify the same part of a file, and Git doesn\u2019t know which version to keep. For example, imagine two developers working on the same function in a file\u2014one optimizes its performance while the other updates its documentation. When these changes are merged, Git identifies a conflict because both developers altered the same section of the file, requiring manual resolution. This is called a merge conflict. When this happens, Git will pause the merge and mark the conflicting sections in your files like this:</p> <pre><code>```plaintext\n&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD\nCode from the current branch\n=======\nCode from the branch being merged\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; cool-feature\n```\n</code></pre> <p>To resolve the conflict:</p> <p>(1) Use <code>git status</code> to see which files have conflicts. It will list the files that need attention:</p> <pre><code>git status\n</code></pre> <p>This is especially useful if multiple files are involved.</p> <p>(2) Open each conflicting file and manually edit it to remove the conflict markers and choose the correct content.</p> <p>(3) Add the resolved files:</p> <pre><code>git add &lt;file&gt;\n</code></pre> <p>(4) Complete the merge with a commit:</p> <pre><code>git commit -m \"Resolve merge conflict\"\n</code></pre> <p>If you decide you don\u2019t want to proceed with the merge and want to return to the state before the merge started, you can abort the merge with:</p> <pre><code>git merge --abort\n</code></pre> <p>This will cancel the merge and reset your working directory to the state it was in before the merge began.</p>"},{"location":"resources/git/ch3-git-branch-merge/#cleaning-up-branches","title":"Cleaning Up Branches","text":"<p>Once a branch has been merged, you can delete it to keep your repository tidy:</p> <pre><code>git branch -d cool-feature\n</code></pre> <p>If the branch hasn\u2019t been merged but you still want to delete it, use:</p> <pre><code>git branch -D cool-feature\n</code></pre>"},{"location":"resources/git/ch3-git-branch-merge/#modern-git-why-use-git-switch-rather-than-git-checkout","title":"Modern Git: Why use <code>git switch</code> rather than <code>git checkout</code>?","text":"<p>Many tutorials and older users of <code>git</code> will use <code>checkout</code> where you are learning to use <code>switch</code>. Why?</p> <p><code>git switch</code> was introduced in Git version 2.23 (August 2019) as part of an effort to make Git\u2019s commands more user-friendly and less ambiguous. Historically, <code>git checkout</code> handled many different tasks, from switching branches to checking out individual files or commits. This multitasking nature often led to confusion for new users and even experienced developers.</p> <p>By separating branch-related operations (<code>git switch</code>) from other tasks like checking out specific files or commits (<code>git checkout</code>), Git improved usability and reduced the likelihood of mistakes. </p> <p>For most branching tasks, <code>git switch</code> is the modern and preferred choice. It simplifies workflows and makes commands more intuitive for beginners and teams alike.</p> <ul> <li>Use <code>git switch</code> for creating or moving between branches. It\u2019s explicit and avoids accidentally losing work or entering a detached <code>HEAD</code> state.</li> <li>Use <code>git checkout</code> when you need to:<ul> <li>Recover a specific file from a previous commit:   <pre><code>git checkout &lt;commit-hash&gt; -- &lt;file&gt;\n</code></pre></li> <li>Temporarily view or test a specific commit without creating a new branch (a detached HEAD state):   <pre><code>git checkout &lt;commit-hash&gt;\n</code></pre></li> </ul> </li> </ul>"},{"location":"resources/git/ch3-git-branch-merge/#key-takeaways","title":"Key Takeaways","text":"<ul> <li>A Git branch is a lightweight pointer to a commit. Your current working branch updates to point to new commits added to the branch.</li> <li>Use branches to isolate work, experiment, and collaborate without impacting other branches.</li> <li>Create branches early and often; they\u2019re fast, lightweight, and encourage clean workflows.</li> <li>HEAD points to your current working branch or commit and guides Git commands.</li> <li>Use git switch to create or move between branches; it\u2019s modern and more intuitive than git checkout.</li> <li>Branches can be merged either by fast-forwarding (when no divergence) or merge commits (when histories diverge).</li> <li>Resolve merge conflicts manually by editing files, staging changes, and committing resolutions.</li> <li>Delete merged branches with git branch -d to keep your repository clean.</li> <li>Commit, stash, or discard current changes in your working directory before switching branches to avoid conflicts or lost work.</li> </ul>"},{"location":"resources/git/ch3-git-branch-merge/#subcommands-covered","title":"Subcommands Covered","text":"<ul> <li><code>git branch</code>: Create, list, or delete branches; the core tool for managing branches.  </li> <li><code>git branch -d</code>: Safely delete branches that have been merged. <code>-D</code> is the unsafe variant.</li> <li><code>git switch</code>: Switch between branches or create and switch in one step with <code>--create</code>.  </li> <li><code>git merge</code>: Combine changes from one branch into another, creating a unified history.  </li> <li><code>git merge --abort</code>: Cancel a merge when there are conflicts and return to the pre-merge conflict state.</li> <li><code>git log --graph --oneline</code>: Visualize commit history with branch relationships.</li> <li><code>git stash</code>: Temporarily stash away changes to focus on other tasks or branches.  </li> <li><code>git stash pop</code>: Recover stashed changes to the current working directory.</li> </ul>"},{"location":"resources/git/ch4-git-remote-fetch-push-pull/","title":"Ch. 4 Git Collaboration: Working with Remote Repositories","text":"<p>In today's software development world, writing code is rarely a solo endeavor. Whether you're contributing to open source projects, working on a team assignment, or collaborating with others across the globe, you'll need to share your code and coordinate with other developers. This is where Git's collaboration features become essential - they're the foundation of modern software development practices.</p> <p>This tutorial will help you master the core concepts and commands needed for effective collaboration using Git. By the end, you will:</p> <ul> <li>Understand how Git connects and synchronizes with other repositories</li> <li>Be able to share your code with teammates and pull in their latest changes</li> <li>Know how to handle common collaboration scenarios and resolve conflicts</li> <li>Be ready to participate effectively in team projects</li> </ul>"},{"location":"resources/git/ch4-git-remote-fetch-push-pull/#understanding-remotes-your-gateway-to-collaboration","title":"Understanding Remotes: Your Gateway to Collaboration","text":"<p>Think of your local Git repository as your personal workspace - it's where you write code, make commits, and track changes. But how do you share these changes with your teammates? That's where remote repositories come in. A remote repository acts like a shared storage space that everyone on your team can access. It's similar to how cloud storage lets multiple people share and sync files, but with special features designed for code collaboration.</p> <p>What's a Remote Repository?</p> <p>A remote repository is a version of your project hosted on the internet or a network. It serves as the central reference point that all team members use to share and synchronize their work. Common hosting platforms include GitHub, GitLab, and Bitbucket.</p> <p>Let's start by connecting to a remote repository. We'll use GitHub as our example, but these concepts work the same way with any Git hosting service:</p> <pre><code>git remote add origin https://github.com/username/project.git # (1)!\n</code></pre> <ol> <li>Create a new connection named \"origin\" pointing to your GitHub repository</li> </ol> <p>We're using \"origin\" as the name for our remote repository here. While you can choose any name you like, \"origin\" is the conventional choice for your primary remote repository - think of it as the source of truth for your project.</p> <p>You can manage your remote connections with these helpful commands:</p> <pre><code>git remote --verbose # (1)!\ngit remote show origin # (2)!\n</code></pre> <ol> <li>List all remote repositories with their URLs</li> <li>Display detailed information about the \"origin\" remote</li> </ol> <p>Command Shorthand</p> <p>You can use <code>git remote -v</code> as a shorter version of the verbose flag.</p>"},{"location":"resources/git/ch4-git-remote-fetch-push-pull/#https-vs-ssh-remote-urls","title":"HTTPS vs SSH Remote URLs","text":"<p>When adding a remote, you have two main options for how to connect: HTTPS or SSH.</p> <pre><code># HTTPS style remote\ngit remote add origin https://github.com/username/repository.git\n\n# SSH style remote\ngit remote add origin git@github.com:username/repository.git\n</code></pre> <p>HTTPS (Hypertext Transfer Protocol Secure) is the protocol that powers secure websites and is GitHub's recommended approach for repository connections. SSH (Secure Shell) is a protocol designed for secure remote access to systems.</p> <p>Both protocols can be set up to remember your credentials, so you won't need to enter them each time you interact with GitHub. With HTTPS, this means configuring a credential manager to store your personal access token. With SSH, you'll set up a key pair that allows for automatic authentication.</p> <p>For most developers, HTTPS is the better choice. It works reliably across different networks and firewall configurations, and GitHub's tooling is optimized for HTTPS connections. Consider SSH as an alternative only if you have specific requirements that HTTPS doesn't meet, or if you're already comfortable managing SSH keys.</p> <p>Authentication Deep Dive</p> <p>GitHub provides comprehensive documentation about authentication methods, security best practices, and troubleshooting tips in their authentication guide. You'll find detailed instructions for setting up both HTTPS and SSH authentication, including how to create and manage access tokens, configure SSH keys, and use two-factor authentication for additional security.</p>"},{"location":"resources/git/ch4-git-remote-fetch-push-pull/#fetching-preview-changes-before-merging","title":"Fetching: Preview Changes Before Merging","text":"<p>Before you integrate changes from your teammates, it's often helpful to see what they've done first. That's where fetching comes in - it lets you download and inspect changes without immediately applying them to your work. Think of it like previewing changes in a Google Doc before accepting them.</p> <pre><code>git fetch --all # (1)!\n</code></pre> <ol> <li>Download all branches and commits from every configured remote</li> </ol> <p>Command Shorthand</p> <p>The shorter version is <code>git fetch -a</code> once you're comfortable with the operation.</p> <p>When you fetch, Git downloads all new commits but doesn't modify your working files or local branches. This is particularly useful when you want to:</p> <ul> <li>Review your teammates' changes before incorporating them</li> <li>Check if there are any potential conflicts with your work</li> <li>Work with multiple feature branches from different team members</li> </ul> <p>For example, if your teammate pushed changes to a branch named <code>feature-login</code>, here's how you can examine their work:</p> <pre><code>git fetch origin # (1)!\ngit switch feature-login # (2)!\n</code></pre> <ol> <li>Download the latest changes from the remote repository</li> <li>Create and switch to a local branch tracking the remote feature-login branch</li> </ol> <p>Let's look at how this works using a sequence diagram. In sequence diagrams, you see a timeline of how operations unfold between different participants (in our case, different repositories). Each vertical line represents a different participant, and each entry on that line happens in sequence over time as you read from top to bottom. These diagrams are a common tool in software engineering for understanding how different parts of a system interact.</p> <pre><code>sequenceDiagram\n    participant L as Local Repository\n    participant R as Remote Repository\n    participant T as Teammate (feature-login)\n\n    Note over L,R: No feature-login branch locally\n    T-&gt;&gt;T: Creates commits A, B on feature-login\n    T-&gt;&gt;R: Pushes feature-login\n    Note over R: Remote has feature-login at B\n    L-&gt;&gt;R: git fetch origin\n    R--&gt;&gt;L: Updates origin/feature-login to B\n    Note over L: Creates origin/feature-login\n    L-&gt;&gt;L: git switch feature-login\n    Note over L: Creates and switches to&lt;br/&gt;local feature-login tracking&lt;br/&gt;origin/feature-login</code></pre> <p>After the <code>switch</code> command, you are now working in a local branch named <code>feature-login</code> which tracks <code>origin/feature-login</code>. Since it's just a branch, if you think your teammate's work looks good and you'd like to merge it into your project, you can switch back to whatever branch you'd like and, just like any other branch, merge it in!</p>"},{"location":"resources/git/ch4-git-remote-fetch-push-pull/#understanding-remote-branches","title":"Understanding Remote Branches","text":"<p>Git uses a special naming system to keep track of branches that exist in remote repositories. Remote branches are prefixed with \"remotes/origin/\" to distinguish them from your local branches. You can see all remote branches using:</p> <pre><code>git branch --remotes # (1)!\n</code></pre> <ol> <li>Display all remote branches known to your local repository</li> </ol> <p>The output might look something like this:</p> <pre><code>  remotes/origin/main\n  remotes/origin/feature-login\n  remotes/origin/bugfix-header\n  remotes/origin/documentation\n  remotes/origin/HEAD -&gt; origin/main\n</code></pre> <p>Remote References</p> <p>Remote branch names can be used in any Git command that accepts a branch name. For example: <code>git diff main origin/main</code> shows differences between your local and remote main branches.</p>"},{"location":"resources/git/ch4-git-remote-fetch-push-pull/#pulling-combining-fetch-and-merge","title":"Pulling: Combining Fetch and Merge","text":"<ol> <li>Switch to your main branch</li> <li>Download and integrate the latest changes from the remote main branch</li> </ol> <p>Check Your Branch</p> <p>Always verify which branch you're on before pulling. Pulling while on the wrong branch means you'll merge remote changes into the wrong place in your repository.</p>"},{"location":"resources/git/ch4-git-remote-fetch-push-pull/#pulling-when-remote-branches-havent-diverged","title":"Pulling When Remote Branches Haven't Diverged","text":"<p>If you haven't made any new commits since your last synchronization with the remote repository, pulling performs a fast-forward merge, just like you've seen before when merging branches. The remote branch <code>origin/main</code> is treated exactly like any other branch that has new commits \u2013 Git simply moves your branch pointer forward to match it.</p> <pre><code>sequenceDiagram\n    participant L as Local Repository (main)\n    participant R as Remote Repository (main)\n    participant T as Teammate (main)\n\n    Note over L,T: All main branches at commit B\n    T-&gt;&gt;T: Creates commits C, D on main\n    T-&gt;&gt;R: Pushes main\n    Note over R: Remote main now at D\n    L-&gt;&gt;R: git pull\n    R--&gt;&gt;L: Fetch updates origin/main to D\n    Note over L: Fast-forward local main&lt;br/&gt;from B to D to match origin/main</code></pre>"},{"location":"resources/git/ch4-git-remote-fetch-push-pull/#pulling-when-remote-branches-have-diverged","title":"Pulling When Remote Branches Have Diverged","text":"<p>If you've made local commits while others have pushed to the remote, your branch and <code>origin/main</code> have diverged \u2013 a situation you're familiar with from merging branches. Just as before, Git needs to create a merge commit to combine these parallel lines of development.</p> <p>Here's the corresponding sequence diagram:</p> <pre><code>sequenceDiagram\n    participant L as Local Repository (main)\n    participant R as Remote Repository (main)\n    participant T as Teammate (main)\n\n    Note over L,T: All main branches at commit B\n    T-&gt;&gt;T: Creates commits C, D on main\n    T-&gt;&gt;R: Pushes main\n    Note over R: Remote main now at D\n    L-&gt;&gt;L: Creates commits E, F on main\n    Note over L: Local main now at F\n    L-&gt;&gt;R: git pull\n    R--&gt;&gt;L: Fetch updates origin/main to D\n    Note over L: Create merge commit G combining&lt;br/&gt;local main (F) and origin/main (D)</code></pre> <p>You might need to resolve conflicts here, just as you would when merging any other diverged branches. Remember that <code>origin/main</code> is just Git's way of tracking what's on the remote repository \u2013 once you have fetched a remote branch, it's just a local branch with a different naming convention and, as such, it behaves exactly like any other branch when it comes to merging.</p>"},{"location":"resources/git/ch4-git-remote-fetch-push-pull/#cloning-starting-with-an-existing-project","title":"Cloning: Starting with an Existing Project","text":"<p>You've likely started many projects by cloning an existing repository. Now that you understand how Git manages remote repositories, let's explore what actually happens during the cloning process. Cloning is essentially an automated combination of several operations you've just learned about, packaged into a single command for convenience.</p> <p>When you run <code>git clone</code>, Git performs these steps in sequence:</p> <ol> <li>Creates a new directory for your project</li> <li>Initializes a fresh Git repository inside it</li> <li>Adds a remote named \"origin\" pointing to the URL you're cloning from</li> <li>Fetches all branches and history from that remote</li> <li>Sets up tracking relationships between local and remote branches</li> <li>Checks out the default branch (usually <code>main</code>) as your working copy</li> </ol> <p>Let's see this in action:</p> <pre><code>git clone https://github.com/username/project.git # (1)!\n</code></pre> <ol> <li>Download the repository and set up a local copy with remote tracking</li> </ol> <p>This single command accomplishes what would otherwise require several manual steps:</p> <pre><code>mkdir project\ncd project\ngit init\ngit remote add origin https://github.com/username/project.git\ngit fetch origin\ngit switch main\n</code></pre>"},{"location":"resources/git/ch4-git-remote-fetch-push-pull/#pushing-sharing-your-work","title":"Pushing: Sharing Your Work","text":"<p>Now that you understand how to get changes from your teammates through pulling, let's look at how to share your work with them through pushing. When you push your commits, you're asking the remote repository to integrate your changes into its history.</p>"},{"location":"resources/git/ch4-git-remote-fetch-push-pull/#setting-up-branch-tracking","title":"Setting Up Branch Tracking","text":"<p>When you're working on a completely new feature or bug fix, you'll often start by creating a local branch. Until you share this branch with others, it exists only in your local repository \u2013 the remote repository doesn't know anything about it yet. In these cases, when you push the branch for the first time, you need to tell Git two things:</p> <ol> <li>Which remote repository should store this branch (usually \"origin\")</li> <li>What name the branch should have on the remote (usually the same as your local branch name)</li> </ol> <p>This is what the <code>--set-upstream</code> flag (or <code>-u</code> for short) does in the following command:</p> <pre><code>git push --set-upstream origin feature-awesome # (1)!\n</code></pre> <ol> <li>Upload your new branch and configure it to track a branch of the same name on the remote</li> </ol> <p>This command creates a connection, or \"tracking relationship,\" between your local <code>feature-awesome</code> branch and a new branch of the same name on the remote repository. This tracking relationship is important \u2013 once established, it lets you use simple <code>git push</code> and <code>git pull</code> commands without having to specify the remote and branch names each time.</p> <p>Local vs Remote Branches</p> <p>This is different from when you <code>fetch</code> and <code>switch</code> to a branch that your teammate has already shared. In that case, Git automatically sets up the tracking relationship for you because it knows the branch came from the remote repository. As such, you can push new commits to the teammate's branch without needing to use <code>--set-upstream</code> the first time.</p>"},{"location":"resources/git/ch4-git-remote-fetch-push-pull/#creating-new-remote-branches","title":"Creating New Remote Branches","text":"<p>When you push a branch that doesn't exist on the remote repository yet, Git will create it for you.</p> <pre><code>sequenceDiagram\n    participant L as Local Repository (feature)\n    participant R as Remote Repository\n    participant T as Teammate\n\n    Note over L,R: No feature branch exists on remote\n    L-&gt;&gt;L: Creates commits A, B on feature\n    L-&gt;&gt;R: git push -u origin feature\n    Note over R: Creates feature branch&lt;br/&gt;with commits A, B</code></pre> <p>You'll encounter this scenario frequently when starting new work. For example, when you create a new feature branch locally and want to share it with your team, or when you're starting a new bug fix and want to get early feedback.</p>"},{"location":"resources/git/ch4-git-remote-fetch-push-pull/#pushing-to-existing-branches","title":"Pushing to Existing Branches","text":"<p>When pushing to a branch that already exists on the remote, Git checks if your changes can be merged cleanly thanks to a linear commit history. If no one has pushed new changes to the remote branch since you last pulled, Git can perform a fast-forward merge on the remote repository \u2013 just like the fast-forward merges you're familiar with locally. Your commits are simply added to the end of the remote branch's history:</p> <pre><code>sequenceDiagram\n    participant L as Local Repository (main)\n    participant R as Remote Repository (main)\n    participant T as Teammate (main)\n\n    Note over L,T: All main branches at commit B\n    L-&gt;&gt;L: Creates commits C, D on main\n    L-&gt;&gt;R: git push\n    Note over R: Fast-forward remote main&lt;br/&gt;from B to D</code></pre>"},{"location":"resources/git/ch4-git-remote-fetch-push-pull/#handling-push-rejections","title":"Handling Push Rejections","text":"<p>Sometimes your push will be rejected because the remote branch has new commits that you don't have locally. This is Git's way of preventing you from accidentally overwriting your teammates' work. When this happens, you need to merge their changes in to your local repository's branch before you can push yours:</p> <pre><code>sequenceDiagram\n    participant L as Local Repository (main)\n    participant R as Remote Repository (main)\n    participant T as Teammate (main)\n\n    Note over L,T: All main branches at commit B\n    L-&gt;&gt;L: Creates commits C, D on main\n    T-&gt;&gt;T: Creates commits E, F on main\n    T-&gt;&gt;R: Pushes main\n    Note over R: Remote main now at F\n    L-&gt;&gt;R: Attempts to push\n    R--&gt;&gt;L: Rejects push (not up to date)\n    L-&gt;&gt;R: git pull\n    R--&gt;&gt;L: Fetch and Merge origin/main\n    Note over L: Create merge commit G combining&lt;br/&gt;local main (D) and origin/main (F)\n    L-&gt;&gt;R: git push\n    Note over R: Uploads commits C, D, G&lt;br/&gt;Fast-forward remote main to G</code></pre> <p>This sequence should look familiar \u2013 it's the same divergent history situation you saw with pulling, just in reverse. Here's what's happening:</p> <ol> <li>The remote rejects your push because accepting it would lose your teammate's work</li> <li>You pull to get your teammate's changes, creating a merge commit</li> <li>Now your history contains everything from the remote, so your push can be accepted</li> </ol> <p>Remember that after the pull creates a merge commit, your subsequent push will be accepted because it's effectively a fast-forward merge from the remote's perspective \u2013 all the commits it has are already part of your history.</p>"},{"location":"resources/git/ch4-git-remote-fetch-push-pull/#best-practices-for-working-with-remote-repositories","title":"Best Practices for Working with Remote Repositories","text":"<p>Let's discuss some essential habits that will help you collaborate effectively with your team when working with remote repositories.</p>"},{"location":"resources/git/ch4-git-remote-fetch-push-pull/#fetch-early-and-often","title":"Fetch Early and Often","text":"<p>Make a habit of frequently fetching from your remote repository, just as you regularly save your work. Fetching is safe \u2013 it won't modify your working directory or local branches \u2013 and it helps you stay aware of what your teammates are doing. Many developers start their day by fetching the latest changes and do so again before starting any significant new work. This practice helps them spot potential conflicts early and stay synchronized with their team.</p>"},{"location":"resources/git/ch4-git-remote-fetch-push-pull/#pull-before-you-push","title":"Pull Before You Push","text":"<p>Always pull before pushing to a shared branch, even if you think your local branch is up to date. This habit ensures you're working with the latest code and helps prevent push rejections. When working on long-running feature branches, it's also good practice to regularly pull from the main branch to keep your feature branch up to date. This prevents your branch from diverging too far from the main line of development.</p>"},{"location":"resources/git/ch4-git-remote-fetch-push-pull/#communicate-branch-intent","title":"Communicate Branch Intent","text":"<p>When pushing a new branch to the remote repository, use clear, descriptive names that communicate the branch's purpose. A good branch name tells your teammates what work is being done without them having to examine the code. Many teams use prefixes to categorize the type of work and include ticket numbers for tracking:</p> <pre><code>feature-user-authentication\nfeature-issue-123-email-notifications\nbugfix-login-timeout\nbugfix-456-memory-leak\nwip-oauth-integration\n</code></pre> <p>These descriptive names help your team understand at a glance what changes to expect when reviewing your code.</p>"},{"location":"resources/git/ch4-git-remote-fetch-push-pull/#handle-conflicts-promptly","title":"Handle Conflicts Promptly","text":"<p>If you encounter conflicts during a pull, address them right away while the changes are fresh in your mind. The longer you wait, the harder it becomes to remember the context of the changes and make good decisions about how to resolve the conflicts.</p>"},{"location":"resources/git/ch4-git-remote-fetch-push-pull/#push-thoughtfully","title":"Push Thoughtfully","text":"<p>While it's important to share your work regularly, avoid pushing broken or incomplete code to shared branches. Before pushing, make sure your changes compile, pass tests, and include any new files your changes depend on. This is especially important for branches that others actively use, like the main branch.</p>"},{"location":"resources/git/ch4-git-remote-fetch-push-pull/#summary-and-key-points","title":"Summary and Key Points","text":"<p>Working with remote repositories in Git is all about effective collaboration. Remember:</p> <ul> <li>Remote repositories are shared spaces for code collaboration</li> <li>Fetch lets you preview changes before integrating them</li> <li>Pull combines fetching and merging in one step</li> <li>Push shares your work with the team</li> </ul>"},{"location":"resources/git/ch4-git-remote-fetch-push-pull/#essential-commands-reference","title":"Essential Commands Reference","text":"<pre><code>git remote add &lt;name&gt; &lt;url&gt;    # (1)!\ngit fetch -a                   # (2)!\ngit switch &lt;branch&gt;            # (3)!\ngit pull                       # (4)!\ngit push -u origin &lt;branch&gt;    # (5)!\n</code></pre> <ol> <li>Connect to a remote repository</li> <li>Download all remote changes</li> <li>Switch to or create a branch</li> <li>Download and integrate remote changes</li> <li>Upload your changes and set tracking</li> </ol> <p>Further Reading</p> <ul> <li>Git Remote Documentation</li> <li>GitHub Authentication Guide</li> <li>Pro Git Book: Working with Remotes</li> </ul>"},{"location":"resources/git/exercise/","title":"Collaborating with <code>git</code> on a <code>MkDocs</code> Project","text":"<p>In this tutorial, you will work to create </p>"},{"location":"resources/git/exercise/#how-do-collaborative-apps-address-who-can-do-what","title":"How do collaborative apps address \"Who can do what?\"","text":"<p>Think about how you engage with your favorite apps daily. When you post pictures on Instagram, you control who sees them\u2014perhaps just your close friends or maybe everyone. When collaborating on a Google Docs project, you decide whether classmates can edit or just comment. And within your Google Drive, some folders might be shared with your study group, while others remain private. These everyday interactions with social media and collaboration tools are your practical introduction to three pivotal software engineering concepts: authentication, authorization, and access control.</p> <p>As you dive into building your software projects or integrate into development teams, you will encounter these patterns repeatedly. Whether crafting a straightforward web application or developing complex enterprise software, pivotal questions arise: \"How do users prove who they are?\", \"What permissions should different users have?\", and \"How are these permissions enforced consistently?\" Fortunately, the answers to these questions are built on established terminology and conceptual frameworks developed over many decades of software engineering projects.</p>"},{"location":"resources/git/exercise/#authentication","title":"Authentication","text":"<p>Authentication is the process of verifying the identity of a user, system, or entity attempting to access a resource. This verification process involves validating one or more authentication factors, which typically fall into three categories:</p> <ul> <li>Something you know (like passwords or PINs)</li> <li>Something you have (like security tokens or smart cards)</li> <li>Something you are (like fingerprints or facial features)</li> </ul> <p>The authentication process generates a digital identity that the system can then use for subsequent interactions. For example, when you log into a system, an authentication process may create a session token that represents your verified identity.</p>"},{"location":"resources/git/exercise/#authorization-and-access-control","title":"Authorization and Access Control","text":"<p>Authorization is the process of determining whether an authenticated identity has permission to perform specific actions or access particular resources. Authorization defines what an authenticated user can do within a system by evaluating their privileges against a set of rules or policies. Authorization always occurs after authentication - a system must know who you are before it can determine what you're allowed to do.</p> <p>Access Control is the implementation mechanism that enforces authorization decisions and protects resources from unauthorized access. While authorization defines the rules about who can do what, access control provides the technical mechanisms to enforce these rules. Access control systems implement various models such as:</p> <ul> <li>Role-Based Access Control (RBAC): Groups permissions into roles and assigns users to appropriate roles</li> <li>Attribute-Based Access Control (ABAC): Makes access decisions based on attributes of users, resources, and context</li> <li>Mandatory Access Control (MAC): Enforces system-wide policies that users cannot modify</li> <li>Discretionary Access Control (DAC): Allows resource owners to control access to their resources</li> </ul> <p>The Relationship Chain These three concepts work together in a sequential chain:</p> <p>Authentication verifies identity (\"Who are you?\") Authorization determines permissions (\"What are you allowed to do?\") Access Control enforces those permissions (\"Here's how we'll make sure you only do what you're allowed to do\")</p> <p>For example, when you attempt to access a secure file:</p> <ol> <li>The system first authenticates you by validating your login credentials</li> <li>Once authenticated, the authorization system checks your permissions to determine if you should have access to take an action on a given resource</li> <li>If authorized, the access control mechanism enforces this decision by actually allowing or blocking the file access attempt</li> </ol>"},{"location":"resources/project-management/wireframes/","title":"Wireframing and Prototyping: Visualizing User Experiences","text":"<p>Wireframing is a foundational practice within User Interface (UI) and User Experience (UX) design, enabling teams to visualize ideas quickly, set clear expectations, and efficiently communicate with internal members as well as external stakeholders and clients. It serves as a critical step in project management and human-centered design, helping teams align their design vision with user needs and practical constraints.</p>"},{"location":"resources/project-management/wireframes/#communicating-and-storyboarding-with-wireframes","title":"Communicating and Storyboarding with Wireframes","text":"<p>Wireframes significantly enhance communication within teams and facilitate alignment with external stakeholders by visually representing concepts that can be challenging to articulate through text alone. Written descriptions often leave room for interpretation, which may lead to misunderstandings or gaps in expectations. For instance, a product team might use text to describe an interactive onboarding flow, believing they have communicated clearly. However, when stakeholders see the final implementation, they may find it confusing, overly complicated, or different from what they had envisioned.</p> <p>These pitfalls highlight why wireframes are invaluable for catching misunderstandings early. By visually mapping out interfaces and interactions, wireframes clarify how a user will actually engage with the product. This process helps to uncover hidden assumptions or overlooked complexities, allowing teams to address these issues proactively rather than reactively.</p> <p>Storyboarding with wireframes is particularly powerful when dealing with user stories or agile epics. Teams can visually outline user journeys, demonstrating clearly how a feature or product experience progresses step by step. For example, a written description might imply a straightforward user sign-up flow. However, once visually storyboarded with wireframes, it becomes obvious that additional steps or screens are needed to provide necessary context or guidance, improving usability and the overall user experience.</p> <p>Additionally, wireframing enhances empathy within teams by providing a tangible reference point that mirrors real user interactions. Rather than abstractly imagining user experiences, teams can concretely visualize workflows, helping them to anticipate user frustrations or difficulties. This empathy-driven approach ensures that designs are not only technically feasible but also intuitive and user-friendly.</p> <p>Ultimately, effective use of wireframes in storyboarding saves time and resources by reducing misalignment and ensuring everyone involved has a shared and accurate understanding of what the final product will feel like to the end-user.</p>"},{"location":"resources/project-management/wireframes/#wireframing-fidelity-spectrum","title":"Wireframing Fidelity Spectrum","text":"<p>Understanding wireframing involves recognizing the varying levels of detail, often called fidelity. Each fidelity level offers unique benefits and serves specific purposes during the design and development process.</p>"},{"location":"resources/project-management/wireframes/#low-fidelity-lo-fi-wireframes","title":"Low-Fidelity (Lo-Fi) Wireframes","text":"<p>Low-fidelity wireframes are simple, rough sketches typically drawn by hand using markers, sharpies, or whiteboards. These wireframes focus purely on representing the general layout and core interactions of the interface without attention to visual details or styling. The strength of low-fidelity wireframes lies in their simplicity and speed\u2014they can be rapidly created and easily modified, making them ideal for initial brainstorming and team discussions. These early-stage wireframes facilitate quick concept validation and help teams collaboratively identify high-level design concerns before significant resources are committed. However, because these sketches lack detail, they may not effectively communicate intricate functionalities or aesthetics to stakeholders unfamiliar with the project.</p>"},{"location":"resources/project-management/wireframes/#mid-fidelity-mid-fi-wireframes","title":"Mid-Fidelity (Mid-Fi) Wireframes","text":"<p>Mid-fidelity wireframes introduce greater accuracy and detail by using digital tools like Balsamiq or Figma. They define layouts and interaction states more precisely than low-fidelity sketches and often include basic color schemes and placeholder content. Mid-fi wireframes strike a balance, providing sufficient detail for teams to discuss and validate functionality and usability without investing excessive time in visual refinement. They serve well in preliminary usability testing and internal reviews, clearly conveying navigation and user flow. Despite their increased clarity, mid-fi wireframes still might lack the detailed visual polish needed for definitive stakeholder approval or rigorous usability assessments.</p>"},{"location":"resources/project-management/wireframes/#high-fidelity-hi-fi-wireframes-prototypes","title":"High-Fidelity (Hi-Fi) Wireframes &amp; Prototypes","text":"<p>High-fidelity wireframes and prototypes closely resemble the final product in appearance and interaction, typically developed using advanced prototyping software such as Figma, Adobe XD, or Sketch. These prototypes incorporate realistic visual elements, including exact colors, typography, images, and brand identity, along with interactive components and transitions that simulate real-world interactions. High-fidelity prototypes are especially valuable for gaining precise feedback from stakeholders, performing formal usability testing, and ensuring that the final vision of the design is clearly communicated to development teams. However, the primary trade-off with high-fidelity prototypes is that they are more time-consuming and resource-intensive to create. Introducing them too early can unintentionally constrain creative exploration and lock in design decisions prematurely.</p>"},{"location":"resources/project-management/wireframes/#comparison-of-wireframe-fidelity-levels","title":"Comparison of Wireframe Fidelity Levels","text":"Fidelity Level Pros Cons Typical Uses Time/Cost to Produce Low-Fidelity (Lo-Fi) Fast, inexpensive, easy to modify Lacks detail, can be unclear for stakeholders Initial brainstorming, early internal discussions Low time, low cost Mid-Fidelity (Mid-Fi) Clearer detail, balances speed and accuracy Still lacks final polish, not ideal for final approvals Preliminary usability tests, internal reviews Moderate time, moderate cost High-Fidelity (Hi-Fi) Realistic appearance, precise feedback Time-consuming, expensive, limits early exploration Client presentations, formal usability testing, development documentation High time, high cost"},{"location":"resources/project-management/wireframes/#cost-efficiency-and-design-exploration","title":"Cost Efficiency and Design Exploration","text":"<p>Wireframing is also an economically efficient practice within project management. It empowers teams to experiment with multiple design approaches before committing to development, minimizing risks by uncovering issues early. Because wireframes have minimal overhead, they allow teams to iteratively refine and optimize the user experience without the high cost associated with reworking actual code. Ultimately, wireframing supports teams in balancing ideal user experiences with practical limitations, ensuring the end product is both innovative and realistically achievable.</p>"},{"location":"resources/project-management/wireframes/#wireframing-challenges-with-llm-chat-ai","title":"Wireframing Challenges with LLM &amp; Chat-AI","text":"<p>The emergence of Large Language Models (LLMs) and AI-driven conversational interfaces presents new challenges for traditional wireframing practices. These interfaces are inherently textual and conversational, making it difficult to capture nuanced interactions through visual wireframes alone. In these scenarios, interaction scripts and detailed textual scenarios become more valuable, clearly specifying conversational flows and anticipated user interactions. While wireframes remain useful, relying exclusively on them is insufficient when dealing with sophisticated, dialogue-heavy experiences.</p>"},{"location":"resources/project-management/wireframes/#key-takeaways","title":"Key Takeaways","text":"<p>Wireframing is an essential, cost-effective practice that supports clear communication, thorough exploration, and thoughtful validation of user interfaces and experiences. By progressing through different fidelity levels\u2014from simple sketches to highly detailed prototypes\u2014teams can efficiently identify and solve design problems, build empathy for users, and manage stakeholder expectations. Incorporating wireframing early and continuously into your design process greatly enhances the likelihood of delivering intuitive, user-centered products.</p>"}]}